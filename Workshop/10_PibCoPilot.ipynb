{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIB CoPilot\n",
    "PIBs are also used to create a pitchbook by assessing a company's strategy, competitive positioning, review of financial statements, industry dynamics, and trends within the industry. \n",
    "1. Company Overview and Executive Bio - A brief description of the company and its key executives with biographies.\n",
    "2. Conference calls: The same day a company issues its quarterly press release, it will also hold a conference call. On the call, analysts often learn details about management guidance. These conference calls are transcribed by several service providers and can be accessed by subscribers of large financial data providers.\n",
    "3. Press Release: Can be found in the investor relations section of most companies' websites and contains the financial statements which are used in forms 10-K and 10-Q. \n",
    "4. News: News articles that may affect a company's stock price or growth prospect would be something that analysts look into, particularly within a 6-12 month time horizon.\n",
    "5. SEC filings: These regulatory documents require a company to file Form 10-K and Form 10-Q with the SEC on an ongoing basis. Form 10-K is a financial overview and commentary for the last year, usually found on the company's website. Form 10-Q is similar to form 10-K, but it is a report for the last quarter instead of the previous year.\n",
    "6. Equity research reports: Look into key forecasts for metrics like Revenue, EBITDA, and EPS for the company or competing firms to form a consensus estimate. \n",
    "7. Investor Presentations: Companies provide historical information as an important foundation from which forecasts are made to guide key forecasting drivers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0 -  Pre-requsite and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "import json  \n",
    "import openai\n",
    "from Utilities.envVars import *\n",
    "import uuid\n",
    "# Set Search Service endpoint, index name, and API key from environment variables\n",
    "indexName = SearchIndex\n",
    "\n",
    "# Set OpenAI API key and endpoint\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = OpenAiVersion\n",
    "openai_api_key = OpenAiKey\n",
    "assert openai_api_key, \"ERROR: Azure OpenAI Key is missing\"\n",
    "openai.api_key = openai_api_key\n",
    "openAiEndPoint = f\"https://{OpenAiService}.openai.azure.com\"\n",
    "assert openAiEndPoint, \"ERROR: Azure OpenAI Endpoint is missing\"\n",
    "assert \"openai.azure.com\" in openAiEndPoint.lower(), \"ERROR: Azure OpenAI Endpoint should be in the form: \\n\\n\\t<your unique endpoint identifier>.openai.azure.com\"\n",
    "openai.api_base = openAiEndPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "embeddingModelType = \"azureopenai\"\n",
    "temperature = 0\n",
    "tokenLength = 1000\n",
    "symbol = 'SMFG'\n",
    "apikey = FmpKey\n",
    "os.environ['BING_SUBSCRIPTION_KEY'] = BingKey\n",
    "os.environ['BING_SEARCH_URL'] = BingUrl\n",
    "pibIndexName = 'pibdata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.llms.openai import AzureOpenAI, OpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from IPython.display import display, HTML\n",
    "from langchain.utilities import BingSearchAPIWrapper\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import pandas as pd\n",
    "from langchain.prompts import PromptTemplate\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import timedelta\n",
    "from Utilities.pibCopilot import indexDocs, createPressReleaseIndex, createStockNewsIndex, mergeDocs, createPibIndex, findPibData, findEarningCalls, deletePibData, performEarningCallCogSearch\n",
    "from Utilities.pibCopilot import indexEarningCallSections, createEarningCallVectorIndex, createEarningCallIndex, performCogSearch, createSecFilingIndex, findSecFiling\n",
    "from Utilities.pibCopilot import findLatestSecFilings, createSecFilingsVectorIndex, indexSecFilingsSections\n",
    "import typing\n",
    "from Utilities.fmp import *\n",
    "from langchain.chat_models import AzureChatOpenAI, ChatOpenAI\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flexibility to change the call to OpenAI or Azure OpenAI\n",
    "if (embeddingModelType == 'azureopenai'):\n",
    "    openai.api_type = \"azure\"\n",
    "    openai.api_key = OpenAiKey\n",
    "    openai.api_version = OpenAiVersion\n",
    "    openai.api_base = OpenAiBase\n",
    "    \n",
    "    llm = AzureChatOpenAI(\n",
    "                openai_api_base=openai.api_base,\n",
    "                openai_api_version=OpenAiVersion,\n",
    "                deployment_name=OpenAiChat16k,\n",
    "                temperature=temperature,\n",
    "                openai_api_key=OpenAiKey,\n",
    "                openai_api_type=\"azure\",\n",
    "                max_tokens=tokenLength)\n",
    "    \n",
    "    logging.info(\"LLM Setup done\")\n",
    "    embeddings = OpenAIEmbeddings(deployment=OpenAiEmbedding, chunk_size=1, openai_api_key=OpenAiKey)\n",
    "elif embeddingModelType == \"openai\":\n",
    "    openai.api_type = \"open_ai\"\n",
    "    openai.api_base = \"https://api.openai.com/v1\"\n",
    "    openai.api_version = '2020-11-07' \n",
    "    openai.api_key = OpenAiApiKey\n",
    "    llm = OpenAI(temperature=temperature,\n",
    "            openai_api_key=OpenAiApiKey,\n",
    "            model_name=\"gpt-3.5-turbo\",\n",
    "            max_tokens=tokenLength)\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=OpenAiApiKey)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "central = timezone('US/Central')\n",
    "today = datetime.now(central)\n",
    "currentYear = today.year\n",
    "historicalDate = today - relativedelta(years=3)\n",
    "historicalYear = historicalDate.year\n",
    "historicalDate = historicalDate.strftime(\"%Y-%m-%d\")\n",
    "totalYears = currentYear - historicalYear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find CIK based on Symbol\n",
    "cik = str(int(searchCik(apikey=apikey, ticker=symbol)[0][\"companyCik\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#symbol: str = \"AAPL\"\n",
    "#cik = \"320193\"\n",
    "#symbols: typing.List[str] = [\"AAPL\", \"CSCO\", \"QQQQ\"]\n",
    "#exchange: str = \"NYSE\"\n",
    "#exchanges: typing.List[str] = [\"NYSE\", \"NASDAQ\"]\n",
    "#query: str = \"AA\"\n",
    "#limit: int = 3\n",
    "#period: str = \"quarter\"\n",
    "#download: bool = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1022837'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deletePibData(SearchService, SearchKey, pibIndexName, \"1535929\", \"2\", returnFields=['id', 'symbol', 'cik', 'step', 'description', 'insertedDate',\n",
    "#                                                                        'pibData'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Paid Data - Company Profile and Key Executives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search index pibdata already exists\n",
      "[{'id': '87989235-2709-4195-aeba-a0629196e7c3', 'symbol': 'SMFG', 'cik': '1022837', 'step': '1', 'description': 'Company Profile', 'insertedDate': '2023-08-06', 'pibData': \"[{'symbol': 'SMFG', 'mktCap': 61103701402, 'companyName': 'Sumitomo Mitsui Financial Group, Inc.', 'currency': 'USD', 'cik': '0001022837', 'isin': 'US86562M2098', 'exchange': 'New York Stock Exchange', 'industry': 'Banks—Diversified', 'sector': 'Financial Services', 'address': '1-2, Marunouchi 1-chome', 'city': 'Tokyo', 'state': '', 'zip': '100-0005', 'website': 'https://www.smfg.co.jp', 'description': 'Sumitomo Mitsui Financial Group, Inc., together with its subsidiaries, provides commercial banking, leasing, securities, consumer finance, and other services in Japan, the Americas, Europe, the Middle East, Asia, and Oceania. It operates through four segments: Wholesale Business Unit, Retail Business Unit, Global Business Unit, and Global Markets Business Unit. The Wholesale Business Unit segment offers financing, investment management, risk hedging, and settlement services, as well as financial solutions related to mergers and acquisition, and other advisory services primarily for large, mid, and small-sized corporate clients; various leasing services, including equipment, and operating and leveraged leasing; and digital services, such as robotic process automation and electronic contract services. The Retail Business Unit segment offers wealth management, settlement, consumer finance, and housing loan products and services, as well as business and asset succession services to high-net-worth customers. The Global Business Unit segment offers loans, deposits, clearing services, trade finance, project finance, loan syndication, derivatives, and cash management services; underwriting services; and leasing services related to the construction machinery, transportation equipment, industrial machinery, medical equipment, and aircraft leasing. The Global Markets Business Unit segment offers solutions through foreign exchange products, derivatives, bonds, stocks, and other marketable financial products. It also undertakes asset liability management operations. The company also offers credit card, internet banking, system development and engineering, data processing, management consulting and economic research, and investment advisory and investment trust management services. Sumitomo Mitsui Financial Group, Inc. was incorporated in 2002 and is headquartered in Tokyo, Japan.'}]\"}, {'id': 'c1291424-a8b0-4cc0-b9b9-357a04c2e17d', 'symbol': 'SMFG', 'cik': '1022837', 'step': '1', 'description': 'Biography of Key Executives', 'insertedDate': '2023-08-06', 'pibData': '[{\\'name\\': \\'Naoki  Tamura\\', \\'title\\': \\'Senior Managing Executive Officer & Sr. MD of Retail Bus. Division\\', \\'biography\\': \\'Naoki Tamura is an Executive Officer at Tokuyama Corp. He has held various executive positions at SMBC and SMFG. He is also a Senior Managing Executive Officer at Sumitomo Mitsui Financial Group. Naoki Tamura has a background in finance and has experience in the retail banking industry. He is known for his expertise in financial services and has been involved in technology-enabled innovation in the financial sector. He has also served as a director and chairman in various companies.\\'}, {\\'name\\': \\'Yoshihiro  Hyakutome\\', \\'title\\': \\'Senior Managing Executive Officer & Group Chief Compliance Officer\\', \\'biography\\': \\'The summary provides information about Yoshihiro Hyakutome, who is currently the Director & Compliance Head at Sumitomo Mitsui Banking Corp. He has been working as a Senior Managing Executive Officer at Sumitomo Mitsui Banking Corporation for 4 years. He is also on the board of the Japanese Chamber of Commerce & Industry of New York, Inc. Additionally, the summary mentions his role as the Group Chief Compliance Officer at Sumitomo Mitsui Financial Group, Inc. and his position as the CEO of the Americas Division at Sumitomo Mitsui Banking Corporation.\\'}, {\\'name\\': \\'Mr. Toru  Nakashima\\', \\'title\\': \\'Senior Managing Executive Officer, Group Chief Financial Officer, CSO & Director\\', \\'biography\\': \\'The Noguchi Museum holds copyrighted materials that require permission for use. George Nakashima was a woodworker, furniture maker, and architect. Toru Nakashima is the Group CFO and Director at Sumitomo Mitsui Financial Group. Isamu Noguchi wrote an essay from a prison camp during World War II. Toru Nakashima is a Senior Managing Executive Officer at Sumitomo Mitsui Banking Corporation. Sumitomo Mitsui Financial Group offers various financial services. Toru Nakashima is also an Executive Director at Goodman. There is a book on George Nakashima written by his daughter. Toru Nakashima serves as the Group CFO, Senior Managing Executive Officer, Group CSO, and Director at Sumitomo Mitsui Financial Group. The highest stakes action in sports is the business side. The Chief Financial Officer (CFO) is responsible for managing the financial actions of a company. There is overlap between the responsibilities of executive directors and managing directors. Katsunori Tanizaki is a colleague of Toru Nakashima at SMBC Nikko Securities.\\'}, {\\'name\\': \\'Mr. Katsunori  Tanizaki\\', \\'title\\': \\'Senior Managing Corporation Executive Officer & Group CDIO\\', \\'biography\\': \"Katsunori Tanizaki is a Senior Managing Executive Officer and Group Chief Digital Innovation Officer at Sumitomo Mitsui Financial Group. He has extensive experience in information technology and has held various executive roles within the company. Tanizaki joined Sumitomo Bank in 1982 and has been with the company since its merger with Sakura Bank in 2001. He is responsible for modernizing the group\\'s IT infrastructure and upskilling employees. Tanizaki is also a director and senior managing executive officer at Sumitomo Mitsui Banking Corporation.\"}, {\\'name\\': \\'Jun  Okahashi\\', \\'title\\': \\'Gen. Mang. of Financial & Accounting Department\\', \\'biography\\': \\'The summary provides information about Jun Okahashi, who is the General Manager of the Financial & Accounting Department at Sumitomo Mitsui Inc. It also mentions that Jun Ohta is the CEO of Sumitomo Mitsui Financial Group and provides details about his tenure and compensation.\\'}, {\\'name\\': \\'Mr. Kohei  Ohashi\\', \\'title\\': \\'SVice President (IR Department)\\', \\'biography\\': \\'Kohei Horikoshi is a Japanese manga artist known for creating the series My Hero Academia. He has also worked on other manga series such as Ōmagadoki Dōbutsuen and Barrage. Horikoshi has had a fascination with the fine arts since childhood and began drawing at a young age. My Hero Academia has been translated into multiple languages, adapted into an anime series and films, and has several video games. Horikoshi has had a significant impact on the world of manga.\\'}, {\\'name\\': \\'Mr. Toshikazu  Yaku\\', \\'title\\': \\'Deputy Pres, Representative Executive Officer & Group CHRO\\', \\'biography\\': \\'The summary is not clear as it contains a mixture of unrelated information and does not provide a coherent summary of the text.\\'}, {\\'name\\': \\'Mr. Jun  Ohta\\', \\'title\\': \\'Pres, Group Chief Executive Officer & Director\\', \\'biography\\': \"The summary is about Jun Ohta, who currently holds the position of Executive President, CEO & Representative Director at Sumitomo Mitsui Financial Group, Inc. He has held various positions within the company, including Director and Senior Managing Executive Officer. Ohta has a background in applied physics and has served on various technical program committees. The summary also mentions Ohta\\'s involvement in a leadership change at the Japanese lender\\'s subsidiaries and his role as the Group Chief Executive Officer.\"}, {\\'name\\': \\'Mr. Masahiko  Oshima\\', \\'title\\': \\'Deputy Pres, Representative Executive Officer & Co-Head of Wholesale Bus. Unit\\', \\'biography\\': \\'The concise summary of the given text is that Masahiko Oshima is the Deputy President and Executive Officer, as well as the Co-Head of the Wholesale Business Unit at Sumitomo Mitsui Financial Group. He is also a Director and Representative Director at Sumitomo Mitsui Banking Corporation.\\'}, {\\'name\\': \\'Mr. Takashi  Kobayashi\\', \\'title\\': \\'Senior Managing Corporation Executive Officer & Group CHRO\\', \\'biography\\': \\'The summary is about multiple individuals named Takashi Kobayashi who hold various positions in different companies and organizations. It mentions their current roles, past positions, and some personal information. The summary also includes information about a haiku poet named Issa.\\'}, {\\'name\\': \\'Mr. Kimio  Matsuura\\', \\'title\\': \\'Senior Managing Executive Officer & GM of Joint Bus. Division - Wholesale Bus. Division\\', \\'biography\\': \\'The summary states that Kimio Matsuura is a former Senior Managing Executive Officer at Sumitomo Mitsui Financial Group. It mentions his compensation, career history, education, and memberships. The summary also discusses the importance of executive bios as marketing materials and provides tips on how to write a compelling bio. It includes information about other executives at Sumitomo Mitsui Inc and their roles. Additionally, it mentions the portrayal of Kimiyo Matsumoto in Kamen Rider Kabuto and Kamen Rider Den-O.\\'}, {\\'name\\': \\'Fumihiko  Ito\\', \\'title\\': \\'Senior Managing Corporation Executive Officer, Group Chief Financial Officer, Group CSO & Director\\', \\'biography\\': \"The summary provides information about various individuals and their roles within Sumitomo Mitsui Financial Group (SMFG). Teiko Kudo is a Director and Senior Managing Executive Officer, while Fumihiko Ito is a Group CFO and Group CSO. SMFG established a Corporate Sustainability Committee in 2018, and Fumihiko Ito has held various positions within the company since 2020. The summary also mentions other directors and provides information about Fumihiko Ito\\'s education and career history. Additionally, it briefly mentions the services offered by SMFG and provides contact information for Fumihiko Ito.\"}, {\\'name\\': \\'Fumihiko  Ito\\', \\'title\\': \\'Senior Managing Corporation Executive Officer & Group Chief Financial Officer and Group CSO\\', \\'biography\\': \\'The Management Committee of Sumitomo Mitsui Banking Corporation (SMBC) Group includes Fumihiko Ito as the Managing Executive Officer and Teiko Kudo as the Senior Managing Executive Officer. SMBC Group established the Corporate Sustainability Committee in 2018 to promote sustainability. Fumihiko Ito has held various positions within the company, including Group Chief Financial Officer and Group Chief Strategy Officer. Sumitomo Mitsui Financial Group Inc (SMFG) is a financial holding company that offers banking and financial services. The company also has a Chief Security Officer responsible for personnel and asset security. Fumihiko Maki is an architect known for his modernist designs. A Chief Financial Officer (CFO) is the highest-ranking financial professional in an organization. The Management Committee of SMBC Group also includes other executive officers with various roles.\\'}, {\\'name\\': \\'Jun  Uchikawa\\', \\'title\\': \\'Senior Managing Corporation Executive Officer, Group Chief Information Officer & GM of IT Planning Dept.\\', \\'biography\\': \\'The summary provides information about various individuals holding executive positions in different companies. It mentions Jun Uchikawa as the Senior Managing Corporate Exec Officer/Group CIO at Sumitomo Mitsui Finl Group. It also mentions Jun Ohta as the Chief Executive Officer, President, and Director of a company. Additionally, it includes information about Akimoto Uchikawa being elected as the next President and Chief Executive Officer of Teijin Limited. The summary also briefly mentions the responsibilities of a Chief Executive Officer (CEO) and the role of the board of directors in a corporation.\\'}, {\\'name\\': \\'Fumihiko  Ito\\', \\'title\\': \\'Senior Managing Executive Officer, Group Chief Financial Officer, Group CSO & Director\\', \\'biography\\': \"Hayashi Fumiko was a Japanese novelist known for her realistic stories about urban working-class life. She had a passion for literature from a young age and went on to become a successful writer. She lived an unsettled life until she settled in Onomichi and graduated from high school. Hayashi Fumiko\\'s works focused on the struggles and experiences of the working class in urban settings.\"}, {\\'name\\': \\'Mr. Takeshi  Mikami\\', \\'title\\': \\'Senior Managing Corporation Executive Officers & Group CAE\\', \\'biography\\': \"The summary includes various unrelated pieces of information, making it difficult to provide a concise summary. However, some key points mentioned include Takashi Murakami\\'s background and career as a contemporary artist, his influence from Jeff Koons, and his role as the founder and president of Kaikai Kiki Co., Ltd. Additionally, it mentions Takeshi Mikami\\'s position as a Senior Managing Corporate Executive Officer/Group CAE at Sumitomo Mitsui Financial Group.\"}]'}]\n"
     ]
    }
   ],
   "source": [
    "# Get the information about the company and list of all executives.\n",
    "# Check if we have already created record for Profile\n",
    "createPibIndex(SearchService, SearchKey, pibIndexName)\n",
    "step = \"1\"\n",
    "s1Data = []\n",
    "r = findPibData(SearchService, SearchKey, pibIndexName, cik, step, returnFields=['id', 'symbol', 'cik', 'step', 'description', 'insertedDate',\n",
    "                                                                   'pibData'])\n",
    "if r.get_count() == 0:\n",
    "    step1Profile = []\n",
    "    profile = companyProfile(apikey=apikey, symbol=symbol)\n",
    "    df = pd.DataFrame.from_dict(pd.json_normalize(profile))\n",
    "    sData = {\n",
    "            'id' : str(uuid.uuid4()),\n",
    "            'symbol': symbol,\n",
    "            'cik': cik,\n",
    "            'step': step,\n",
    "            'description': 'Company Profile',\n",
    "            'insertedDate': today.strftime(\"%Y-%m-%d\"),\n",
    "            'pibData' : str(df[['symbol', 'mktCap', 'companyName', 'currency', 'cik', 'isin', 'exchange', 'industry', 'sector', 'address', 'city', 'state', 'zip', 'website', 'description']].to_dict('records'))\n",
    "    }\n",
    "    step1Profile.append(sData)\n",
    "    s1Data.append(sData)\n",
    "    # Insert data into pibIndex\n",
    "    mergeDocs(SearchService, SearchKey, pibIndexName, step1Profile)\n",
    "\n",
    "    # Get the list of all executives and generate biography for each of them\n",
    "    executives = keyExecutives(apikey=apikey, symbol=symbol)\n",
    "    df = pd.DataFrame.from_dict(pd.json_normalize(executives),orient='columns')\n",
    "    df = df.drop_duplicates(subset='name', keep=\"first\")\n",
    "\n",
    "    step1Biography = []\n",
    "    tools = []\n",
    "    topK = 1\n",
    "    step1Executives = []\n",
    "    #### With the company profile and key executives, we can ask Bing Search to get the biography of the all Key executives and \n",
    "    # ask OpenAI to summarize it - Public Data\n",
    "    for executive in executives:\n",
    "        name = executive['name']\n",
    "        title = executive['title']\n",
    "        query = f\"Give me brief biography of {name} who is {title} at {symbol}. Biography should be restricted to {symbol} and summarize it as 2 paragraphs.\"\n",
    "        qaPromptTemplate = \"\"\"\n",
    "            Rephrase the following question asked by user to perform intelligent internet search\n",
    "            {query}\n",
    "            \"\"\"\n",
    "        optimizedPrompt = qaPromptTemplate.format(query=query)\n",
    "        qaPrompt = PromptTemplate(input_variables=[\"query\"],template=qaPromptTemplate)\n",
    "        chain = LLMChain(llm=llm, prompt=qaPrompt)\n",
    "        q = chain.run(query=query)\n",
    "        bingSearch = BingSearchAPIWrapper(k=20)\n",
    "        results = bingSearch.run(query=q)\n",
    "        chain = load_summarize_chain(llm, chain_type=\"stuff\")\n",
    "        docs = [Document(page_content=results)]\n",
    "        summary = chain.run(docs)\n",
    "        step1Executives.append({\n",
    "            \"name\": name,\n",
    "            \"title\": title,\n",
    "            \"biography\": summary\n",
    "        })\n",
    "\n",
    "    sData = {\n",
    "            'id' : str(uuid.uuid4()),\n",
    "            'symbol': symbol,\n",
    "            'cik': cik,\n",
    "            'step': step,\n",
    "            'description': 'Biography of Key Executives',\n",
    "            'insertedDate': today.strftime(\"%Y-%m-%d\"),\n",
    "            'pibData' : str(step1Executives)\n",
    "    }\n",
    "    step1Biography.append(sData)\n",
    "    s1Data.append(sData)\n",
    "    mergeDocs(SearchService, SearchKey, pibIndexName, step1Biography)\n",
    "else:\n",
    "    for s in r:\n",
    "        s1Data.append(\n",
    "            {\n",
    "                'id' : s['id'],\n",
    "                'symbol': s['symbol'],\n",
    "                'cik': s['cik'],\n",
    "                'step': s['step'],\n",
    "                'description': s['description'],\n",
    "                'insertedDate': s['insertedDate'],\n",
    "                'pibData' : s['pibData']\n",
    "            })\n",
    "\n",
    "print(s1Data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Paid Data -  Get the Earnings Call Transcript for each quarter for last 3 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search index earningcalls already exists\n"
     ]
    }
   ],
   "source": [
    "# Call the paid data (FMP) API\n",
    "# Get the earning call transcripts for the last 3 years and merge documents into the index.\n",
    "i = 0\n",
    "earningsData = []\n",
    "step = \"2\"\n",
    "earningIndexName = 'earningcalls'\n",
    "# Create the index if it does not exist\n",
    "createEarningCallIndex(SearchService, SearchKey, earningIndexName)\n",
    "# Get the list of all earning calls available\n",
    "earningCallDates = earningCallsAvailableDates(apikey=apikey, symbol=symbol)\n",
    "if len(earningCallDates) > 0:\n",
    "    quarter = earningCallDates[0][0]\n",
    "    year = earningCallDates[0][1]\n",
    "    r = findEarningCalls(SearchService, SearchKey, earningIndexName, symbol, str(quarter), str(year), returnFields=['id', 'symbol', \n",
    "                'quarter', 'year', 'callDate', 'content'])\n",
    "    if r.get_count() == 0:\n",
    "        insertEarningCall = []\n",
    "        earningTranscript = earningCallTranscript(apikey=apikey, symbol=symbol, year=str(year), quarter=quarter)\n",
    "        for transcript in earningTranscript:\n",
    "            symbol = transcript['symbol']\n",
    "            quarter = transcript['quarter']\n",
    "            year = transcript['year']\n",
    "            callDate = transcript['date']\n",
    "            content = transcript['content']\n",
    "            todayYmd = today.strftime(\"%Y-%m-%d\")\n",
    "            id = f\"{symbol}-{year}-{quarter}\"\n",
    "            earningRecord = {\n",
    "                \"id\": id,\n",
    "                \"symbol\": symbol,\n",
    "                \"quarter\": str(quarter),\n",
    "                \"year\": str(year),\n",
    "                \"callDate\": callDate,\n",
    "                \"content\": content,\n",
    "                #\"inserteddate\": datetime.now(central).strftime(\"%Y-%m-%d\"),\n",
    "            }\n",
    "            earningsData.append(earningRecord)\n",
    "            insertEarningCall.append(earningRecord)\n",
    "            mergeDocs(SearchService, SearchKey, earningIndexName, insertEarningCall)\n",
    "    else:\n",
    "        print(f\"Found {r.get_count()} records for {symbol} for {quarter} {year}\")\n",
    "        for s in r:\n",
    "            earningsData.append(\n",
    "                {\n",
    "                    'id' : s['id'],\n",
    "                    'symbol': s['symbol'],\n",
    "                    'quarter': s['quarter'],\n",
    "                    'year': s['year'],\n",
    "                    'callDate': s['callDate'],\n",
    "                    'content': s['content']\n",
    "                })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the transcripts as per Split Method, Chunk Size and Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's just use the latest earnings call transcript to create the documents that we want to use it for generative AI tasks\n",
    "if len(earningsData) > 0:\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=8000, chunk_overlap=1000)\n",
    "\n",
    "    print(\"Last earning call transcripts was on :\", earningsData[-1]['callDate'])\n",
    "    rawDocs = splitter.create_documents([earningsData[-1]['content']])\n",
    "    docs = splitter.split_documents(rawDocs)\n",
    "    print(\"Number of documents chunks generated from Call transcript : \", len(docs))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the vector store embedding data for chunked sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the last index of the earning call transcript in vector Index\n",
    "if len(earningsData) > 0:\n",
    "    earningVectorIndexName = 'latestearningcalls'\n",
    "    createEarningCallVectorIndex(SearchService, SearchKey, earningVectorIndexName)\n",
    "\n",
    "    indexEarningCallSections(OpenAiService, OpenAiKey, OpenAiVersion, OpenAiApiKey, SearchService, SearchKey,\n",
    "                            embeddingModelType, OpenAiEmbedding, earningVectorIndexName, docs,\n",
    "                            earningsData[-1]['callDate'], earningsData[-1]['symbol'], earningsData[-1]['year'],\n",
    "                            earningsData[-1]['quarter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAnswer(chainType, topK, symbol, quarter, year, question, indexName, llm):\n",
    "    r = performEarningCallCogSearch(OpenAiService, OpenAiKey, OpenAiVersion, OpenAiApiKey, SearchService, SearchKey, embeddingModelType, \n",
    "        OpenAiEmbedding, symbol, str(quarter), str(year), question, indexName, topK, returnFields=['id', 'symbol', 'quarter', 'year', 'callDate', 'content'])\n",
    "    \n",
    "    if r == None:\n",
    "        docs = [Document(page_content=\"No results found\")]\n",
    "    else :\n",
    "        docs = [\n",
    "            Document(page_content=doc['content'], metadata={\"id\": doc['id'], \"source\": ''})\n",
    "            for doc in r\n",
    "            ]\n",
    "    \n",
    "    if chainType == \"map_reduce\":\n",
    "        # Prompt for MapReduce\n",
    "        qaTemplate = \"\"\"Use the following portion of a long document to see if any of the text is relevant to answer the question.\n",
    "                Return any relevant text.\n",
    "                {context}\n",
    "                Question: {question}\n",
    "                Relevant text, if any :\"\"\"\n",
    "\n",
    "        qaPrompt = PromptTemplate(\n",
    "            template=qaTemplate, input_variables=[\"context\", \"question\"]\n",
    "        )\n",
    "\n",
    "        combinePromptTemplate = \"\"\"Given the following extracted parts of a long document and a question, create a final answer.\n",
    "        If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
    "        If the answer is not contained within the text below, say \\\"I don't know\\\".\n",
    "\n",
    "        QUESTION: {question}\n",
    "        =========\n",
    "        {summaries}\n",
    "        =========\n",
    "        \"\"\"\n",
    "        combinePrompt = PromptTemplate(\n",
    "            template=combinePromptTemplate, input_variables=[\"summaries\", \"question\"]\n",
    "        )\n",
    "\n",
    "        qaChain = load_qa_with_sources_chain(llm, chain_type=chainType, question_prompt=qaPrompt, \n",
    "                                            combine_prompt=combinePrompt, \n",
    "                                            return_intermediate_steps=True)\n",
    "        answer = qaChain({\"input_documents\": docs, \"question\": question})\n",
    "        outputAnswer = answer['output_text']\n",
    "\n",
    "    elif chainType == \"stuff\":\n",
    "    # Prompt for ChainType = Stuff\n",
    "        template = \"\"\"\n",
    "                Given the following extracted parts of a long document and a question, create a final answer. \n",
    "                If you don't know the answer, just say that you don't know. Don't try to make up an answer. \n",
    "                If the answer is not contained within the text below, say \\\"I don't know\\\".\n",
    "\n",
    "                QUESTION: {question}\n",
    "                =========\n",
    "                {summaries}\n",
    "                =========\n",
    "                \"\"\"\n",
    "        qaPrompt = PromptTemplate(template=template, input_variables=[\"summaries\", \"question\"])\n",
    "        qaChain = load_qa_with_sources_chain(llm, chain_type=chainType, prompt=qaPrompt)\n",
    "        answer = qaChain({\"input_documents\": docs, \"question\": question}, return_only_outputs=True)\n",
    "        outputAnswer = answer['output_text']\n",
    "    elif chainType == \"default\":\n",
    "        # Default Prompt\n",
    "        qaChain = load_qa_with_sources_chain(llm, chain_type=\"stuff\")\n",
    "        answer = qaChain({\"input_documents\": docs, \"question\": question}, return_only_outputs=True)\n",
    "        outputAnswer = answer['output_text']\n",
    "\n",
    "    return outputAnswer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top questions to ask during earning call - Let's see if we can find the answers to these questions in the transcripts\n",
    "- What are some of the current and looming threats to the business?\n",
    "- What is the debt level or debt ratio of the company right now?\n",
    "- How do you feel about the upcoming product launches or new products?\n",
    "- How are you managing or investing in your human capital?\n",
    "- How do you track the trends in your industry?\n",
    "- Are there major slowdowns in the production of goods?\n",
    "- How will you maintain or surpass this performance in the next few quarters?\n",
    "- What will your market look like in five years as a result of using your product or service?\n",
    "- How are you going to address the risks that will affect the long-term growth of the company?\n",
    "- How is the performance this quarter going to affect the long-term goals of the company?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another specific question to ask\n",
    "- Revenue: Provide key information about revenue for the quarter\n",
    "- Profitability: Provide key information about profits and losses (P&L) for the quarter\n",
    "- Industry Trends: Provide key information about industry trends for the quarter\n",
    "- Trend: Provide key information about business trends discussed on the call\n",
    "- Risk: Provide key information about risk discussed on the call\n",
    "- AI: Provide key information about AI discussed on the call\n",
    "- M&A: Provide any information about mergers and acquisitions (M&A) discussed on the call.\n",
    "- Guidance: Provide key information about guidance discussed on the call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since we have the lastest transcripts in the document format, let's summarize the information with following specific summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = findPibData(SearchService, SearchKey, pibIndexName, cik, step, returnFields=['id', 'symbol', 'cik', 'step', 'description', 'insertedDate',\n",
    "#                                                                    'pibData'])\n",
    "# s2Data = []\n",
    "# if r.get_count() == 0:\n",
    "\n",
    "#     earningCallQa = []\n",
    "#     commonQuestions = [\n",
    "#         \"What are some of the current and looming threats to the business?\",\n",
    "#         \"What is the debt level or debt ratio of the company right now?\",\n",
    "#         \"How do you feel about the upcoming product launches or new products?\",\n",
    "#         \"How are you managing or investing in your human capital?\",\n",
    "#         \"How do you track the trends in your industry?\",\n",
    "#         \"Are there major slowdowns in the production of goods?\",\n",
    "#         \"How will you maintain or surpass this performance in the next few quarters?\",\n",
    "#         \"What will your market look like in five years as a result of using your product or service?\",\n",
    "#         \"How are you going to address the risks that will affect the long-term growth of the company?\",\n",
    "#         \"How is the performance this quarter going to affect the long-term goals of the company?\"\n",
    "#     ]\n",
    "\n",
    "#     for question in commonQuestions:\n",
    "#         answer = findAnswer('map_reduce', 3, question, earningVectorIndexName)\n",
    "#         if \"I don't know\" not in answer:\n",
    "#             earningCallQa.append({\"question\": question, \"answer\": answer})\n",
    "\n",
    "#     commonQuestions = [\n",
    "#         \"Provide key information about revenue for the quarter\",\n",
    "#         \"Provide key information about profits and losses (P&L) for the quarter\",\n",
    "#         \"Provide key information about industry trends for the quarter\",\n",
    "#         \"Provide key information about business trends discussed on the call\",\n",
    "#         \"Provide key information about risk discussed on the call\",\n",
    "#         \"Provide key information about AI discussed on the call\",\n",
    "#         \"Provide any information about mergers and acquisitions (M&A) discussed on the call.\",\n",
    "#         \"Provide key information about guidance discussed on the call\"\n",
    "#     ]\n",
    "\n",
    "#     for question in commonQuestions:\n",
    "#         answer = findAnswer('map_reduce', 3, question, earningVectorIndexName)\n",
    "#         if \"I don't know\" not in answer:\n",
    "#             earningCallQa.append({\"question\": question, \"answer\": answer})\n",
    "\n",
    "#     # With the data indexed, let's summarize the information\n",
    "#     # While we are using the standard prompt by langchain, you can modify the prompt to suit your needs\n",
    "#     # 1. Financial Results Summary: Please provide a summary of the financial results.\n",
    "#     # 2. Business Highlights: Please provide a summary of the business highlights.\n",
    "#     # 3. Future Outlook: Please provide a summary of the future outlook.\n",
    "#     # 4. Business Risks: Please provide a summary of the business risks.\n",
    "#     # 5. Management Positive Sentiment: Please provide a summary of the what management is confident about.\n",
    "#     # 6. Management Negative Sentiment: Please provide a summary of the what management is concerned about.\n",
    "#     # 7. Future Growth Strategies : Please generate a concise and comprehensive strategies summary that includes the information in  bulleted format.\n",
    "#     # 8. Risk Increase: Please provide a summary of the risks that have increased.\n",
    "#     # 9. Risk Decrease: Please provide a summary of the risks that have decreased.\n",
    "#     # 10. Opportunity Increase: Please provide a summary of the opportunities that have increased.\n",
    "#     # 11. Opportunity Decrease: Please provide a summary of the opportunities that have decreased.\n",
    "#     commonSummary = [\n",
    "#         \"Financial Results\",\n",
    "#         \"Business Highlights\",\n",
    "#         \"Future Outlook\",\n",
    "#         \"Business Risks\",\n",
    "#         \"Management Positive Sentiment\",\n",
    "#         \"Management Negative Sentiment\",\n",
    "#         \"Future Growth Strategies\"\n",
    "#     ]\n",
    "\n",
    "#     promptTemplate = \"\"\"You are an AI assistant tasked with summarizing financial information from earning call transcript. \n",
    "#             Your summary should accurately capture the key information in the document while avoiding the omission of any domain-specific words. \n",
    "#             Please generate a concise and comprehensive summary on the following topics. \n",
    "#             {summarize}\n",
    "#             Please remember to use clear language and maintain the integrity of the original information without missing any important details:\n",
    "#             {text}\n",
    "#             \"\"\"\n",
    "#     for summary in commonSummary:\n",
    "#         customPrompt = PromptTemplate(template=promptTemplate.replace('{summarize}', summary), input_variables=[\"text\"])\n",
    "#         chainType = \"map_reduce\"\n",
    "#         summaryChain = load_summarize_chain(llmChat, chain_type=chainType, return_intermediate_steps=False, \n",
    "#                                     map_prompt=customPrompt, combine_prompt=customPrompt)\n",
    "#         summaryOutput = summaryChain({\"input_documents\": docs}, return_only_outputs=True)\n",
    "#         outputAnswer = summaryOutput['output_text'].replace('Summary:', '')\n",
    "#         if \"I don't know\" not in answer and len(outputAnswer) > 0:\n",
    "#             earningCallQa.append({\"question\": summary, \"answer\": outputAnswer})\n",
    "\n",
    "#     s2Data.append({\n",
    "#                 'id' : str(uuid.uuid4()),\n",
    "#                 'symbol': symbol,\n",
    "#                 'cik': cik,\n",
    "#                 'step': step,\n",
    "#                 'description': 'Earning Call Q&A',\n",
    "#                 'insertedDate': today.strftime(\"%Y-%m-%d\"),\n",
    "#                 'pibData' : str(earningCallQa)\n",
    "#         })\n",
    "#     mergeDocs(SearchService, SearchKey, pibIndexName, s2Data)\n",
    "# else:\n",
    "#     print('Found existing data')\n",
    "#     for s in r:\n",
    "#         s2Data.append(\n",
    "#             {\n",
    "#                 'id' : s['id'],\n",
    "#                 'symbol': s['symbol'],\n",
    "#                 'cik': s['cik'],\n",
    "#                 'step': s['step'],\n",
    "#                 'description': s['description'],\n",
    "#                 'insertedDate': s['insertedDate'],\n",
    "#                 'pibData' : s['pibData']\n",
    "#             })\n",
    "        \n",
    "# print(s2Data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In case if we wanted to see summary of summary, run code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For the chaintype of MapReduce and Refine, we can also get insight into intermediate steps of the pipeline.\n",
    "# # This way you can inspect the results from map_reduce chain type, each top similar chunk summary\n",
    "# intermediateSteps = summary['intermediate_steps']\n",
    "# for step in intermediateSteps:\n",
    "#         display(HTML(\"<b>Chunk Summary:</b> \" + step))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Paid Data - Press Releases - Get the Press Releases for last year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarizePressReleases(llm, docs):\n",
    "    promptTemplate = \"\"\"You are an AI assistant tasked with summarizing company's press releases and performing sentiments on those. \n",
    "                Your summary should accurately capture the key information in the press-releases while avoiding the omission of any domain-specific words. \n",
    "                Please generate a concise and comprehensive summary and sentiment with score with range of 0 to 10. \n",
    "                Your response should be in JSON object with following keys.  All JSON properties are required.\n",
    "                summary: \n",
    "                sentiment:\n",
    "                sentiment score: \n",
    "                {text}\n",
    "                \"\"\"\n",
    "    customPrompt = PromptTemplate(template=promptTemplate, input_variables=[\"text\"])\n",
    "    chainType = \"stuff\"\n",
    "    summaryChain = load_summarize_chain(llm, chain_type=chainType, prompt=customPrompt)\n",
    "    summary = summaryChain({\"input_documents\": docs}, return_only_outputs=True)\n",
    "    outputAnswer = summary['output_text']\n",
    "    return outputAnswer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing data\n",
      "[{'id': '0c6ade48-d697-4362-8ea9-3cd4543b96f4', 'symbol': 'SMFG', 'cik': '1022837', 'step': '3', 'description': 'Press Releases', 'insertedDate': '2023-08-06', 'pibData': '[{\\'releaseDate\\': \\'2023-04-27 06:30:00\\', \\'title\\': \"JEFFERIES AND SMBC EXPAND AND STRENGTHEN STRATEGIC ALLIANCE, BROADENING JOINT BUSINESS EFFORTS AND INCREASING SMBC\\'S EQUITY OWNERSHIP IN JEFFERIES\", \\'summary\\': \\'Jefferies Financial Group and Sumitomo Mitsui Financial Group have expanded their strategic alliance to collaborate on future corporate and investment banking business opportunities, as well as in equity sales and trading.\\', \\'sentiment\\': \\'Positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2022-12-22 09:00:00\\', \\'title\\': \\'SMBC NIKKO SECURITIES AMERICA, INC. EXPANDS EQUITY EXECUTION SERVICES GROUP WITH SEVERAL NEW HIRES\\', \\'summary\\': \\'SMBC Nikko Securities America, Inc., a member of SMBC Group, has made several significant hires in its equity execution business to expand its capabilities and presence in the Japanese and U.S. equities markets.\\', \\'sentiment\\': \\'Positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2022-11-08 09:00:00\\', \\'title\\': \\'SMBC NIKKO SECURITIES AMERICA, INC. APPOINTS RAFFI DAWSON AS MANAGING DIRECTOR, HEAD OF STRUCTURED FINANCE GROUP\\', \\'summary\\': \\'SMBC Nikko Securities America, Inc. has appointed Raffi Dawson as the Managing Director and Head of Structured Finance Group.\\', \\'sentiment\\': \\'Positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2022-10-19 09:00:00\\', \\'title\\': \\'SMBC CONTINUES GROWTH WITH NEW HUMAN RESOURCES, STRATEGY & TRANSFORMATION APPOINTMENTS\\', \\'summary\\': \\'SMBC announces new appointments in human resources, strategy, and transformation, signaling continued growth.\\', \\'sentiment\\': \\'positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2022-10-04 09:00:00\\', \\'title\\': \\'SMBC APPOINTS RICK DAVISON AS CHIEF FINANCIAL OFFICER\\', \\'summary\\': \\'SMBC has appointed Rick Davison as Chief Financial Officer.\\', \\'sentiment\\': \\'Neutral\\', \\'sentimentScore\\': 5.5}, {\\'releaseDate\\': \\'2022-09-14 09:00:00\\', \\'title\\': \\'SMBC NIKKO SECURITIES AMERICA APPOINTS JOSEPH A. LAVORGNA AS NEW CHIEF ECONOMIST\\', \\'summary\\': \\'SMBC Nikko Securities America has appointed Joseph A. LaVorgna as its new Chief Economist.\\', \\'sentiment\\': \\'positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2022-08-24 09:00:00\\', \\'title\\': \\'SMBC GROUP TO LAUNCH JENIUS BANK™, A NEW DIGITAL CONSUMER BANKING BUSINESS IN THE U.S.\\', \\'summary\\': \\'SMBC Group is set to launch Jenius Bank, a new digital consumer banking business in the U.S.\\', \\'sentiment\\': \\'positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2022-08-23 09:00:00\\', \\'title\\': \"SMBC LATIN AMERICA CLOSES LANDMARK RENEWABLES TRANSACTION WITH $710 MILLION BOND ISSUANCE, ONE OF THE LARGEST PRIVATE PLACEMENT IN REGION\\'S RECENT HISTORY\", \\'summary\\': \\'SMBC Latin America has successfully closed a landmark renewables transaction with a $710 million bond issuance.\\', \\'sentiment\\': \\'positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2022-08-11 09:00:00\\', \\'title\\': \\'SMBC NIKKO SECURITIES AMERICA, INC. FURTHER STRENGTHENS ITS DEBT CAPITAL MARKETS TEAM; HIRES TOM BAUSANO AS MANAGING DIRECTOR AND CO-HEAD\\', \\'summary\\': \\'SMBC Nikko Securities America, Inc. has hired Tom Bausano as Managing Director and Co-Head of its Debt Capital Markets team.\\', \\'sentiment\\': \\'Positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2022-06-28 09:30:00\\', \\'title\\': \\'MARATHON CAPITAL AND SUMITOMO MITSUI BANKING CORPORATION FORM STRATEGIC PARTNERSHIP\\', \\'summary\\': \\'Marathon Capital, LLC has entered into a strategic collaboration agreement with Sumitomo Mitsui Banking Corporation (SMBC) to expand their reach and service offerings, providing comprehensive strategic and financial support for global energy transition goals.\\', \\'sentiment\\': \\'Positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2022-04-29 10:00:00\\', \\'title\\': \\'SMBC APPOINTS DEBBIE FREER CHIEF OPERATING OFFICER\\', \\'summary\\': \\'SMBC has appointed Debbie Freer as Chief Operating Officer.\\', \\'sentiment\\': \\'Neutral\\', \\'sentimentScore\\': 5.0}, {\\'releaseDate\\': \\'2022-04-19 08:00:00\\', \\'title\\': \\'SMBC WELCOMES HIROFUMI OTSUKA AS NEW CHIEF EXECUTIVE OFFICER OF SMBC AMERICAS DIVISION AND PRESIDENT AND CEO OF SMBC AMERICAS HOLDINGS\\', \\'summary\\': \\'SMBC has appointed Hirofumi Otsuka as the new Chief Executive Officer of SMBC Americas Division and President and CEO of SMBC Americas Holdings.\\', \\'sentiment\\': \\'Neutral\\', \\'sentimentScore\\': 5.0}, {\\'releaseDate\\': \\'2021-09-28 10:16:00\\', \\'title\\': \\'SMBC NIKKO SECURITIES AMERICA, INC. HIRES INDUSTRY VETERAN SCOTT ASHBY\\', \\'summary\\': \\'SMBC Nikko Securities America, Inc. has hired industry veteran Scott Ashby.\\', \\'sentiment\\': \\'Neutral\\', \\'sentimentScore\\': 5}, {\\'releaseDate\\': \\'2021-06-08 11:40:00\\', \\'title\\': \\'RANDOLPH HABECK JOINS SMBC NIKKO SECURITIES AMERICA, INC. AS MANAGING DIRECTOR FOR DEBT SYNDICATE TEAM; BRINGS ADDED ESG FINANCING DEPTH\\', \\'summary\\': \\'Randolph Habeck has joined SMBC Nikko Securities America, Inc. as Managing Director for the Debt Syndicate Team, bringing added expertise in ESG financing.\\', \\'sentiment\\': \\'Positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2021-05-05 09:00:00\\', \\'title\\': \\'SMBC AMERICAS HOLDINGS, INC. ELECTS KEVIN G. CHAVERS AS INDEPENDENT DIRECTOR\\', \\'summary\\': \\'SMBC Americas Holdings, Inc. has elected Kevin G. Chavers as an independent director.\\', \\'sentiment\\': \\'Neutral\\', \\'sentimentScore\\': 5.0}]'}]\n"
     ]
    }
   ],
   "source": [
    "# For now we are calling API to get data, but otherwise we need to ensure the data is not persisted in our \n",
    "# index repository before calling again, if it is persisted then we need to delete it first\n",
    "step = \"3\"\n",
    "s3Data = []\n",
    "r = findPibData(SearchService, SearchKey, pibIndexName, cik, step, returnFields=['id', 'symbol', 'cik', 'step', 'description', 'insertedDate',\n",
    "                                                                   'pibData'])\n",
    "if r.get_count() == 0:\n",
    "    counter = 0\n",
    "    pressReleasesList = []\n",
    "    pressReleaseIndexName = 'pressreleases'\n",
    "    # Create the index if it does not exist\n",
    "    createPressReleaseIndex(SearchService, SearchKey, pressReleaseIndexName)\n",
    "    print(f\"Processing ticker : {symbol}\")\n",
    "    pr = pressReleases(apikey=apikey, symbol=symbol, limit=25)\n",
    "    for pressRelease in pr:\n",
    "        symbol = pressRelease['symbol']\n",
    "        releaseDate = pressRelease['date']\n",
    "        title = pressRelease['title']\n",
    "        content = pressRelease['text']\n",
    "        todayYmd = today.strftime(\"%Y-%m-%d\")\n",
    "        id = f\"{symbol}-{counter}\"\n",
    "        pressReleasesList.append({\n",
    "            \"id\": id,\n",
    "            \"symbol\": symbol,\n",
    "            \"releaseDate\": releaseDate,\n",
    "            \"title\": title,\n",
    "            \"content\": content,\n",
    "        })\n",
    "        counter = counter + 1\n",
    "\n",
    "    mergeDocs(SearchService, SearchKey, pressReleaseIndexName, pressReleasesList)\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=50)\n",
    "    rawPressReleasesDoc = [Document(page_content=t['content']) for t in pressReleasesList[:25]]\n",
    "    pressReleasesDocs = splitter.split_documents(rawPressReleasesDoc)\n",
    "    print(\"Number of documents chunks generated from Press releases : \", len(pressReleasesDocs))\n",
    "\n",
    "    pressReleasesPib = []\n",
    "    last25PressReleases = pressReleasesList[:25]\n",
    "    i = 0\n",
    "    for pDocs in pressReleasesDocs:\n",
    "        try:\n",
    "            outputAnswer = summarizePressReleases(llm, [pDocs])\n",
    "            jsonStep = json.loads(outputAnswer)\n",
    "            pressReleasesPib.append({\n",
    "                    \"releaseDate\": last25PressReleases[i]['releaseDate'],\n",
    "                    \"title\": last25PressReleases[i]['title'],\n",
    "                    \"summary\": jsonStep['summary'],\n",
    "                    \"sentiment\": jsonStep['sentiment'],\n",
    "                    \"sentimentScore\": jsonStep['sentiment score']\n",
    "            })\n",
    "            i = i + 1\n",
    "        except Exception as e:\n",
    "            i = i + 1\n",
    "            continue\n",
    "    \n",
    "    s3Data.append({\n",
    "                'id' : str(uuid.uuid4()),\n",
    "                'symbol': symbol,\n",
    "                'cik': cik,\n",
    "                'step': step,\n",
    "                'description': 'Press Releases',\n",
    "                'insertedDate': today.strftime(\"%Y-%m-%d\"),\n",
    "                'pibData' : str(pressReleasesPib)\n",
    "        })\n",
    "    mergeDocs(SearchService, SearchKey, pibIndexName, s3Data)\n",
    "else:\n",
    "    print('Found existing data')\n",
    "    for s in r:\n",
    "        s3Data.append(\n",
    "            {\n",
    "                'id' : s['id'],\n",
    "                'symbol': s['symbol'],\n",
    "                'cik': s['cik'],\n",
    "                'step': s['step'],\n",
    "                'description': s['description'],\n",
    "                'insertedDate': s['insertedDate'],\n",
    "                'pibData' : s['pibData']\n",
    "            })\n",
    "\n",
    "print(s3Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Paid Data - Get Stock News - Limit it to cover for current year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For now we are calling API to get data, but otherwise we need to ensure the data is not persisted in our \n",
    "# # index repository before calling again, if it is persisted then we need to delete it first\n",
    "# counter = 0\n",
    "# stockNewsList = []\n",
    "# stockNewsIndexName = 'stocknews'\n",
    "# # Create the index if it does not exist\n",
    "# createStockNewsIndex(SearchService, SearchKey, stockNewsIndexName)\n",
    "# print(f\"Processing ticker : {symbol}\")\n",
    "# sn = stockNews(apikey=apikey, tickers=symbol, limit=5000)\n",
    "# for news in sn:\n",
    "#     symbol = news['symbol']\n",
    "#     publishedDate = news['publishedDate']\n",
    "#     title = news['title']\n",
    "#     image = news['image']\n",
    "#     site = news['site']\n",
    "#     content = news['text']\n",
    "#     url = news['url']\n",
    "#     todayYmd = today.strftime(\"%Y-%m-%d\")\n",
    "#     id = f\"{symbol}-{todayYmd}-{counter}\"\n",
    "#     stockNewsList.append({\n",
    "#         \"id\": id,\n",
    "#         \"symbol\": symbol,\n",
    "#         \"publishedDate\": publishedDate,\n",
    "#         \"title\": title,\n",
    "#         \"image\": image,\n",
    "#         \"site\": site,\n",
    "#         \"content\": content,\n",
    "#         \"url\": url,\n",
    "#     })\n",
    "#     counter = counter + 1\n",
    "# mergeDocs(SearchService, SearchKey, stockNewsIndexName, stockNewsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Group our news by Date and summarize the content and sentimet per day\n",
    "# stocksDf = pd.DataFrame.from_dict(pd.json_normalize(stockNewsList))\n",
    "# stocksDf['publishedDate'] = pd.to_datetime(stocksDf['publishedDate']).dt.date\n",
    "# stocksNewsDailyDf = stocksDf.sort_values('publishedDate').groupby('publishedDate')['content'].apply('\\n'.join).reset_index()\n",
    "# splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=50)\n",
    "# rawNewsDocs = [Document(page_content=row['content']) for index, row in stocksNewsDailyDf.tail(10).iterrows()]\n",
    "# newsDocs = splitter.split_documents(rawNewsDocs)\n",
    "# print(\"Number of documents chunks generated from Press releases : \", len(newsDocs))\n",
    "\n",
    "# # With the data indexed, let's summarize the information\n",
    "# promptTemplate = \"\"\"You are an AI assistant tasked with summarizing news related to company and performing sentiments on those. \n",
    "#         Your summary should accurately capture the key information in the document while avoiding the omission of any domain-specific words. \n",
    "#         Please generate a concise and comprehensive summary and sentiment with score with range of 0 to 10. Your response should be in JSON format with following keys.\n",
    "#         summary: \n",
    "#         sentiment:\n",
    "#         sentiment score:\n",
    "#         Please remember to use clear language and maintain the integrity of the original information without missing any important details.\n",
    "#         {text}\n",
    "#         \"\"\"\n",
    "# customPrompt = PromptTemplate(template=promptTemplate, input_variables=[\"text\"])\n",
    "# chainType = \"map_reduce\"\n",
    "# summaryChain = load_summarize_chain(llm, chain_type=chainType, return_intermediate_steps=True, \n",
    "#                                     map_prompt=customPrompt, combine_prompt=customPrompt)\n",
    "# summary = summaryChain({\"input_documents\": newsDocs}, return_only_outputs=True)\n",
    "# outputAnswer = summary['output_text']\n",
    "# print(outputAnswer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For the chaintype of MapReduce and Refine, we can also get insight into intermediate steps of the pipeline.\n",
    "# # This way you can inspect the results from map_reduce chain type, each top similar chunk summary\n",
    "# intermediateSteps = summary['intermediate_steps']\n",
    "# for step in intermediateSteps:\n",
    "#         display(HTML(\"<b>Chunk Summary:</b> \" + step))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Public Data - Get the SEC Filings - Limit it to cover for last 3 year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "filingType = \"10-K\"\n",
    "secFilingsList = secFilings(apikey=apikey, symbol=symbol, filing_type=filingType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search index latestsecfilings already exists\n",
      "Latest SEC Filings for CIK :  73124  and Symbol :  NTRS  already processed\n"
     ]
    }
   ],
   "source": [
    "latestFilingDateTime = datetime.strptime(secFilingsList[0]['fillingDate'], '%Y-%m-%d %H:%M:%S')\n",
    "latestFilingDate = latestFilingDateTime.strftime(\"%Y-%m-%d\")\n",
    "filingYear = latestFilingDateTime.strftime(\"%Y\")\n",
    "filingMonth = int(latestFilingDateTime.strftime(\"%m\"))\n",
    "\n",
    "if filingMonth > 0 & filingMonth <= 3:\n",
    "    filingQuarter = 1\n",
    "elif filingMonth > 3 & filingMonth <= 6:\n",
    "    filingQuarter = 2\n",
    "elif filingMonth > 6 & filingMonth <= 9:\n",
    "    filingQuarter = 3\n",
    "else:\n",
    "    filingQuarter = 4\n",
    "\n",
    "\n",
    "secFilingIndexName = 'secdata'\n",
    "secFilingList = []\n",
    "dt = pd.to_datetime(datetime.now(), format='%Y/%m/%d')\n",
    "dt1 = pd.to_datetime(latestFilingDate, format='%Y/%m/%d')\n",
    "totalDays = (dt-dt1).days\n",
    "if totalDays < 31:\n",
    "    skipIndicies = False\n",
    "else:\n",
    "    skipIndicies = True\n",
    "emptyBody = {\n",
    "        \"values\": [\n",
    "            {\n",
    "                \"recordId\": 0,\n",
    "                \"data\": {\n",
    "                    \"text\": \"\"\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "}\n",
    "\n",
    "secExtractBody = {\n",
    "    \"values\": [\n",
    "        {\n",
    "            \"recordId\": 0,\n",
    "            \"data\": {\n",
    "                \"text\": {\n",
    "                    \"edgar_crawler\": {\n",
    "                        \"start_year\": int(filingYear),\n",
    "                        \"end_year\": int(filingYear),\n",
    "                        \"quarters\": [filingQuarter],\n",
    "                        \"filing_types\": [\n",
    "                            \"10-K\"\n",
    "                        ],\n",
    "                        \"cik_tickers\": [cik],\n",
    "                        \"user_agent\": \"Your name (your email)\",\n",
    "                        \"raw_filings_folder\": \"RAW_FILINGS\",\n",
    "                        \"indices_folder\": \"INDICES\",\n",
    "                        \"filings_metadata_file\": \"FILINGS_METADATA.csv\",\n",
    "                        \"skip_present_indices\": skipIndicies,\n",
    "                    },\n",
    "                    \"extract_items\": {\n",
    "                        \"raw_filings_folder\": \"RAW_FILINGS\",\n",
    "                        \"extracted_filings_folder\": \"EXTRACTED_FILINGS\",\n",
    "                        \"filings_metadata_file\": \"FILINGS_METADATA.csv\",\n",
    "                        \"items_to_extract\": [\"1\",\"1A\",\"1B\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"7A\",\"8\",\"9\",\"9A\",\"9B\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\"],\n",
    "                        \"remove_tables\": False,\n",
    "                        \"skip_extracted_filings\": False\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Check if we have already processed the latest filing, if yes then skip\n",
    "createSecFilingIndex(SearchService, SearchKey, secFilingIndexName)\n",
    "r = findSecFiling(SearchService, SearchKey, secFilingIndexName, cik, filingType, latestFilingDate, returnFields=['id', 'cik', 'company', 'filingType', 'filingDate',\n",
    "                                                                                                                 'periodOfReport', 'sic', 'stateOfInc', 'fiscalYearEnd',\n",
    "                                                                                                                 'filingHtmlIndex', 'htmFilingLink', 'completeTextFilingLink',\n",
    "                                                                                                                 'item1', 'item1A', 'item1B', 'item2', 'item3', 'item4', 'item5',\n",
    "                                                                                                                 'item6', 'item7', 'item7A', 'item8', 'item9', 'item9A', 'item9B',\n",
    "                                                                                                                 'item10', 'item11', 'item12', 'item13', 'item14', 'item15',\n",
    "                                                                                                                 'sourcefile'])\n",
    "if r.get_count() == 0:\n",
    "    # Call Azure Function to perform Web-scraping and store the JSON in our blob\n",
    "    secExtract = requests.post(SecExtractionUrl, json = secExtractBody)\n",
    "    # Once the JSON is created, call the function to process the JSON and store the data in our index\n",
    "    docPersistUrl = SecDocPersistUrl + \"&indexType=cogsearchvs&indexName=\" + secFilingIndexName + \"&embeddingModelType=\" + embeddingModelType\n",
    "    secPersist = requests.post(docPersistUrl, json = emptyBody)\n",
    "    r = findSecFiling(SearchService, SearchKey, secFilingIndexName, cik, filingType, latestFilingDate, returnFields=['id', 'cik', 'company', 'filingType', 'filingDate',\n",
    "                                                                                                                 'periodOfReport', 'sic', 'stateOfInc', 'fiscalYearEnd',\n",
    "                                                                                                                 'filingHtmlIndex', 'htmFilingLink', 'completeTextFilingLink',\n",
    "                                                                                                                 'item1', 'item1A', 'item1B', 'item2', 'item3', 'item4', 'item5',\n",
    "                                                                                                                 'item6', 'item7', 'item7A', 'item8', 'item9', 'item9A', 'item9B',\n",
    "                                                                                                                 'item10', 'item11', 'item12', 'item13', 'item14', 'item15',\n",
    "                                                                                                                 'sourcefile'])\n",
    "\n",
    "lastSecData = ''\n",
    "# Retrieve the latest filing from our index\n",
    "for filing in r:\n",
    "    lastSecData = filing['item1'] + '\\n' + filing['item1A'] + '\\n' + filing['item1B'] + '\\n' + filing['item2'] + '\\n' + filing['item3'] + '\\n' + filing['item4'] + '\\n' + \\\n",
    "                filing['item5'] + '\\n' + filing['item6'] + '\\n' + filing['item7'] + '\\n' + filing['item7A'] + '\\n' + filing['item8'] + '\\n' + \\\n",
    "                filing['item9'] + '\\n' + filing['item9A'] + '\\n' + filing['item9B'] + '\\n' + filing['item10'] + '\\n' + filing['item11'] + '\\n' + filing['item12'] + '\\n' + \\\n",
    "                filing['item13'] + '\\n' + filing['item14'] + '\\n' + filing['item15']\n",
    "\n",
    "    secFilingList.append({\n",
    "        \"id\": filing['id'],\n",
    "        \"cik\": filing['cik'],\n",
    "        \"company\": filing['company'],\n",
    "        \"filingType\": filing['filingType'],\n",
    "        \"filingDate\": filing['filingDate'],\n",
    "        \"periodOfReport\": filing['periodOfReport'],\n",
    "        \"sic\": filing['sic'],\n",
    "        \"stateOfInc\": filing['stateOfInc'],\n",
    "        \"fiscalYearEnd\": filing['fiscalYearEnd'],\n",
    "        \"filingHtmlIndex\": filing['filingHtmlIndex'],\n",
    "        \"completeTextFilingLink\": filing['completeTextFilingLink'],\n",
    "        \"item1\": filing['item1'],\n",
    "        \"item1A\": filing['item1A'],\n",
    "        \"item1B\": filing['item1B'],\n",
    "        \"item2\": filing['item2'],\n",
    "        \"item3\": filing['item3'],\n",
    "        \"item4\": filing['item4'],\n",
    "        \"item5\": filing['item5'],\n",
    "        \"item6\": filing['item6'],\n",
    "        \"item7\": filing['item7'],\n",
    "        \"item7A\": filing['item7A'],\n",
    "        \"item8\": filing['item8'],\n",
    "        \"item9\": filing['item9'],\n",
    "        \"item9A\": filing['item9A'],\n",
    "        \"item9B\": filing['item9B'],\n",
    "        \"item10\": filing['item10'],\n",
    "        \"item11\": filing['item11'],\n",
    "        \"item12\": filing['item12'],\n",
    "        \"item13\": filing['item13'],\n",
    "        \"item14\": filing['item14'],\n",
    "        \"item15\": filing['item15'],\n",
    "        \"sourcefile\": filing['sourcefile']\n",
    "    })\n",
    "\n",
    "# Check if we have already processed the latest filing, if yes then skip\n",
    "secFilingsVectorIndexName = 'latestsecfilings'\n",
    "createSecFilingsVectorIndex(SearchService, SearchKey, secFilingsVectorIndexName)\n",
    "r = findLatestSecFilings(SearchService, SearchKey, secFilingsVectorIndexName, cik, symbol, latestFilingDate, filingType, returnFields=['id', 'cik', 'symbol', 'latestFilingDate', 'filingType',\n",
    "                                                                                                                 'content'])\n",
    "if r.get_count() == 0:\n",
    "    print(\"Processing latest SEC Filings for CIK : \", cik, \" and Symbol : \", symbol)\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=8000, chunk_overlap=1000)\n",
    "    rawDocs = splitter.create_documents([lastSecData])\n",
    "    docs = splitter.split_documents(rawDocs)\n",
    "    print(\"Number of documents chunks generated from Last SEC Filings : \", len(docs))\n",
    "\n",
    "    # Store the last index of the earning call transcript in vector Index\n",
    "    indexSecFilingsSections(OpenAiService, OpenAiKey, OpenAiVersion, OpenAiApiKey, SearchService, SearchKey,\n",
    "                         embeddingModelType, OpenAiEmbedding, secFilingsVectorIndexName, docs, cik,\n",
    "                         symbol, latestFilingDate, filingType)\n",
    "else:\n",
    "    print(\"Latest SEC Filings for CIK : \", cik, \" and Symbol : \", symbol, \" already processed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item8 = secFilingList[0]['item8']\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=8000, chunk_overlap=0)\n",
    "rawItemDocs8 = [Document(page_content=item8, metadata={'source': ''})]\n",
    "itemDocs8 = splitter.split_documents(rawItemDocs8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getItem8Answer(llm, docs, question, chainType):\n",
    "    template = \"\"\"\n",
    "            You are an AI assistant tasked with answering questions from financial statements like income statement, cashflow and balance sheets. \n",
    "            The data that you are presented with is in table.\n",
    "            Your answer should accurately capture the key information in the document while avoiding the omission of any domain-specific words. \n",
    "            Please generate a concise and comprehensive information that includes details such as reporting year and amount in millions.\n",
    "            Ensure that it is easy to understand for business professionals and provides an accurate representation of the financial statement history. \n",
    "            \n",
    "            Please remember to use clear language and maintain the integrity of the original information without missing any important details\n",
    "\n",
    "            QUESTION: {question}\n",
    "            =========\n",
    "            {summaries}\n",
    "            =========\n",
    "            \"\"\"\n",
    "    qaPrompt = PromptTemplate(template=template, input_variables=[\"summaries\", \"question\"])\n",
    "    qaChain = load_qa_with_sources_chain(llm, chain_type=chainType, combine_prompt=qaPrompt)\n",
    "    answer = qaChain({\"input_documents\": docs, \"question\": question})\n",
    "    outputAnswer = answer['output_text']\n",
    "    return outputAnswer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reported revenue for 2021 is not provided in the given portion of the document.\n",
      "SOURCES:\n"
     ]
    }
   ],
   "source": [
    "print(getItem8Answer(llm, itemDocs8, \"What was the reported revenue for 2021?\", \"map_reduce\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateSummaries(docs):\n",
    "    chainType = \"map_reduce\"\n",
    "    summaryChain = load_summarize_chain(llm, chain_type=chainType)\n",
    "    summary = summaryChain({\"input_documents\": docs}, return_only_outputs=True)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4 data already exists in the index\n"
     ]
    }
   ],
   "source": [
    "step = \"4\"\n",
    "s4Data = []\n",
    "\n",
    "r = findPibData(SearchService, SearchKey, pibIndexName, cik, step, returnFields=['id', 'symbol', 'cik', 'step', 'description', 'insertedDate',\n",
    "                                                                   'pibData'])\n",
    "\n",
    "if r.get_count() == 0:\n",
    "        secFilingsPib = []\n",
    "\n",
    "        # For different section of extracted data, process summarization and generate common answers to questions\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size=8000, chunk_overlap=0)\n",
    "\n",
    "        # Item 1 - Describes the business of the company\n",
    "        rawItemDocs1 = [Document(page_content=secFilingList[0]['item1'])]\n",
    "        itemDocs1 = splitter.split_documents(rawItemDocs1)\n",
    "        print(\"Number of documents chunks generated from Item1 : \", len(itemDocs1))\n",
    "        summary1 = generateSummaries(itemDocs1)\n",
    "        outputAnswer1 = summary1['output_text']\n",
    "        secFilingsPib.append({\n",
    "                        \"section\": \"item1\",\n",
    "                        \"summaryType\": \"Business Description\",\n",
    "                        \"summary\": outputAnswer1\n",
    "                })\n",
    "\n",
    "        # Item 1A - Risk Factors\n",
    "        rawItemDocs2 = [Document(page_content=secFilingList[0]['item1A'])]\n",
    "        itemDocs2 = splitter.split_documents(rawItemDocs2)\n",
    "        print(\"Number of documents chunks generated from Item1A : \", len(itemDocs2))\n",
    "        summary2 = generateSummaries(itemDocs2)\n",
    "        outputAnswer2 = summary2['output_text']\n",
    "        secFilingsPib.append({\n",
    "                        \"section\": \"item1A\",\n",
    "                        \"summaryType\": \"Risk Factors\",\n",
    "                        \"summary\": outputAnswer2\n",
    "                })\n",
    "\n",
    "        rawItemDocs2 = [Document(page_content=secFilingList[0]['item3'])]\n",
    "        itemDocs2 = splitter.split_documents(rawItemDocs2)\n",
    "        print(\"Number of documents chunks generated from Item3 : \", len(itemDocs2))\n",
    "        summary2 = generateSummaries(itemDocs2)\n",
    "        outputAnswer2 = summary2['output_text']\n",
    "        secFilingsPib.append({\n",
    "                        \"section\": \"item3\",\n",
    "                        \"summaryType\": \"Legal Proceedings\",\n",
    "                        \"summary\": outputAnswer2\n",
    "                })\n",
    "\n",
    "        # Item 6 - Consolidated Financial Data\n",
    "        rawItemDocs3 = [Document(page_content=secFilingList[0]['item5'])]\n",
    "        itemDocs3 = splitter.split_documents(rawItemDocs3)\n",
    "        print(\"Number of documents chunks generated from Item5 : \", len(itemDocs3))\n",
    "        summary3 = generateSummaries(itemDocs3)\n",
    "        outputAnswer3 = summary3['output_text']\n",
    "        secFilingsPib.append({\n",
    "                        \"section\": \"item5\",\n",
    "                        \"summaryType\": \"Market\",\n",
    "                        \"summary\": outputAnswer3\n",
    "                })\n",
    "\n",
    "        # Item 7 - Management's Discussion and Analysis of Financial Condition and Results of Operations\n",
    "        rawItemDocs4 = [Document(page_content=secFilingList[0]['item7'])]\n",
    "        itemDocs4 = splitter.split_documents(rawItemDocs4)\n",
    "        print(\"Number of documents chunks generated from Item7 : \", len(itemDocs4))\n",
    "        summary4 = generateSummaries(itemDocs4)\n",
    "        outputAnswer4 = summary4['output_text']\n",
    "        secFilingsPib.append({\n",
    "                        \"section\": \"item7\",\n",
    "                        \"summaryType\": \"Management Discussion\",\n",
    "                        \"summary\": outputAnswer4\n",
    "                })\n",
    "\n",
    "        # Item 7a - Market risk disclosures\n",
    "        rawItemDocs5 = [Document(page_content=secFilingList[0]['item7A'])]\n",
    "        itemDocs5= splitter.split_documents(rawItemDocs5)\n",
    "        print(\"Number of documents chunks generated from Item7A : \", len(itemDocs5))\n",
    "        summary5 = generateSummaries(itemDocs5)\n",
    "        outputAnswer5 = summary5['output_text']\n",
    "        secFilingsPib.append({\n",
    "                        \"section\": \"item7A\",\n",
    "                        \"summaryType\": \"Risk Disclosures\",\n",
    "                        \"summary\": outputAnswer5\n",
    "                })\n",
    "\n",
    "        # Item 9 - Disagreements with accountants and changes in accounting\n",
    "        section9 = secFilingList[0]['item9'] + \"\\n \" + secFilingList[0]['item9A'] + \"\\n \" + secFilingList[0]['item9B']\n",
    "        rawItemDocs6 = [Document(page_content=section9)]\n",
    "        itemDocs6 = splitter.split_documents(rawItemDocs6)\n",
    "        print(\"Number of documents chunks generated from Item9 : \", len(itemDocs6))\n",
    "        summary6 = generateSummaries(itemDocs6)\n",
    "        outputAnswer6 = summary6['output_text']\n",
    "        secFilingsPib.append({\n",
    "                        \"section\": \"item9\",\n",
    "                        \"summaryType\": \"Accounting Disclosures\",\n",
    "                        \"summary\": outputAnswer6\n",
    "                })\n",
    "        \n",
    "        s4Data.append({\n",
    "                'id' : str(uuid.uuid4()),\n",
    "                'symbol': symbol,\n",
    "                'cik': cik,\n",
    "                'step': step,\n",
    "                'description': 'SEC Filings',\n",
    "                'insertedDate': today.strftime(\"%Y-%m-%d\"),\n",
    "                'pibData' : str(secFilingsPib)\n",
    "        })\n",
    "        mergeDocs(SearchService, SearchKey, pibIndexName, s4Data)\n",
    "else:\n",
    "        print(\"Step 4 data already exists in the index\")\n",
    "        for item in r:\n",
    "                s4Data.append({\n",
    "                        'id' : item['id'],\n",
    "                        'symbol': item['symbol'],\n",
    "                        'cik': item['cik'],\n",
    "                        'step': item['step'],\n",
    "                        'description': item['description'],\n",
    "                        'insertedDate': item['insertedDate'],\n",
    "                        'pibData' : item['pibData']\n",
    "                })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Private Data - Equity Research Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azure.search.documents import SearchClient\n",
    "# from azure.core.credentials import AzureKeyCredential\n",
    "# step = \"5\"\n",
    "# searchClient = SearchClient(endpoint=f\"https://{SearchService}.search.windows.net\",\n",
    "#         index_name=pibIndexName,\n",
    "#         credential=AzureKeyCredential(SearchKey))\n",
    "# r = searchClient.search(  \n",
    "#     search_text=\"\",\n",
    "#     filter=\"cik eq '\" + cik + \"' and step eq '\" + step + \"'\",\n",
    "#     select=[\"id\"],\n",
    "#     semantic_configuration_name=\"semanticConfig\",\n",
    "#     include_total_count=True\n",
    "# )\n",
    "# if r.get_count() > 0:\n",
    "#     for doc in r:\n",
    "#         searchClient.delete_documents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = \"5\"\n",
    "s5Data = []\n",
    "r = findPibData(SearchService, SearchKey, pibIndexName, cik, step, returnFields=['id', 'symbol', 'cik', 'step', 'description', 'insertedDate',\n",
    "                                                                   'pibData'])\n",
    "\n",
    "if r.get_count() == 0:\n",
    "    companyRating = rating(apikey=apikey, symbol=symbol)\n",
    "    fScore = financialScore(apikey=apikey, symbol=symbol)\n",
    "    esgScores = esgScore(apikey=apikey, symbol=symbol)\n",
    "    esgRating = esgRatings(apikey=apikey, symbol=symbol)\n",
    "    ugConsensus = upgradeDowngrades(apikey=apikey, symbol=symbol)\n",
    "    priceConsensus = priceTarget(apikey=apikey, symbol=symbol)\n",
    "    #ratingsDf = pd.DataFrame.from_dict(pd.json_normalize(companyRating))\n",
    "    researchReport = []\n",
    "\n",
    "    try:\n",
    "        researchReport.append({\n",
    "            \"key\": \"Overall Recommendation\",\n",
    "            \"value\": companyRating[0]['ratingRecommendation']\n",
    "        })\n",
    "        researchReport.append({\n",
    "            \"key\": \"DCF Recommendation\",\n",
    "            \"value\": companyRating[0]['ratingDetailsDCFRecommendation']\n",
    "        })\n",
    "        researchReport.append({\n",
    "            \"key\": \"ROE Recommendation\",\n",
    "            \"value\": companyRating[0]['ratingDetailsROERecommendation']\n",
    "        })\n",
    "        researchReport.append({\n",
    "            \"key\": \"ROA Recommendation\",\n",
    "            \"value\": companyRating[0]['ratingDetailsROARecommendation']\n",
    "        })\n",
    "        researchReport.append({\n",
    "            \"key\": \"PB Recommendation\",\n",
    "            \"value\": companyRating[0]['ratingDetailsPBRecommendation']\n",
    "        })\n",
    "        researchReport.append({\n",
    "            \"key\": \"PE Recommendation\",\n",
    "            \"value\": companyRating[0]['ratingDetailsPERecommendation']\n",
    "        })\n",
    "    except:\n",
    "        logging.info('No data found for companyRating')\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        researchReport.append({\n",
    "            \"key\": \"Altman ZScore\",\n",
    "            \"value\": fScore[0]['altmanZScore']\n",
    "        })\n",
    "        researchReport.append({\n",
    "            \"key\": \"Piotroski Score\",\n",
    "            \"value\": fScore[0]['piotroskiScore']\n",
    "        })\n",
    "    except:\n",
    "        logging.info('No data found for fScore')\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        researchReport.append({\n",
    "            \"key\": \"Environmental Score\",\n",
    "            \"value\": esgScores[0]['environmentalScore']\n",
    "        })\n",
    "        researchReport.append({\n",
    "            \"key\": \"Social Score\",\n",
    "            \"value\": esgScores[0]['socialScore']\n",
    "        })\n",
    "        researchReport.append({\n",
    "            \"key\": \"Governance Score\",\n",
    "            \"value\": esgScores[0]['governanceScore']\n",
    "        })\n",
    "        researchReport.append({\n",
    "            \"key\": \"ESG Score\",\n",
    "            \"value\": esgScores[0]['ESGScore']\n",
    "        })\n",
    "    except:\n",
    "        logging.info('No data found for esgScores')\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        researchReport.append({\n",
    "            \"key\": \"ESG RIsk Rating\",\n",
    "            \"value\": esgRating[0]['ESGRiskRating']\n",
    "        })\n",
    "    except:\n",
    "        logging.info('No data found for esgRating')\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        researchReport.append({\n",
    "            \"key\": \"Analyst Consensus Buy\",\n",
    "            \"value\": ugConsensus[0]['buy']\n",
    "        })\n",
    "        researchReport.append({\n",
    "            \"key\": \"Analyst Consensus Sell\",\n",
    "            \"value\": ugConsensus[0]['sell']\n",
    "        })\n",
    "        researchReport.append({\n",
    "            \"key\": \"Analyst Consensus Strong Buy\",\n",
    "            \"value\": ugConsensus[0]['strongBuy']\n",
    "        })\n",
    "        researchReport.append({\n",
    "            \"key\": \"Analyst Consensus Strong Sell\",\n",
    "            \"value\": ugConsensus[0]['strongSell']\n",
    "        })\n",
    "        researchReport.append({\n",
    "            \"key\": \"Analyst Consensus Hold\",\n",
    "            \"value\": ugConsensus[0]['hold']\n",
    "        })\n",
    "        researchReport.append({\n",
    "            \"key\": \"Analyst Consensus\",\n",
    "            \"value\": ugConsensus[0]['consensus']\n",
    "        })\n",
    "    except:\n",
    "        logging.info('No data found for ugConsensus')\n",
    "        pass\n",
    "    # researchReport.append({\n",
    "    #     \"key\": \"Price Target Consensus\",\n",
    "    #     \"value\": priceConsensus[0]['targetConsensus']\n",
    "    # })\n",
    "    # researchReport.append({\n",
    "    #     \"key\": \"Price Target Median\",\n",
    "    #     \"value\": priceConsensus[0]['targetMedian']\n",
    "    # })\n",
    "  \n",
    "    s5Data.append({\n",
    "                'id' : str(uuid.uuid4()),\n",
    "                'symbol': symbol,\n",
    "                'cik': cik,\n",
    "                'step': step,\n",
    "                'description': 'Research Report',\n",
    "                'insertedDate': today.strftime(\"%Y-%m-%d\"),\n",
    "                'pibData' : str(researchReport)\n",
    "        })\n",
    "    mergeDocs(SearchService, SearchKey, pibIndexName, s5Data)\n",
    "else:\n",
    "    for s in r:\n",
    "        s5Data.append(\n",
    "            {\n",
    "                'id' : s['id'],\n",
    "                'symbol': s['symbol'],\n",
    "                'cik': s['cik'],\n",
    "                'step': s['step'],\n",
    "                'description': s['description'],\n",
    "                'insertedDate': s['insertedDate'],\n",
    "                'pibData' : s['pibData']\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Paid Data - Investor Presentations - Financial Reports (Balance Sheet, Income Statement and Cash Flow) for last 3 years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'date': '2022-12-31', 'symbol': 'NTRS', 'reportedCurrency': 'USD', 'cik': '0000073124', 'fillingDate': '2023-02-28', 'acceptedDate': '2023-02-28 16:20:50', 'calendarYear': '2022', 'period': 'FY', 'revenue': 6761200000, 'costOfRevenue': 0, 'grossProfit': 6761200000, 'grossProfitRatio': 1, 'researchAndDevelopmentExpenses': 0, 'generalAndAdministrativeExpenses': 2685400000, 'sellingAndMarketingExpenses': 76700000, 'sellingGeneralAndAdministrativeExpenses': 2685400000, 'otherExpenses': 0, 'operatingExpenses': 0, 'costAndExpenses': 0, 'interestIncome': 2877700000, 'interestExpense': 990500000, 'depreciationAndAmortization': 553600000, 'ebitda': 2816000000, 'ebitdaratio': 0.4164941135, 'operatingIncome': 2262400000, 'operatingIncomeRatio': 0.3346151571, 'totalOtherIncomeExpensesNet': -496100000, 'incomeBeforeTax': 1766300000, 'incomeBeforeTaxRatio': 0.2612406082, 'incomeTaxExpense': 430300000, 'netIncome': 1336000000, 'netIncomeRatio': 0.1975980595, 'eps': 6.16, 'epsdiluted': 6.14, 'weightedAverageShsOut': 208309331, 'weightedAverageShsOutDil': 208867264, 'link': 'https://www.sec.gov/Archives/edgar/data/73124/000007312423000049/0000073124-23-000049-index.htm', 'finalLink': 'https://www.sec.gov/Archives/edgar/data/73124/000007312423000049/ntrs-20221231.htm'}, {'date': '2021-12-31', 'symbol': 'NTRS', 'reportedCurrency': 'USD', 'cik': '0000073124', 'fillingDate': '2022-02-28', 'acceptedDate': '2022-02-28 16:35:35', 'calendarYear': '2021', 'period': 'FY', 'revenue': 6464500000, 'costOfRevenue': 0, 'grossProfit': 6464500000, 'grossProfitRatio': 1, 'researchAndDevelopmentExpenses': 0, 'generalAndAdministrativeExpenses': 2442400000, 'sellingAndMarketingExpenses': 65500000, 'sellingGeneralAndAdministrativeExpenses': 2442400000, 'otherExpenses': 0, 'operatingExpenses': 0, 'costAndExpenses': 0, 'interestIncome': 1406500000, 'interestExpense': 23800000, 'depreciationAndAmortization': 515600000, 'ebitda': 2525700000, 'ebitdaratio': 0.3907030706, 'operatingIncome': 2010100000, 'operatingIncomeRatio': 0.3109443886, 'totalOtherIncomeExpensesNet': 0, 'incomeBeforeTax': 2010100000, 'incomeBeforeTaxRatio': 0.3109443886, 'incomeTaxExpense': 464800000, 'netIncome': 1545300000, 'netIncomeRatio': 0.2390440096, 'eps': 7.16, 'epsdiluted': 7.14, 'weightedAverageShsOut': 208076000, 'weightedAverageShsOutDil': 208899000, 'link': 'https://www.sec.gov/Archives/edgar/data/73124/000007312422000071/0000073124-22-000071-index.htm', 'finalLink': 'https://www.sec.gov/Archives/edgar/data/73124/000007312422000071/ntrs-20211231.htm'}, {'date': '2020-12-31', 'symbol': 'NTRS', 'reportedCurrency': 'USD', 'cik': '0000073124', 'fillingDate': '2021-02-23', 'acceptedDate': '2021-02-23 16:51:30', 'calendarYear': '2020', 'period': 'FY', 'revenue': 6100800000, 'costOfRevenue': 0, 'grossProfit': 6100800000, 'grossProfitRatio': 1, 'researchAndDevelopmentExpenses': 0, 'generalAndAdministrativeExpenses': 2334800000, 'sellingAndMarketingExpenses': 59200000, 'sellingGeneralAndAdministrativeExpenses': 2334800000, 'otherExpenses': 0, 'operatingExpenses': 0, 'costAndExpenses': 0, 'interestIncome': 1643500000, 'interestExpense': 200300000, 'depreciationAndAmortization': 500300000, 'ebitda': 2127900000, 'ebitdaratio': 0.3487903226, 'operatingIncome': 1627600000, 'operatingIncomeRatio': 0.266784684, 'totalOtherIncomeExpensesNet': 0, 'incomeBeforeTax': 1627600000, 'incomeBeforeTaxRatio': 0.266784684, 'incomeTaxExpense': 418300000, 'netIncome': 1209300000, 'netIncomeRatio': 0.1982199056, 'eps': 5.48, 'epsdiluted': 5.46, 'weightedAverageShsOut': 208319412, 'weightedAverageShsOutDil': 209007986, 'link': 'https://www.sec.gov/Archives/edgar/data/73124/000007312421000071/0000073124-21-000071-index.htm', 'finalLink': 'https://www.sec.gov/Archives/edgar/data/73124/000007312421000071/ntrs-20201231.htm'}, {'date': '2019-12-31', 'symbol': 'NTRS', 'reportedCurrency': 'USD', 'cik': '0000073124', 'fillingDate': '2020-02-25', 'acceptedDate': '2020-02-25 17:06:15', 'calendarYear': '2019', 'period': 'FY', 'revenue': 6073100000, 'costOfRevenue': 0, 'grossProfit': 6073100000, 'grossProfitRatio': 1, 'researchAndDevelopmentExpenses': 0, 'generalAndAdministrativeExpenses': 2214200000, 'sellingAndMarketingExpenses': 104200000, 'sellingGeneralAndAdministrativeExpenses': 2214200000, 'otherExpenses': 0, 'operatingExpenses': 0, 'costAndExpenses': 0, 'interestIncome': 2499900000, 'interestExpense': 822000000, 'depreciationAndAmortization': 458900000, 'ebitda': 2403000000, 'ebitdaratio': 0.3956793071, 'operatingIncome': 1944100000, 'operatingIncomeRatio': 0.3201165797, 'totalOtherIncomeExpensesNet': 0, 'incomeBeforeTax': 1944100000, 'incomeBeforeTaxRatio': 0.3201165797, 'incomeTaxExpense': 451900000, 'netIncome': 1492200000, 'netIncomeRatio': 0.2457064761, 'eps': 6.66, 'epsdiluted': 6.63, 'weightedAverageShsOut': 214525547, 'weightedAverageShsOutDil': 215601149, 'link': 'https://www.sec.gov/Archives/edgar/data/73124/000007312420000101/0000073124-20-000101-index.htm', 'finalLink': 'https://www.sec.gov/Archives/edgar/data/73124/000007312420000101/a201910-k.htm'}, {'date': '2018-12-31', 'symbol': 'NTRS', 'reportedCurrency': 'USD', 'cik': '0000073124', 'fillingDate': '2019-02-26', 'acceptedDate': '2019-02-26 16:37:47', 'calendarYear': '2018', 'period': 'FY', 'revenue': 5220800000, 'costOfRevenue': 0, 'grossProfit': 5220800000, 'grossProfitRatio': 1, 'researchAndDevelopmentExpenses': 0, 'generalAndAdministrativeExpenses': 2224600000, 'sellingAndMarketingExpenses': 98300000, 'sellingGeneralAndAdministrativeExpenses': 2322900000, 'otherExpenses': 2378100000, 'operatingExpenses': 4701000000, 'costAndExpenses': 0, 'interestIncome': 2321400000, 'interestExpense': 698700000, 'depreciationAndAmortization': 460900000, 'ebitda': 3117400000, 'ebitdaratio': 0.5971115537848606, 'operatingIncome': 0, 'operatingIncomeRatio': 0, 'totalOtherIncomeExpensesNet': 0, 'incomeBeforeTax': 1957800000, 'incomeBeforeTaxRatio': 0.375, 'incomeTaxExpense': 401400000, 'netIncome': 1556400000, 'netIncomeRatio': 0.29811523138216367, 'eps': 6.68, 'epsdiluted': 6.64, 'weightedAverageShsOut': 223148000, 'weightedAverageShsOutDil': 224488000, 'link': 'https://www.sec.gov/Archives/edgar/data/73124/000007312419000088/0000073124-19-000088-index.html', 'finalLink': 'https://www.sec.gov/Archives/edgar/data/73124/000007312419000088/a201810-k.htm'}, {'date': '2017-12-31', 'symbol': 'NTRS', 'reportedCurrency': 'USD', 'cik': '0000073124', 'fillingDate': '2018-02-27', 'acceptedDate': '2018-02-27 17:02:44', 'calendarYear': '2017', 'period': 'FY', 'revenue': 4706900000, 'costOfRevenue': 0, 'grossProfit': 4706900000, 'grossProfitRatio': 1, 'researchAndDevelopmentExpenses': 0, 'generalAndAdministrativeExpenses': 2131100000, 'sellingAndMarketingExpenses': 95400000, 'sellingGeneralAndAdministrativeExpenses': 2226500000, 'otherExpenses': 1855500000, 'operatingExpenses': 4082000000, 'costAndExpenses': 0, 'interestIncome': 1769400000, 'interestExpense': 340200000, 'depreciationAndAmortization': 421700000, 'ebitda': 2395800000, 'ebitdaratio': 0.5089974293059126, 'operatingIncome': 0, 'operatingIncomeRatio': 0, 'totalOtherIncomeExpensesNet': 0, 'incomeBeforeTax': 1633900000, 'incomeBeforeTaxRatio': 0.3471286834222099, 'incomeTaxExpense': 434900000, 'netIncome': 1199000000, 'netIncomeRatio': 0.25473241411544756, 'eps': 4.95, 'epsdiluted': 4.92, 'weightedAverageShsOut': 228258000, 'weightedAverageShsOutDil': 229654000, 'link': 'https://www.sec.gov/Archives/edgar/data/73124/000007312418000141/0000073124-18-000141-index.html', 'finalLink': 'https://www.sec.gov/Archives/edgar/data/73124/000007312418000141/a201710-k.htm'}, {'date': '2016-12-31', 'symbol': 'NTRS', 'reportedCurrency': 'USD', 'cik': '0000073124', 'fillingDate': '2017-02-28', 'acceptedDate': '2017-02-27 21:25:26', 'calendarYear': '2016', 'period': 'FY', 'revenue': 4334700000, 'costOfRevenue': 0, 'grossProfit': 4334700000, 'grossProfitRatio': 1, 'researchAndDevelopmentExpenses': 0, 'generalAndAdministrativeExpenses': 1909100000, 'sellingAndMarketingExpenses': 83600000, 'sellingGeneralAndAdministrativeExpenses': 1992700000, 'otherExpenses': 1634300000, 'operatingExpenses': 3627000000, 'costAndExpenses': 0, 'interestIncome': 1416900000, 'interestExpense': 182000000, 'depreciationAndAmortization': 373300000, 'ebitda': 2072400000, 'ebitdaratio': 0.4780953699217939, 'operatingIncome': 0, 'operatingIncomeRatio': 0, 'totalOtherIncomeExpensesNet': 0, 'incomeBeforeTax': 1517100000, 'incomeBeforeTaxRatio': 0.3499896186587307, 'incomeTaxExpense': 484600000, 'netIncome': 1032500000, 'netIncomeRatio': 0.23819410801208848, 'eps': 4.35, 'epsdiluted': 4.32, 'weightedAverageShsOut': 227581000, 'weightedAverageShsOutDil': 229151000, 'link': 'https://www.sec.gov/Archives/edgar/data/73124/000007312417000117/0000073124-17-000117-index.html', 'finalLink': 'https://www.sec.gov/Archives/edgar/data/73124/000007312417000117/a201610-k.htm'}, {'date': '2015-12-31', 'symbol': 'NTRS', 'reportedCurrency': 'USD', 'cik': '0000073124', 'fillingDate': '2016-02-29', 'acceptedDate': '2016-02-29 16:57:00', 'calendarYear': '2015', 'period': 'FY', 'revenue': 4106900000, 'costOfRevenue': 0, 'grossProfit': 4106900000, 'grossProfitRatio': 1, 'researchAndDevelopmentExpenses': 0, 'generalAndAdministrativeExpenses': 1794300000, 'sellingAndMarketingExpenses': 93200000, 'sellingGeneralAndAdministrativeExpenses': 1887500000, 'otherExpenses': 1504500000, 'operatingExpenses': 3392000000, 'costAndExpenses': 0, 'interestIncome': 1224000000, 'interestExpense': 153900000, 'depreciationAndAmortization': 351600000, 'ebitda': 1970500000, 'ebitdaratio': 0.47980228396113855, 'operatingIncome': 0, 'operatingIncomeRatio': 0, 'totalOtherIncomeExpensesNet': 0, 'incomeBeforeTax': 1465000000, 'incomeBeforeTaxRatio': 0.35671674499013856, 'incomeTaxExpense': 491200000, 'netIncome': 973800000, 'netIncomeRatio': 0.2371131510384962, 'eps': 4.03, 'epsdiluted': 3.99, 'weightedAverageShsOut': 232280000, 'weightedAverageShsOutDil': 234222000, 'link': 'https://www.sec.gov/Archives/edgar/data/73124/000007312416000324/0000073124-16-000324-index.html', 'finalLink': 'https://www.sec.gov/Archives/edgar/data/73124/000007312416000324/ntrs2015123110-k.htm'}, {'date': '2014-12-31', 'symbol': 'NTRS', 'reportedCurrency': 'USD', 'cik': '0000073124', 'fillingDate': '2015-02-26', 'acceptedDate': '2015-02-26 17:04:56', 'calendarYear': '2014', 'period': 'FY', 'revenue': 3756600000, 'costOfRevenue': 0, 'grossProfit': 3756600000, 'grossProfitRatio': 1, 'researchAndDevelopmentExpenses': 0, 'generalAndAdministrativeExpenses': 1747700000, 'sellingAndMarketingExpenses': 88000000, 'sellingGeneralAndAdministrativeExpenses': 1835700000, 'otherExpenses': 1486300000, 'operatingExpenses': 3322000000, 'costAndExpenses': 0, 'interestIncome': 1186900000, 'interestExpense': 181400000, 'depreciationAndAmortization': 335700000, 'ebitda': 1707300000, 'ebitdaratio': 0.4544801149976042, 'operatingIncome': 0, 'operatingIncomeRatio': 0, 'totalOtherIncomeExpensesNet': 0, 'incomeBeforeTax': 1190200000, 'incomeBeforeTaxRatio': 0.316829047542991, 'incomeTaxExpense': 378400000, 'netIncome': 811800000, 'netIncomeRatio': 0.21609966459032104, 'eps': 3.34, 'epsdiluted': 3.32, 'weightedAverageShsOut': 235830000, 'weightedAverageShsOutDil': 237720000, 'link': 'https://www.sec.gov/Archives/edgar/data/73124/000119312515065963/d802907d10k.htm', 'finalLink': 'https://www.sec.gov/Archives/edgar/data/73124/000119312515065963/d802907d10k.htm'}, {'date': '2013-12-31', 'symbol': 'NTRS', 'reportedCurrency': 'USD', 'cik': '0000073124', 'fillingDate': '2014-02-26', 'acceptedDate': '2014-02-26 16:43:54', 'calendarYear': '2013', 'period': 'FY', 'revenue': 3525200000, 'costOfRevenue': 0, 'grossProfit': 3525200000, 'grossProfitRatio': 1, 'researchAndDevelopmentExpenses': 0, 'generalAndAdministrativeExpenses': 1626700000, 'sellingAndMarketingExpenses': 91600000, 'sellingGeneralAndAdministrativeExpenses': 1718300000, 'otherExpenses': 1517700000, 'operatingExpenses': 3236000000, 'costAndExpenses': 0, 'interestIncome': 1155500000, 'interestExpense': 222400000, 'depreciationAndAmortization': 318500000, 'ebitda': 1616400000, 'ebitdaratio': 0.4585271757630773, 'operatingIncome': 0, 'operatingIncomeRatio': 0, 'totalOtherIncomeExpensesNet': 0, 'incomeBeforeTax': 1075500000, 'incomeBeforeTaxRatio': 0.3050890729603994, 'incomeTaxExpense': 344200000, 'netIncome': 731300000, 'netIncomeRatio': 0.20744922273913538, 'eps': 3.01, 'epsdiluted': 2.99, 'weightedAverageShsOut': 239265000, 'weightedAverageShsOutDil': 240555000, 'link': 'https://www.sec.gov/Archives/edgar/data/73124/000119312514069870/d619551d10k.htm', 'finalLink': 'https://www.sec.gov/Archives/edgar/data/73124/000119312514069870/d619551d10k.htm'}]\n"
     ]
    }
   ],
   "source": [
    "incomeStatement = incomeStatement(apikey=apikey, symbol=symbol, limit=10)\n",
    "print(incomeStatement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>symbol</th>\n",
       "      <th>Filing Date</th>\n",
       "      <th>Accepted Date</th>\n",
       "      <th>Calendar Year</th>\n",
       "      <th>Period</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Cost of Revenue</th>\n",
       "      <th>Gross Profit</th>\n",
       "      <th>Gross Profit Ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>Total Other Net Expenses</th>\n",
       "      <th>Income Before Tax</th>\n",
       "      <th>Income Before Tax Ratio</th>\n",
       "      <th>Income Tax Expenses</th>\n",
       "      <th>Net Income</th>\n",
       "      <th>Net Income Ratio</th>\n",
       "      <th>EPS</th>\n",
       "      <th>Diluted EPS</th>\n",
       "      <th>Outstanding Shares</th>\n",
       "      <th>Diluted Outstanding Shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>NTRS</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28 16:20:50</td>\n",
       "      <td>2022</td>\n",
       "      <td>FY</td>\n",
       "      <td>6761200000</td>\n",
       "      <td>0</td>\n",
       "      <td>6761200000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-496100000</td>\n",
       "      <td>1766300000</td>\n",
       "      <td>0.261241</td>\n",
       "      <td>430300000</td>\n",
       "      <td>1336000000</td>\n",
       "      <td>0.197598</td>\n",
       "      <td>6.16</td>\n",
       "      <td>6.14</td>\n",
       "      <td>208309331</td>\n",
       "      <td>208867264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>NTRS</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>2022-02-28 16:35:35</td>\n",
       "      <td>2021</td>\n",
       "      <td>FY</td>\n",
       "      <td>6464500000</td>\n",
       "      <td>0</td>\n",
       "      <td>6464500000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010100000</td>\n",
       "      <td>0.310944</td>\n",
       "      <td>464800000</td>\n",
       "      <td>1545300000</td>\n",
       "      <td>0.239044</td>\n",
       "      <td>7.16</td>\n",
       "      <td>7.14</td>\n",
       "      <td>208076000</td>\n",
       "      <td>208899000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>NTRS</td>\n",
       "      <td>2021-02-23</td>\n",
       "      <td>2021-02-23 16:51:30</td>\n",
       "      <td>2020</td>\n",
       "      <td>FY</td>\n",
       "      <td>6100800000</td>\n",
       "      <td>0</td>\n",
       "      <td>6100800000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1627600000</td>\n",
       "      <td>0.266785</td>\n",
       "      <td>418300000</td>\n",
       "      <td>1209300000</td>\n",
       "      <td>0.198220</td>\n",
       "      <td>5.48</td>\n",
       "      <td>5.46</td>\n",
       "      <td>208319412</td>\n",
       "      <td>209007986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>NTRS</td>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>2020-02-25 17:06:15</td>\n",
       "      <td>2019</td>\n",
       "      <td>FY</td>\n",
       "      <td>6073100000</td>\n",
       "      <td>0</td>\n",
       "      <td>6073100000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1944100000</td>\n",
       "      <td>0.320117</td>\n",
       "      <td>451900000</td>\n",
       "      <td>1492200000</td>\n",
       "      <td>0.245706</td>\n",
       "      <td>6.66</td>\n",
       "      <td>6.63</td>\n",
       "      <td>214525547</td>\n",
       "      <td>215601149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>NTRS</td>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>2019-02-26 16:37:47</td>\n",
       "      <td>2018</td>\n",
       "      <td>FY</td>\n",
       "      <td>5220800000</td>\n",
       "      <td>0</td>\n",
       "      <td>5220800000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1957800000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>401400000</td>\n",
       "      <td>1556400000</td>\n",
       "      <td>0.298115</td>\n",
       "      <td>6.68</td>\n",
       "      <td>6.64</td>\n",
       "      <td>223148000</td>\n",
       "      <td>224488000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>NTRS</td>\n",
       "      <td>2018-02-27</td>\n",
       "      <td>2018-02-27 17:02:44</td>\n",
       "      <td>2017</td>\n",
       "      <td>FY</td>\n",
       "      <td>4706900000</td>\n",
       "      <td>0</td>\n",
       "      <td>4706900000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1633900000</td>\n",
       "      <td>0.347129</td>\n",
       "      <td>434900000</td>\n",
       "      <td>1199000000</td>\n",
       "      <td>0.254732</td>\n",
       "      <td>4.95</td>\n",
       "      <td>4.92</td>\n",
       "      <td>228258000</td>\n",
       "      <td>229654000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>NTRS</td>\n",
       "      <td>2017-02-28</td>\n",
       "      <td>2017-02-27 21:25:26</td>\n",
       "      <td>2016</td>\n",
       "      <td>FY</td>\n",
       "      <td>4334700000</td>\n",
       "      <td>0</td>\n",
       "      <td>4334700000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1517100000</td>\n",
       "      <td>0.349990</td>\n",
       "      <td>484600000</td>\n",
       "      <td>1032500000</td>\n",
       "      <td>0.238194</td>\n",
       "      <td>4.35</td>\n",
       "      <td>4.32</td>\n",
       "      <td>227581000</td>\n",
       "      <td>229151000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>NTRS</td>\n",
       "      <td>2016-02-29</td>\n",
       "      <td>2016-02-29 16:57:00</td>\n",
       "      <td>2015</td>\n",
       "      <td>FY</td>\n",
       "      <td>4106900000</td>\n",
       "      <td>0</td>\n",
       "      <td>4106900000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1465000000</td>\n",
       "      <td>0.356717</td>\n",
       "      <td>491200000</td>\n",
       "      <td>973800000</td>\n",
       "      <td>0.237113</td>\n",
       "      <td>4.03</td>\n",
       "      <td>3.99</td>\n",
       "      <td>232280000</td>\n",
       "      <td>234222000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>NTRS</td>\n",
       "      <td>2015-02-26</td>\n",
       "      <td>2015-02-26 17:04:56</td>\n",
       "      <td>2014</td>\n",
       "      <td>FY</td>\n",
       "      <td>3756600000</td>\n",
       "      <td>0</td>\n",
       "      <td>3756600000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1190200000</td>\n",
       "      <td>0.316829</td>\n",
       "      <td>378400000</td>\n",
       "      <td>811800000</td>\n",
       "      <td>0.216100</td>\n",
       "      <td>3.34</td>\n",
       "      <td>3.32</td>\n",
       "      <td>235830000</td>\n",
       "      <td>237720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>NTRS</td>\n",
       "      <td>2014-02-26</td>\n",
       "      <td>2014-02-26 16:43:54</td>\n",
       "      <td>2013</td>\n",
       "      <td>FY</td>\n",
       "      <td>3525200000</td>\n",
       "      <td>0</td>\n",
       "      <td>3525200000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1075500000</td>\n",
       "      <td>0.305089</td>\n",
       "      <td>344200000</td>\n",
       "      <td>731300000</td>\n",
       "      <td>0.207449</td>\n",
       "      <td>3.01</td>\n",
       "      <td>2.99</td>\n",
       "      <td>239265000</td>\n",
       "      <td>240555000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date symbol Filing Date        Accepted Date Calendar Year Period  \\\n",
       "0 2022-12-31   NTRS  2023-02-28  2023-02-28 16:20:50          2022     FY   \n",
       "1 2021-12-31   NTRS  2022-02-28  2022-02-28 16:35:35          2021     FY   \n",
       "2 2020-12-31   NTRS  2021-02-23  2021-02-23 16:51:30          2020     FY   \n",
       "3 2019-12-31   NTRS  2020-02-25  2020-02-25 17:06:15          2019     FY   \n",
       "4 2018-12-31   NTRS  2019-02-26  2019-02-26 16:37:47          2018     FY   \n",
       "5 2017-12-31   NTRS  2018-02-27  2018-02-27 17:02:44          2017     FY   \n",
       "6 2016-12-31   NTRS  2017-02-28  2017-02-27 21:25:26          2016     FY   \n",
       "7 2015-12-31   NTRS  2016-02-29  2016-02-29 16:57:00          2015     FY   \n",
       "8 2014-12-31   NTRS  2015-02-26  2015-02-26 17:04:56          2014     FY   \n",
       "9 2013-12-31   NTRS  2014-02-26  2014-02-26 16:43:54          2013     FY   \n",
       "\n",
       "      Revenue Cost of Revenue Gross Profit Gross Profit Ratio  ...  \\\n",
       "0  6761200000               0   6761200000                  1  ...   \n",
       "1  6464500000               0   6464500000                  1  ...   \n",
       "2  6100800000               0   6100800000                  1  ...   \n",
       "3  6073100000               0   6073100000                  1  ...   \n",
       "4  5220800000               0   5220800000                  1  ...   \n",
       "5  4706900000               0   4706900000                  1  ...   \n",
       "6  4334700000               0   4334700000                  1  ...   \n",
       "7  4106900000               0   4106900000                  1  ...   \n",
       "8  3756600000               0   3756600000                  1  ...   \n",
       "9  3525200000               0   3525200000                  1  ...   \n",
       "\n",
       "  Total Other Net Expenses Income Before Tax Income Before Tax Ratio  \\\n",
       "0               -496100000        1766300000                0.261241   \n",
       "1                        0        2010100000                0.310944   \n",
       "2                        0        1627600000                0.266785   \n",
       "3                        0        1944100000                0.320117   \n",
       "4                        0        1957800000                0.375000   \n",
       "5                        0        1633900000                0.347129   \n",
       "6                        0        1517100000                0.349990   \n",
       "7                        0        1465000000                0.356717   \n",
       "8                        0        1190200000                0.316829   \n",
       "9                        0        1075500000                0.305089   \n",
       "\n",
       "  Income Tax Expenses  Net Income Net Income Ratio   EPS Diluted EPS  \\\n",
       "0           430300000  1336000000         0.197598  6.16        6.14   \n",
       "1           464800000  1545300000         0.239044  7.16        7.14   \n",
       "2           418300000  1209300000         0.198220  5.48        5.46   \n",
       "3           451900000  1492200000         0.245706  6.66        6.63   \n",
       "4           401400000  1556400000         0.298115  6.68        6.64   \n",
       "5           434900000  1199000000         0.254732  4.95        4.92   \n",
       "6           484600000  1032500000         0.238194  4.35        4.32   \n",
       "7           491200000   973800000         0.237113  4.03        3.99   \n",
       "8           378400000   811800000         0.216100  3.34        3.32   \n",
       "9           344200000   731300000         0.207449  3.01        2.99   \n",
       "\n",
       "  Outstanding Shares Diluted Outstanding Shares  \n",
       "0          208309331                  208867264  \n",
       "1          208076000                  208899000  \n",
       "2          208319412                  209007986  \n",
       "3          214525547                  215601149  \n",
       "4          223148000                  224488000  \n",
       "5          228258000                  229654000  \n",
       "6          227581000                  229151000  \n",
       "7          232280000                  234222000  \n",
       "8          235830000                  237720000  \n",
       "9          239265000                  240555000  \n",
       "\n",
       "[10 rows x 34 columns]"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incomeStmtDf = pd.read_json(json.dumps(incomeStatement))\n",
    "incomeStmtDf = incomeStmtDf[['date', 'symbol', 'fillingDate',\n",
    "       'acceptedDate', 'calendarYear', 'period', 'revenue', 'costOfRevenue',\n",
    "       'grossProfit', 'grossProfitRatio', 'researchAndDevelopmentExpenses',\n",
    "       'generalAndAdministrativeExpenses', 'sellingAndMarketingExpenses',\n",
    "       'sellingGeneralAndAdministrativeExpenses', 'otherExpenses',\n",
    "       'operatingExpenses', 'costAndExpenses', 'interestIncome',\n",
    "       'interestExpense', 'depreciationAndAmortization', 'ebitda',\n",
    "       'ebitdaratio', 'operatingIncome', 'operatingIncomeRatio',\n",
    "       'totalOtherIncomeExpensesNet', 'incomeBeforeTax',\n",
    "       'incomeBeforeTaxRatio', 'incomeTaxExpense', 'netIncome',\n",
    "       'netIncomeRatio', 'eps', 'epsdiluted', 'weightedAverageShsOut',\n",
    "       'weightedAverageShsOutDil']]\n",
    "incomeStmtDf.columns = [['date', 'symbol', 'Filing Date',\n",
    "       'Accepted Date', 'Calendar Year', 'Period', 'Revenue', 'Cost of Revenue',\n",
    "       'Gross Profit', 'Gross Profit Ratio', 'R&D Expenses',\n",
    "       'General Adminstrative Expenses', 'Selling and Marketing Expenses',\n",
    "       'Selling General Administrative Expenses', 'Other Expenses',\n",
    "       'Operating Expenses', 'Cost and Expenses', 'Interest Income',\n",
    "       'Interest Expense', 'Depreciation & Amortization', 'EBITDA',\n",
    "       'EBITDA Ratio', 'Operating Income', 'Operating Income Ratio',\n",
    "       'Total Other Net Expenses', 'Income Before Tax',\n",
    "       'Income Before Tax Ratio', 'Income Tax Expenses', 'Net Income',\n",
    "       'Net Income Ratio', 'EPS', 'Diluted EPS', 'Outstanding Shares',\n",
    "       'Diluted Outstanding Shares']]\n",
    "incomeStmtDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deletePibData(SearchService, SearchKey, pibIndexName, \"51143\", \"1\", returnFields=['id', 'symbol', 'cik', 'step', 'description', 'insertedDate',\n",
    "#                                                                       'pibData'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PROMPT_PREFIX = \"\"\"\n",
    "First set the pandas display options to show all the columns, get the column names, then answer the question.\n",
    "\"\"\"\n",
    "\n",
    "CSV_PROMPT_SUFFIX = \"\"\"\n",
    "- **ALWAYS** before giving the Final Answer, try another method. Then reflect on the answers of the two methods you did and ask yourself if it answers correctly the original question. If you are not sure, try another method.\n",
    "- If the methods tried do not give the same result, reflect and try again until you have two methods that have the same result. \n",
    "- If you still cannot arrive to a consistent result, say that you are not sure of the answer.\n",
    "- If you are sure of the correct answer, create a beautiful and thorough response using Markdown.\n",
    "- **DO NOT MAKE UP AN ANSWER OR USE PRIOR KNOWLEDGE, ONLY USE THE RESULTS OF THE CALCULATIONS YOU HAVE DONE**. \n",
    "- **ALWAYS**, as part of your \"Final Answer\", explain how you got to the answer on a section that starts with: \"\\n\\nExplanation:\\n\". In the explanation, mention the column names that you used to get to the final answer. \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to filter the dataframe to only include rows where the 'Calendar Year' column is 2022, and then sum the 'Revenue' column.\n",
      "\n",
      "Action: python_repl_ast\n",
      "Action Input: df[df[('Calendar Year',)] == 2022]['Revenue'].sum()\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mRevenue    6761200000\n",
      "dtype: int64\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe total revenue for the year 2022 is 6,761,200,000.\n",
      "\n",
      "Final Answer: 6,761,200,000\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "6,761,200,000\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_pandas_dataframe_agent\n",
    "from langchain.agents.agent_toolkits import create_python_agent\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.python import PythonREPL\n",
    "\n",
    "agent = create_pandas_dataframe_agent(llm,df=incomeStmtDf, verbose=True)\n",
    "\n",
    "Question = 'What is the total revenue for the year 2022?'\n",
    "#Question = 'How much did revenue increased in 2022 in comparision to 2021?'\n",
    "response = agent.run(Question) \n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
