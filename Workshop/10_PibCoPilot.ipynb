{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIB CoPilot\n",
    "PIBs are also used to create a pitchbook by assessing a company's strategy, competitive positioning, review of financial statements, industry dynamics, and trends within the industry. \n",
    "1. Company Overview and Executive Bio - A brief description of the company and its key executives with biographies.\n",
    "2. Conference calls: The same day a company issues its quarterly press release, it will also hold a conference call. On the call, analysts often learn details about management guidance. These conference calls are transcribed by several service providers and can be accessed by subscribers of large financial data providers.\n",
    "3. Press Release: Can be found in the investor relations section of most companies' websites and contains the financial statements which are used in forms 10-K and 10-Q. \n",
    "4. News: News articles that may affect a company's stock price or growth prospect would be something that analysts look into, particularly within a 6-12 month time horizon.\n",
    "5. SEC filings: These regulatory documents require a company to file Form 10-K and Form 10-Q with the SEC on an ongoing basis. Form 10-K is a financial overview and commentary for the last year, usually found on the company's website. Form 10-Q is similar to form 10-K, but it is a report for the last quarter instead of the previous year.\n",
    "6. Equity research reports: Look into key forecasts for metrics like Revenue, EBITDA, and EPS for the company or competing firms to form a consensus estimate. \n",
    "7. Investor Presentations: Companies provide historical information as an important foundation from which forecasts are made to guide key forecasting drivers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0 -  Pre-requsite and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "import json  \n",
    "import openai\n",
    "from Utilities.envVars import *\n",
    "import uuid\n",
    "# Set Search Service endpoint, index name, and API key from environment variables\n",
    "indexName = SearchIndex\n",
    "\n",
    "# Set OpenAI API key and endpoint\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = OpenAiVersion\n",
    "openai_api_key = OpenAiKey\n",
    "assert openai_api_key, \"ERROR: Azure OpenAI Key is missing\"\n",
    "openai.api_key = openai_api_key\n",
    "openAiEndPoint = f\"https://{OpenAiService}.openai.azure.com\"\n",
    "assert openAiEndPoint, \"ERROR: Azure OpenAI Endpoint is missing\"\n",
    "assert \"openai.azure.com\" in openAiEndPoint.lower(), \"ERROR: Azure OpenAI Endpoint should be in the form: \\n\\n\\t<your unique endpoint identifier>.openai.azure.com\"\n",
    "openai.api_base = openAiEndPoint\n",
    "davincimodel = OpenAiDavinci\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "embeddingModelType = \"azureopenai\"\n",
    "temperature = 0\n",
    "tokenLength = 1000\n",
    "symbol = 'AMZN'\n",
    "apikey = FmpKey\n",
    "os.environ['BING_SUBSCRIPTION_KEY'] = BingKey\n",
    "os.environ['BING_SEARCH_URL'] = BingUrl\n",
    "pibIndexName = 'pibdata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.llms.openai import AzureOpenAI, OpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from IPython.display import display, HTML\n",
    "from langchain.utilities import BingSearchAPIWrapper\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import pandas as pd\n",
    "from langchain.prompts import PromptTemplate\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import timedelta\n",
    "from Utilities.pibCopilot import indexDocs, createPressReleaseIndex, createStockNewsIndex, mergeDocs, createPibIndex, findPibData, findEarningCalls, deletePibData, performEarningCallCogSearch\n",
    "from Utilities.pibCopilot import indexEarningCallSections, createEarningCallVectorIndex, createEarningCallIndex, performCogSearch, createSecFilingIndex, findSecFiling\n",
    "import typing\n",
    "from Utilities.fmp import *\n",
    "from langchain.chat_models import AzureChatOpenAI, ChatOpenAI\n",
    "\n",
    "# Flexibility to change the call to OpenAI or Azure OpenAI\n",
    "\n",
    "if (embeddingModelType == 'azureopenai'):\n",
    "    openai.api_type = \"azure\"\n",
    "    openai.api_key = OpenAiKey\n",
    "    openai.api_version = OpenAiVersion\n",
    "    openai.api_base = OpenAiBase\n",
    "\n",
    "    llm = AzureOpenAI(deployment_name=OpenAiDavinci,\n",
    "            temperature=temperature,\n",
    "            openai_api_key=OpenAiKey,\n",
    "            max_tokens=tokenLength,\n",
    "            batch_size=10, \n",
    "            max_retries=12)\n",
    "    \n",
    "    llmChat = AzureChatOpenAI(\n",
    "                openai_api_base=openai.api_base,\n",
    "                openai_api_version=OpenAiVersion,\n",
    "                deployment_name=OpenAiChat16k,\n",
    "                temperature=temperature,\n",
    "                openai_api_key=OpenAiKey,\n",
    "                openai_api_type=\"azure\",\n",
    "                max_tokens=tokenLength)\n",
    "    \n",
    "    logging.info(\"LLM Setup done\")\n",
    "    embeddings = OpenAIEmbeddings(deployment=OpenAiEmbedding, chunk_size=1, openai_api_key=OpenAiKey)\n",
    "elif embeddingModelType == \"openai\":\n",
    "    openai.api_type = \"open_ai\"\n",
    "    openai.api_base = \"https://api.openai.com/v1\"\n",
    "    openai.api_version = '2020-11-07' \n",
    "    openai.api_key = OpenAiApiKey\n",
    "    llm = OpenAI(temperature=temperature,\n",
    "            openai_api_key=OpenAiApiKey,\n",
    "            max_tokens=tokenLength)\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=OpenAiApiKey)\n",
    "\n",
    "    llmChat = ChatOpenAI(temperature=temperature,\n",
    "        openai_api_key=OpenAiApiKey,\n",
    "        model_name=\"gpt-3.5-turbo\",\n",
    "        max_tokens=tokenLength)\n",
    "    \n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=OpenAiApiKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "central = timezone('US/Central')\n",
    "today = datetime.now(central)\n",
    "currentYear = today.year\n",
    "historicalDate = today - relativedelta(years=3)\n",
    "historicalYear = historicalDate.year\n",
    "historicalDate = historicalDate.strftime(\"%Y-%m-%d\")\n",
    "totalYears = currentYear - historicalYear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find CIK based on Symbol\n",
    "cik = str(int(searchCik(apikey=apikey, ticker=symbol)[0][\"companyCik\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#symbol: str = \"AAPL\"\n",
    "#cik = \"320193\"\n",
    "#symbols: typing.List[str] = [\"AAPL\", \"CSCO\", \"QQQQ\"]\n",
    "#exchange: str = \"NYSE\"\n",
    "#exchanges: typing.List[str] = [\"NYSE\", \"NASDAQ\"]\n",
    "#query: str = \"AA\"\n",
    "#limit: int = 3\n",
    "#period: str = \"quarter\"\n",
    "#download: bool = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Paid Data - Company Profile and Key Executives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search index pibdata already exists\n",
      "Total docs: 1\n",
      "\tIndexed 1 sections, 1 succeeded\n",
      "Total docs: 1\n",
      "\tIndexed 1 sections, 1 succeeded\n",
      "[{'id': '27368c39-e139-47db-8888-6b5a12563bd5', 'symbol': 'AMZN', 'cik': '1018724', 'step': '1', 'description': 'Company Profile', 'insertedDate': '2023-07-18', 'pibData': \"[{'symbol': 'AMZN', 'mktCap': 1369763417088, 'companyName': 'Amazon.com, Inc.', 'currency': 'USD', 'cik': '0001018724', 'isin': 'US0231351067', 'exchange': 'NASDAQ Global Select', 'industry': 'Internet Retail', 'sector': 'Consumer Cyclical', 'address': '410 Terry Avenue North', 'city': 'Seattle', 'state': 'WA', 'zip': '98109-5210', 'website': 'https://www.amazon.com', 'description': 'Amazon.com, Inc. engages in the retail sale of consumer products and subscriptions through online and physical stores in North America and internationally. The company operates through three segments: North America, International, and Amazon Web Services (AWS). Its products offered through its stores include merchandise and content purchased for resale; and products offered by third-party sellers The company also manufactures and sells electronic devices, including Kindle, Fire tablets, Fire TVs, Rings, Blink, eero, and Echo; and develops and produces media content. In addition, it offers programs that enable sellers to sell their products in its stores; and programs that allow authors, musicians, filmmakers, Twitch streamers, skill and app developers, and others to publish and sell content. Further, the company provides compute, storage, database, analytics, machine learning, and other services, as well as fulfillment, advertising, and digital content subscriptions. Additionally, it offers Amazon Prime, a membership program. The company serves consumers, sellers, developers, enterprises, content creators, and advertisers. Amazon.com, Inc. was incorporated in 1994 and is headquartered in Seattle, Washington.'}]\"}, {'id': '50d89c93-12e4-47b1-af2c-6e043fb39462', 'symbol': 'AMZN', 'cik': '1018724', 'step': '1', 'description': 'Biography of Key Executives', 'insertedDate': '2023-07-18', 'pibData': '[{\\'name\\': \\'Mr. David A. Zapolsky\\', \\'title\\': \\'Senior Vice President, Gen. Counsel & Sec.\\', \\'biography\\': \\' David A. Zapolsky is the Senior Vice President, General Counsel, and Secretary of Amazon. He joined Amazon in 1999 and has 97,116 shares of Amazon stock worth more than $12,603,714. He is currently 59 years old and holds a Bachelor of Arts in Music from Columbia University and a Juris Doctor from University of California, Berkeley - Boalt Hall School of Law. He is responsible for managing a broad range of domestic and international legal, compliance, and regulatory affairs for the company. He recently received a total compensation package of nearly $17.2 million in 2020.\\'}, {\\'name\\': \\'Ms. Shelley L. Reynolds\\', \\'title\\': \\'Vice President, Worldwide Controller & Principal Accounting Officer\\', \\'biography\\': \" Shelley L. Reynolds is the Vice President, Worldwide Controller, and Principal Accounting Officer of Amazon.com Inc. She has been in this role since April 2007 and was previously a partner at Deloitte & Touche LLP. She is 56 years old and is part of Amazon\\'s strong leadership team. She is a graduate of the University of Washington and is a member of Moves magazine\\'s Power Women list. She oversees Amazon\\'s accounting function and manages a global team.\"}, {\\'name\\': \\'Dr. Werner  Vogels\\', \\'title\\': \\'Chief Technology Officer\\', \\'biography\\': \\'\\\\n\\\\nWerner Vogels is the Chief Technology Officer and Vice President of Amazon, responsible for driving technology innovation within the company. He is passionate about helping young businesses reach global scale and transforming enterprises into fast-moving digital organizations. Vogels has also predicted that the use of purpose-built chips will rapidly increase in 2023, accelerating the pace of innovation. He is the only executive apart from Amazon’s CEO Jeff Bezos to speak publicly on behalf of Amazon, and has recently warned that the company will go out of business within 10 to 15 years if it fails to keep innovating.\\'}, {\\'name\\': \\'Mr. Adam N. Selipsky\\', \\'title\\': \\'Chief Executive Officer of Amazon Web Services, Inc.\\', \\'biography\\': \\' Adam N. Selipsky is the CEO of Amazon Web Services (AWS), the world’s most comprehensive and broadly adopted cloud offering. He is responsible for the various roles they have held at Amazon, their contributions to the company, previous roles at other companies, and their educational backgrounds. He is estimated to have a net worth of at least $19.63 million and owns 150,780 shares of Amazon.com stock. Other key executives at Amazon include David A. Zapolsky, Shelley L. Reynolds, Dr. Werner Vogels, and Dave Fildes. Nick Adams is a prototypic Hemingway hero, concerned, reflective, and an outwardly impassive soldier and sportsman.\\'}, {\\'name\\': \\'Mr. Brian T. Olsavsky\\', \\'title\\': \\'Senior Vice President & Chief Financial Officer\\', \\'biography\\': \" Brian T. Olsavsky is the Senior Vice President and Chief Financial Officer of Amazon.com Inc. He joined the company in April 2002 and has held several top roles across the Finance organization. He oversees the company\\'s overall financial activities, including controllership, tax, treasury, analysis, investor relations, internal audit and financial operations. He has an undergraduate degree from The Pennsylvania State University and an MBA from Carnegie Mellon University. He has been awarded the 2019 Outstanding Engineering Alumni Award by the Penn State College of Engineering and owns over 16,800 units of Amazon.com stock worth over $8,423,058. His salary is $319,850.00 per year.\"}, {\\'name\\': \\'Mr. Andrew R. Jassy\\', \\'title\\': \\'Pres, Chief Executive Officer & Director\\', \\'biography\\': \\' Andrew R. Jassy is an American business executive who is the President and Chief Executive Officer (CEO) of Amazon. He was appointed by Jeff Bezos and the Amazon board in the fourth quarter of 2020 and has served as the CEO of Amazon Web Services since 2003. He is also a minority owner of the Seattle Kraken of the National Hockey League. Jassy will replace Jeff Bezos as CEO of Amazon in the third quarter of 2021 and has been the leader of Amazon Web Services since 2006. He has a degree from Harvard University and an MBA from Harvard Business School. He makes $1,298,723 in total compensation and owns 2.04 million shares of the company. On July 5, 2021, Jassy succeeded Jeff Bezos as CEO of Amazon and was elected as a director of the company.\\'}, {\\'name\\': \\'Ms. Beth  Galetti M.B.A.\\', \\'title\\': \\'Senior Vice President of Worldwide HR\\', \\'biography\\': \" Beth Galetti is the Senior Vice President of People eXperience and Technology at Amazon. She has a background in engineering, operations management, information technology, and human resources disciplines. She is responsible for leading a team that oversees the recruitment, growth, development, and support of more than one million employees in 50 countries. She is also Chairman of Program for Appropriate Technology in Health. Galetti is committed to making it easier for Amazon employees to do meaningful work and is working to remove barriers, fix defects, and enable self-service. She is also leading Amazon\\'s efforts to meet their 2021 diversity, equity, and inclusion goals.\"}, {\\'name\\': \\'Mr. Dave  Fildes\\', \\'title\\': \\'Director of Investor Relations\\', \\'biography\\': \" Dave Fildes is the Director of Investor Relations at Amazon.com Inc. He is based in Seattle, Washington and is responsible for answering questions and providing forward-looking statements during the company\\'s quarterly financial results conference calls. He is also involved in scaling the company\\'s Accounts Receivable Team and is part of the global finance team. He is also Co-CEO at Arcadia Petroleum Ltd.\"}, {\\'name\\': \\'Mr. Steven  Kessel\\', \\'title\\': \\'Senior Vice President\\', \\'biography\\': \" Steven Kessel is a Senior Vice President at Amazon.com, where he has worked for 16 years. He has a Bachelor\\'s degree in Computer Science from Dartmouth College and an MBA from Stanford\\'s Graduate School of Business. He has also held board and advisor roles, and is currently focusing on community service and not-for-profit work. He has made 34 transactions over 6 years at Amazon, and owns over 1,375 units of Amazon.com stock worth over $178,448. He also has a Ph.D. in marine ecology and biology from Cardiff University, UK.\"}, {\\'name\\': \\'Mr. Jeffrey M. Blackburn\\', \\'title\\': \\'Senior Vice President of Global Media & Entertainment Organization\\', \\'biography\\': \" Jeff Blackburn is a 22-year veteran of Amazon and a former All-Ivy outside linebacker for Dartmouth Football. He is currently the Senior Vice President of Business Development at Amazon and has an estimated net worth of $130 million. He is married to Anne Fleischli Blackburn \\'91 and they live in Seattle, Washington. He is also the Senior Vice President of Global Media and Entertainment at Amazon, overseeing all entertainment content.\"}, {\\'name\\': \\'Mr. Jeffrey P. Bezos\\', \\'title\\': \\'Founder & Executive Chairman\\', \\'biography\\': \\' Jeff Bezos is an American entrepreneur, media proprietor, and investor who is the founder, executive chairman, and former president and CEO of Amazon.com, Inc. He is estimated to have a net worth of over $120 billion and owns 990,545,661 shares of Amazon.com stock. He stepped down as CEO in 2021 and is now executive chairman. He is also the founder of Bezos Expeditions, LLC and a Principal Advisor at A9.com, Inc.\\'}, {\\'name\\': \\'Mr. David A. Zapolsky\\', \\'title\\': \\'Senior Vice President of Global Public Policy & Gen. Counsel\\', \\'biography\\': \" David A. Zapolsky is the Senior Vice President, General Counsel and Secretary of Amazon.com. He has been with the company since 1999 and manages a broad range of domestic and international legal, compliance, and regulatory affairs. He recently spoke at Drexel University\\'s Thomas R. Kline School of Law and has a total compensation of $163,200. He also owns 97,116 shares of Amazon.com stock worth more than $12,603,714.\"}, {\\'name\\': \\'Ms. Anuradha  Aggarwal\\', \\'title\\': \\'CMO & Director of User Growth\\', \\'biography\\': \\' Anuradha Aggarwal, with over two decades of experience, has joined Amazon as their Director of User Growth and Chief Marketing Officer for Amazon Pay. She previously worked with Hindustan Unilever, Vodafone, Disney-Star India, Marico, and other companies. She updated her LinkedIn page to reflect her new position at the e-commerce platform.\\'}, {\\'name\\': \\'Mr. Douglas J. Herrington\\', \\'title\\': \\'Chief Executive Officer of Worldwide Amazon Stores\\', \\'biography\\': \\' Doug Herrington has been the CEO of Worldwide Amazon Stores since July 2022. He has been with Amazon for 17 years and has extensive experience in consumer retailing, ecommerce, and marketing. He has a BA from Princeton University and an MBA from Harvard Business School. His estimated net worth is at least $74 million. He is also the author of the prequel novel \"Felony Melanie in Pageant Pandemonium\" and the screenwriter of \"Sweet Home Alabama\". Georgia Douglas Johnson was born in Atlanta on September 10, 1880 and was a composer and poet.\\'}]'}]\n"
     ]
    }
   ],
   "source": [
    "# Get the information about the company and list of all executives.\n",
    "# Check if we have already created record for Profile\n",
    "createPibIndex(SearchService, SearchKey, pibIndexName)\n",
    "step = \"1\"\n",
    "s1Data = []\n",
    "r = findPibData(SearchService, SearchKey, pibIndexName, cik, step, returnFields=['id', 'symbol', 'cik', 'step', 'description', 'insertedDate',\n",
    "                                                                   'pibData'])\n",
    "if r.get_count() == 0:\n",
    "    step1Profile = []\n",
    "    profile = companyProfile(apikey=apikey, symbol=symbol)\n",
    "    df = pd.DataFrame.from_dict(pd.json_normalize(profile))\n",
    "    sData = {\n",
    "            'id' : str(uuid.uuid4()),\n",
    "            'symbol': symbol,\n",
    "            'cik': cik,\n",
    "            'step': step,\n",
    "            'description': 'Company Profile',\n",
    "            'insertedDate': today.strftime(\"%Y-%m-%d\"),\n",
    "            'pibData' : str(df[['symbol', 'mktCap', 'companyName', 'currency', 'cik', 'isin', 'exchange', 'industry', 'sector', 'address', 'city', 'state', 'zip', 'website', 'description']].to_dict('records'))\n",
    "    }\n",
    "    step1Profile.append(sData)\n",
    "    s1Data.append(sData)\n",
    "    # Insert data into pibIndex\n",
    "    mergeDocs(SearchService, SearchKey, pibIndexName, step1Profile)\n",
    "\n",
    "    # Get the list of all executives and generate biography for each of them\n",
    "    executives = keyExecutives(apikey=apikey, symbol=symbol)\n",
    "    df = pd.DataFrame.from_dict(pd.json_normalize(executives),orient='columns')\n",
    "    df = df.drop_duplicates(subset='name', keep=\"first\")\n",
    "\n",
    "    step1Biography = []\n",
    "    tools = []\n",
    "    topK = 1\n",
    "    step1Executives = []\n",
    "    #### With the company profile and key executives, we can ask Bing Search to get the biography of the all Key executives and \n",
    "    # ask OpenAI to summarize it - Public Data\n",
    "    for executive in executives:\n",
    "        name = executive['name']\n",
    "        title = executive['title']\n",
    "        query = f\"Give me brief biography of {name} who is {title} at {symbol}. Biography should be restricted to {symbol} and summarize it as 2 paragraphs.\"\n",
    "        qaPromptTemplate = \"\"\"\n",
    "            Rephrase the following question asked by user to perform intelligent internet search\n",
    "            {query}\n",
    "            \"\"\"\n",
    "        optimizedPrompt = qaPromptTemplate.format(query=query)\n",
    "        completion = openai.Completion.create(\n",
    "                    engine=OpenAiDavinci,\n",
    "                    prompt=optimizedPrompt,\n",
    "                    temperature=temperature,\n",
    "                    max_tokens=100,\n",
    "                    n=1)\n",
    "        q = completion.choices[0].text\n",
    "        bingSearch = BingSearchAPIWrapper(k=25)\n",
    "        results = bingSearch.run(query=q)\n",
    "        chain = load_summarize_chain(llm, chain_type=\"stuff\")\n",
    "        docs = [Document(page_content=results)]\n",
    "        summary = chain.run(docs)\n",
    "        step1Executives.append({\n",
    "            \"name\": name,\n",
    "            \"title\": title,\n",
    "            \"biography\": summary\n",
    "        })\n",
    "\n",
    "    sData = {\n",
    "            'id' : str(uuid.uuid4()),\n",
    "            'symbol': symbol,\n",
    "            'cik': cik,\n",
    "            'step': step,\n",
    "            'description': 'Biography of Key Executives',\n",
    "            'insertedDate': today.strftime(\"%Y-%m-%d\"),\n",
    "            'pibData' : str(step1Executives)\n",
    "    }\n",
    "    step1Biography.append(sData)\n",
    "    s1Data.append(sData)\n",
    "    mergeDocs(SearchService, SearchKey, pibIndexName, step1Biography)\n",
    "else:\n",
    "    for s in r:\n",
    "        s1Data.append(\n",
    "            {\n",
    "                'id' : s['id'],\n",
    "                'symbol': s['symbol'],\n",
    "                'cik': s['cik'],\n",
    "                'step': s['step'],\n",
    "                'description': s['description'],\n",
    "                'insertedDate': s['insertedDate'],\n",
    "                'pibData' : s['pibData']\n",
    "            })\n",
    "\n",
    "print(s1Data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Paid Data -  Get the Earnings Call Transcript for each quarter for last 3 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search index earningcalls already exists\n",
      "Found 1 records for AMZN for 1 2023\n"
     ]
    }
   ],
   "source": [
    "# Call the paid data (FMP) API\n",
    "# Get the earning call transcripts for the last 3 years and merge documents into the index.\n",
    "i = 0\n",
    "earningsData = []\n",
    "step = \"2\"\n",
    "earningIndexName = 'earningcalls'\n",
    "# Create the index if it does not exist\n",
    "createEarningCallIndex(SearchService, SearchKey, earningIndexName)\n",
    "# Get the list of all earning calls available\n",
    "earningCallDates = earningCallsAvailableDates(apikey=apikey, symbol=symbol)\n",
    "quarter = earningCallDates[0][0]\n",
    "year = earningCallDates[0][1]\n",
    "r = findEarningCalls(SearchService, SearchKey, earningIndexName, symbol, str(quarter), str(year), returnFields=['id', 'symbol', \n",
    "            'quarter', 'year', 'callDate', 'content'])\n",
    "if r.get_count() == 0:\n",
    "    insertEarningCall = []\n",
    "    earningTranscript = earningCallTranscript(apikey=apikey, symbol=symbol, year=str(year), quarter=quarter)\n",
    "    for transcript in earningTranscript:\n",
    "        symbol = transcript['symbol']\n",
    "        quarter = transcript['quarter']\n",
    "        year = transcript['year']\n",
    "        callDate = transcript['date']\n",
    "        content = transcript['content']\n",
    "        todayYmd = today.strftime(\"%Y-%m-%d\")\n",
    "        id = f\"{symbol}-{year}-{quarter}\"\n",
    "        earningRecord = {\n",
    "            \"id\": id,\n",
    "            \"symbol\": symbol,\n",
    "            \"quarter\": str(quarter),\n",
    "            \"year\": str(year),\n",
    "            \"callDate\": callDate,\n",
    "            \"content\": content,\n",
    "            #\"inserteddate\": datetime.now(central).strftime(\"%Y-%m-%d\"),\n",
    "        }\n",
    "        earningsData.append(earningRecord)\n",
    "        insertEarningCall.append(earningRecord)\n",
    "        mergeDocs(SearchService, SearchKey, earningIndexName, insertEarningCall)\n",
    "else:\n",
    "    print(f\"Found {r.get_count()} records for {symbol} for {quarter} {year}\")\n",
    "    for s in r:\n",
    "        earningsData.append(\n",
    "            {\n",
    "                'id' : s['id'],\n",
    "                'symbol': s['symbol'],\n",
    "                'quarter': s['quarter'],\n",
    "                'year': s['year'],\n",
    "                'callDate': s['callDate'],\n",
    "                'content': s['content']\n",
    "            })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the transcripts as per Split Method, Chunk Size and Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last earning call transcripts was on : 2023-04-27 19:55:02\n",
      "Number of documents chunks generated from Call transcript :  7\n"
     ]
    }
   ],
   "source": [
    "# Let's just use the latest earnings call transcript to create the documents that we want to use it for generative AI tasks\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=8000, chunk_overlap=1000)\n",
    "\n",
    "print(\"Last earning call transcripts was on :\", earningsData[-1]['callDate'])\n",
    "rawDocs = splitter.create_documents([earningsData[-1]['content']])\n",
    "docs = splitter.split_documents(rawDocs)\n",
    "print(\"Number of documents chunks generated from Call transcript : \", len(docs))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the vector store embedding data for chunked sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search index latestearningcalls already exists\n",
      "Total docs: 7\n",
      "Found 7 sections for AMZN 2023 Q1\n",
      "Already indexed 7 sections for AMZN 2023 Q1\n"
     ]
    }
   ],
   "source": [
    "# Store the last index of the earning call transcript in vector Index\n",
    "earningVectorIndexName = 'latestearningcalls'\n",
    "createEarningCallVectorIndex(SearchService, SearchKey, earningVectorIndexName)\n",
    "\n",
    "indexEarningCallSections(OpenAiService, OpenAiKey, OpenAiVersion, OpenAiApiKey, SearchService, SearchKey,\n",
    "                         embeddingModelType, OpenAiEmbedding, earningVectorIndexName, docs,\n",
    "                         earningsData[-1]['callDate'], earningsData[-1]['symbol'], earningsData[-1]['year'],\n",
    "                         earningsData[-1]['quarter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAnswer(chainType, topK, symbol, quarter, year, question, indexName, llm):\n",
    "    r = performEarningCallCogSearch(OpenAiService, OpenAiKey, OpenAiVersion, OpenAiApiKey, SearchService, SearchKey, embeddingModelType, \n",
    "        OpenAiEmbedding, symbol, str(quarter), str(year), question, indexName, topK, returnFields=['id', 'symbol', 'quarter', 'year', 'callDate', 'content'])\n",
    "    \n",
    "    if r == None:\n",
    "        docs = [Document(page_content=\"No results found\")]\n",
    "    else :\n",
    "        docs = [\n",
    "            Document(page_content=doc['content'], metadata={\"id\": doc['id'], \"source\": ''})\n",
    "            for doc in r\n",
    "            ]\n",
    "    \n",
    "    if chainType == \"map_reduce\":\n",
    "        # Prompt for MapReduce\n",
    "        qaTemplate = \"\"\"Use the following portion of a long document to see if any of the text is relevant to answer the question.\n",
    "                Return any relevant text.\n",
    "                {context}\n",
    "                Question: {question}\n",
    "                Relevant text, if any :\"\"\"\n",
    "\n",
    "        qaPrompt = PromptTemplate(\n",
    "            template=qaTemplate, input_variables=[\"context\", \"question\"]\n",
    "        )\n",
    "\n",
    "        combinePromptTemplate = \"\"\"Given the following extracted parts of a long document and a question, create a final answer.\n",
    "        If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
    "        If the answer is not contained within the text below, say \\\"I don't know\\\".\n",
    "\n",
    "        QUESTION: {question}\n",
    "        =========\n",
    "        {summaries}\n",
    "        =========\n",
    "        \"\"\"\n",
    "        combinePrompt = PromptTemplate(\n",
    "            template=combinePromptTemplate, input_variables=[\"summaries\", \"question\"]\n",
    "        )\n",
    "\n",
    "        qaChain = load_qa_with_sources_chain(llm, chain_type=chainType, question_prompt=qaPrompt, \n",
    "                                            combine_prompt=combinePrompt, \n",
    "                                            return_intermediate_steps=True)\n",
    "        answer = qaChain({\"input_documents\": docs, \"question\": question})\n",
    "        outputAnswer = answer['output_text']\n",
    "\n",
    "    elif chainType == \"stuff\":\n",
    "    # Prompt for ChainType = Stuff\n",
    "        template = \"\"\"\n",
    "                Given the following extracted parts of a long document and a question, create a final answer. \n",
    "                If you don't know the answer, just say that you don't know. Don't try to make up an answer. \n",
    "                If the answer is not contained within the text below, say \\\"I don't know\\\".\n",
    "\n",
    "                QUESTION: {question}\n",
    "                =========\n",
    "                {summaries}\n",
    "                =========\n",
    "                \"\"\"\n",
    "        qaPrompt = PromptTemplate(template=template, input_variables=[\"summaries\", \"question\"])\n",
    "        qaChain = load_qa_with_sources_chain(llm, chain_type=chainType, prompt=qaPrompt)\n",
    "        answer = qaChain({\"input_documents\": docs, \"question\": question}, return_only_outputs=True)\n",
    "        outputAnswer = answer['output_text']\n",
    "    elif chainType == \"default\":\n",
    "        # Default Prompt\n",
    "        qaChain = load_qa_with_sources_chain(llm, chain_type=\"stuff\")\n",
    "        answer = qaChain({\"input_documents\": docs, \"question\": question}, return_only_outputs=True)\n",
    "        outputAnswer = answer['output_text']\n",
    "\n",
    "    return outputAnswer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top questions to ask during earning call - Let's see if we can find the answers to these questions in the transcripts\n",
    "- What are some of the current and looming threats to the business?\n",
    "- What is the debt level or debt ratio of the company right now?\n",
    "- How do you feel about the upcoming product launches or new products?\n",
    "- How are you managing or investing in your human capital?\n",
    "- How do you track the trends in your industry?\n",
    "- Are there major slowdowns in the production of goods?\n",
    "- How will you maintain or surpass this performance in the next few quarters?\n",
    "- What will your market look like in five years as a result of using your product or service?\n",
    "- How are you going to address the risks that will affect the long-term growth of the company?\n",
    "- How is the performance this quarter going to affect the long-term goals of the company?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another specific question to ask\n",
    "- Revenue: Provide key information about revenue for the quarter\n",
    "- Profitability: Provide key information about profits and losses (P&L) for the quarter\n",
    "- Industry Trends: Provide key information about industry trends for the quarter\n",
    "- Trend: Provide key information about business trends discussed on the call\n",
    "- Risk: Provide key information about risk discussed on the call\n",
    "- AI: Provide key information about AI discussed on the call\n",
    "- M&A: Provide any information about mergers and acquisitions (M&A) discussed on the call.\n",
    "- Guidance: Provide key information about guidance discussed on the call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since we have the lastest transcripts in the document format, let's summarize the information with following specific summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing data\n",
      "[{'id': '052c5268-ded3-443f-be44-3886c71e6e39', 'symbol': 'AMZN', 'cik': '1018724', 'step': '2', 'description': 'Earning Call Q&A', 'insertedDate': '2023-07-18', 'pibData': '[{\\'question\\': \\'Provide key information about profits and losses (P&L) for the quarter\\', \\'answer\\': \"Based on the provided information, here is the answer to the question: \\\\n\\\\nIn the first quarter of 2023, Amazon reported worldwide net sales of $127.4 billion, representing a 9% year-over-year growth. The company experienced revenue acceleration in its international segment, driven by easing macroeconomic pressures in Europe. However, the uncertain economic environment and ongoing inflationary pressures led to cautious consumer spending and a focus on value. Amazon\\'s advertising services also saw strong engagement, with revenue increasing by 23% year-over-year. In terms of profits, Amazon reported operating income of $4.8 billion for the quarter, above the top end of their guidance range. However, this operating income was negatively impacted by an estimated employee severance charge of approximately $470 million, including $270 million related to AWS. The company also reported overall net income of $3.2 billion for the quarter.\"}, {\\'question\\': \\'Provide key information about business trends discussed on the call\\', \\'answer\\': \\'Based on the provided information, the key information about business trends discussed on the call is as follows:\\\\n\\\\n1. In the international segment, there was an acceleration in growth on an FX-neutral basis, with a 9% growth compared to 5% in Q4. The economy in established countries of Europe is stabilizing, and consumer confidence is increasing.\\\\n\\\\n2. The negative margin in the international segment has come down, partly due to reductions in investments and improvements in operational efficiency. The goal is to work on cost structure and grow the businesses country by country.\\\\n\\\\n3. In the grocery business, consumables have remained strong, and Amazon continues to be pleased with that part of the business. Whole Foods, which pioneered the organic grocery space, is growing nicely. Amazon Fresh, the mass physical offering, is still in the experimental phase, but the company is optimistic about finding a format that can be expanded more broadly.\\\\n\\\\n4. In AWS, customers are cutting workloads in some areas but showing continued strength in hitting contractual limits and planning for the future. The outlook for the business is strong, and efforts are being made to help customers save money.\\\\n\\\\nRegarding the second question about the big investment areas and breaking out all the big investments, the answer is not provided in the given text.\\'}, {\\'question\\': \\'Provide key information about risk discussed on the call\\', \\'answer\\': \\'The key information about risk discussed on the call is not provided in the given text.\\'}, {\\'question\\': \\'Provide key information about guidance discussed on the call\\', \\'answer\\': \\'The key information about guidance discussed on the call is that AWS is experiencing dynamics among customers where they are cutting workloads, but there is continued strength in customers hitting their contractual limits and extending them. The company feels strongly about the outlook for the business and is working to help customers save money. There is no obvious year-over-year comp differential between Q2 and Q1. As for the investments in medical and Kuiper, the company believes they have the potential to be big and move the needle for Amazon. They have identified opportunities for success in the healthcare industry, particularly in primary care, and have launched Amazon Pharmacy. They also see a large opportunity in providing internet connectivity to households and businesses through Kuiper. There was no mention of breaking out all the big investments for more clarity on the retail margin structure.\\'}, {\\'question\\': \\'1. Financial Results\\', \\'answer\\': \\' Amazon reported Q1 net sales of $127.4 billion, a 9% increase YoY. The International segment saw growth due to easing macroeconomic pressures in Europe, but cautious consumer spending and inflationary pressures impacted discretionary categories. Third-party sellers accounted for 59% of unit sales. AWS net sales reached $21.4 billion, a 16% increase YoY. Operating income was $4.8 billion, impacted by an employee severance charge. Overall net income was $3.2 billion. Operating cash flow for the trailing 12 months increased to $54.3 billion.\\'}, {\\'question\\': \\'2. Business Highlights\\', \\'answer\\': \\' Amazon focused on reducing costs and improving delivery speed in its fulfillment network. The advertising business saw strong engagement, attributed to a large customer base and investment in machine learning. In AWS, customers are looking to save money, and Amazon is helping them optimize costs. The company made structural changes to its U.S. fulfillment network to improve delivery speed and cost efficiency.\\'}, {\\'question\\': \\'3. Future Outlook\\', \\'answer\\': \\' Amazon is confident in the future growth of AWS, particularly in the machine learning space. The company continues to invest in strategic long-term initiatives while streamlining costs. They believe their best days are still ahead and are actively working on long-term customer success and building relationships.\\'}, {\\'question\\': \\'4. Business Risks\\', \\'answer\\': \" Amazon mentioned cautious consumer spending and ongoing inflationary pressures impacting discretionary categories. They also acknowledged the need for further improvement in profitability and efficiency across all businesses. They did not provide specific differentiation points for AWS\\'s AI tools or investment priorities for Echo and Alexa.\"}, {\\'question\\': \\'5. Management Positive Sentiment\\', \\'answer\\': \" Management expressed confidence in the growth potential of AWS, the success of the advertising business, and the company\\'s international segment. They highlighted the importance of long-term customer success and building relationships.\"}, {\\'question\\': \\'6. Management Negative Sentiment\\', \\'answer\\': \" Management acknowledged the impact of cautious consumer spending and inflationary pressures on discretionary categories. They mentioned the need for further improvement in profitability and efficiency. They did not provide specific differentiation points for AWS\\'s AI tools or investment priorities for Echo and Alexa.\"}]'}]\n"
     ]
    }
   ],
   "source": [
    "r = findPibData(SearchService, SearchKey, pibIndexName, cik, step, returnFields=['id', 'symbol', 'cik', 'step', 'description', 'insertedDate',\n",
    "                                                                   'pibData'])\n",
    "\n",
    "earningCallQa = []\n",
    "s2Data = []\n",
    "if r.get_count() == 0:\n",
    "    commonQuestions = [\n",
    "        \"What are some of the current and looming threats to the business?\",\n",
    "        \"What is the debt level or debt ratio of the company right now?\",\n",
    "        \"How do you feel about the upcoming product launches or new products?\",\n",
    "        \"How are you managing or investing in your human capital?\",\n",
    "        \"How do you track the trends in your industry?\",\n",
    "        \"Are there major slowdowns in the production of goods?\",\n",
    "        \"How will you maintain or surpass this performance in the next few quarters?\",\n",
    "        \"What will your market look like in five years as a result of using your product or service?\",\n",
    "        \"How are you going to address the risks that will affect the long-term growth of the company?\",\n",
    "        \"How is the performance this quarter going to affect the long-term goals of the company?\"\n",
    "    ]\n",
    "\n",
    "    for question in commonQuestions:\n",
    "        answer = findAnswer('stuff', 3, symbol, quarter, year, question, earningVectorIndexName, llmChat)\n",
    "        if \"I don't know\" not in answer:\n",
    "            earningCallQa.append({\"question\": question, \"answer\": answer})\n",
    "\n",
    "    commonQuestions = [\n",
    "            \"Provide key information about revenue for the quarter\",\n",
    "            \"Provide key information about profits and losses (P&L) for the quarter\",\n",
    "            \"Provide key information about industry trends for the quarter\",\n",
    "            \"Provide key information about business trends discussed on the call\",\n",
    "            \"Provide key information about risk discussed on the call\",\n",
    "            \"Provide key information about AI discussed on the call\",\n",
    "            \"Provide any information about mergers and acquisitions (M&A) discussed on the call.\",\n",
    "            \"Provide key information about guidance discussed on the call\"\n",
    "        ]\n",
    "\n",
    "    for question in commonQuestions:\n",
    "        answer = findAnswer('stuff', 3, symbol, quarter, year, question, earningVectorIndexName, llmChat)\n",
    "        if \"I don't know\" not in answer:\n",
    "            earningCallQa.append({\"question\": question, \"answer\": answer})\n",
    "\n",
    "    promptTemplate = \"\"\"You are an AI assistant tasked with summarizing financial information from earning call transcript. \n",
    "            Your summary should accurately capture the key information in the document while avoiding the omission of any domain-specific words. \n",
    "            Please generate a concise and comprehensive summary between 5-7 paragraphs on each of the following numbered topics.  Your response should include the topic as part of the summary.\n",
    "            1. Financial Results: Please provide a summary of the financial results.\n",
    "            2. Business Highlights: Please provide a summary of the business highlights.\n",
    "            3. Future Outlook: Please provide a summary of the future outlook.\n",
    "            4. Business Risks: Please provide a summary of the business risks.\n",
    "            5. Management Positive Sentiment: Please provide a summary of the what management is confident about.\n",
    "            6. Management Negative Sentiment: Please provide a summary of the what management is concerned about.\n",
    "            Please remember to use clear language and maintain the integrity of the original information without missing any important details:\n",
    "            {text}\n",
    "            \"\"\"\n",
    "    customPrompt = PromptTemplate(template=promptTemplate, input_variables=[\"text\"])\n",
    "    chainType = \"map_reduce\"\n",
    "    summaryChain = load_summarize_chain(llmChat, chain_type=chainType, return_intermediate_steps=False, \n",
    "                                combine_prompt=customPrompt)\n",
    "    summaryOutput = summaryChain({\"input_documents\": docs}, return_only_outputs=True)\n",
    "\n",
    "    output = summaryOutput['output_text']\n",
    "    formattedOutput = output.splitlines()\n",
    "    while(\"\" in formattedOutput):\n",
    "        formattedOutput.remove(\"\")\n",
    "    for summary in formattedOutput:\n",
    "        splitSummary = summary.split(\":\")\n",
    "        question = splitSummary[0]\n",
    "        answer = splitSummary[1]\n",
    "        earningCallQa.append({\"question\": question, \"answer\": answer})\n",
    "\n",
    "    s2Data.append({\n",
    "                'id' : str(uuid.uuid4()),\n",
    "                'symbol': symbol,\n",
    "                'cik': cik,\n",
    "                'step': step,\n",
    "                'description': 'Earning Call Q&A',\n",
    "                'insertedDate': today.strftime(\"%Y-%m-%d\"),\n",
    "                'pibData' : str(earningCallQa)\n",
    "        })\n",
    "    mergeDocs(SearchService, SearchKey, pibIndexName, s2Data)\n",
    "else:\n",
    "    print('Found existing data')\n",
    "    for s in r:\n",
    "        s2Data.append(\n",
    "            {\n",
    "                'id' : s['id'],\n",
    "                'symbol': s['symbol'],\n",
    "                'cik': s['cik'],\n",
    "                'step': s['step'],\n",
    "                'description': s['description'],\n",
    "                'insertedDate': s['insertedDate'],\n",
    "                'pibData' : s['pibData']\n",
    "            })\n",
    "        \n",
    "print(s2Data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = findPibData(SearchService, SearchKey, pibIndexName, cik, step, returnFields=['id', 'symbol', 'cik', 'step', 'description', 'insertedDate',\n",
    "#                                                                    'pibData'])\n",
    "# s2Data = []\n",
    "# if r.get_count() == 0:\n",
    "\n",
    "#     earningCallQa = []\n",
    "#     commonQuestions = [\n",
    "#         \"What are some of the current and looming threats to the business?\",\n",
    "#         \"What is the debt level or debt ratio of the company right now?\",\n",
    "#         \"How do you feel about the upcoming product launches or new products?\",\n",
    "#         \"How are you managing or investing in your human capital?\",\n",
    "#         \"How do you track the trends in your industry?\",\n",
    "#         \"Are there major slowdowns in the production of goods?\",\n",
    "#         \"How will you maintain or surpass this performance in the next few quarters?\",\n",
    "#         \"What will your market look like in five years as a result of using your product or service?\",\n",
    "#         \"How are you going to address the risks that will affect the long-term growth of the company?\",\n",
    "#         \"How is the performance this quarter going to affect the long-term goals of the company?\"\n",
    "#     ]\n",
    "\n",
    "#     for question in commonQuestions:\n",
    "#         answer = findAnswer('map_reduce', 3, question, earningVectorIndexName)\n",
    "#         if \"I don't know\" not in answer:\n",
    "#             earningCallQa.append({\"question\": question, \"answer\": answer})\n",
    "\n",
    "#     commonQuestions = [\n",
    "#         \"Provide key information about revenue for the quarter\",\n",
    "#         \"Provide key information about profits and losses (P&L) for the quarter\",\n",
    "#         \"Provide key information about industry trends for the quarter\",\n",
    "#         \"Provide key information about business trends discussed on the call\",\n",
    "#         \"Provide key information about risk discussed on the call\",\n",
    "#         \"Provide key information about AI discussed on the call\",\n",
    "#         \"Provide any information about mergers and acquisitions (M&A) discussed on the call.\",\n",
    "#         \"Provide key information about guidance discussed on the call\"\n",
    "#     ]\n",
    "\n",
    "#     for question in commonQuestions:\n",
    "#         answer = findAnswer('map_reduce', 3, question, earningVectorIndexName)\n",
    "#         if \"I don't know\" not in answer:\n",
    "#             earningCallQa.append({\"question\": question, \"answer\": answer})\n",
    "\n",
    "#     # With the data indexed, let's summarize the information\n",
    "#     # While we are using the standard prompt by langchain, you can modify the prompt to suit your needs\n",
    "#     # 1. Financial Results Summary: Please provide a summary of the financial results.\n",
    "#     # 2. Business Highlights: Please provide a summary of the business highlights.\n",
    "#     # 3. Future Outlook: Please provide a summary of the future outlook.\n",
    "#     # 4. Business Risks: Please provide a summary of the business risks.\n",
    "#     # 5. Management Positive Sentiment: Please provide a summary of the what management is confident about.\n",
    "#     # 6. Management Negative Sentiment: Please provide a summary of the what management is concerned about.\n",
    "#     # 7. Future Growth Strategies : Please generate a concise and comprehensive strategies summary that includes the information in  bulleted format.\n",
    "#     # 8. Risk Increase: Please provide a summary of the risks that have increased.\n",
    "#     # 9. Risk Decrease: Please provide a summary of the risks that have decreased.\n",
    "#     # 10. Opportunity Increase: Please provide a summary of the opportunities that have increased.\n",
    "#     # 11. Opportunity Decrease: Please provide a summary of the opportunities that have decreased.\n",
    "#     commonSummary = [\n",
    "#         \"Financial Results\",\n",
    "#         \"Business Highlights\",\n",
    "#         \"Future Outlook\",\n",
    "#         \"Business Risks\",\n",
    "#         \"Management Positive Sentiment\",\n",
    "#         \"Management Negative Sentiment\",\n",
    "#         \"Future Growth Strategies\"\n",
    "#     ]\n",
    "\n",
    "#     promptTemplate = \"\"\"You are an AI assistant tasked with summarizing financial information from earning call transcript. \n",
    "#             Your summary should accurately capture the key information in the document while avoiding the omission of any domain-specific words. \n",
    "#             Please generate a concise and comprehensive summary on the following topics. \n",
    "#             {summarize}\n",
    "#             Please remember to use clear language and maintain the integrity of the original information without missing any important details:\n",
    "#             {text}\n",
    "#             \"\"\"\n",
    "#     for summary in commonSummary:\n",
    "#         customPrompt = PromptTemplate(template=promptTemplate.replace('{summarize}', summary), input_variables=[\"text\"])\n",
    "#         chainType = \"map_reduce\"\n",
    "#         summaryChain = load_summarize_chain(llmChat, chain_type=chainType, return_intermediate_steps=False, \n",
    "#                                     map_prompt=customPrompt, combine_prompt=customPrompt)\n",
    "#         summaryOutput = summaryChain({\"input_documents\": docs}, return_only_outputs=True)\n",
    "#         outputAnswer = summaryOutput['output_text'].replace('Summary:', '')\n",
    "#         if \"I don't know\" not in answer and len(outputAnswer) > 0:\n",
    "#             earningCallQa.append({\"question\": summary, \"answer\": outputAnswer})\n",
    "\n",
    "#     s2Data.append({\n",
    "#                 'id' : str(uuid.uuid4()),\n",
    "#                 'symbol': symbol,\n",
    "#                 'cik': cik,\n",
    "#                 'step': step,\n",
    "#                 'description': 'Earning Call Q&A',\n",
    "#                 'insertedDate': today.strftime(\"%Y-%m-%d\"),\n",
    "#                 'pibData' : str(earningCallQa)\n",
    "#         })\n",
    "#     mergeDocs(SearchService, SearchKey, pibIndexName, s2Data)\n",
    "# else:\n",
    "#     print('Found existing data')\n",
    "#     for s in r:\n",
    "#         s2Data.append(\n",
    "#             {\n",
    "#                 'id' : s['id'],\n",
    "#                 'symbol': s['symbol'],\n",
    "#                 'cik': s['cik'],\n",
    "#                 'step': s['step'],\n",
    "#                 'description': s['description'],\n",
    "#                 'insertedDate': s['insertedDate'],\n",
    "#                 'pibData' : s['pibData']\n",
    "#             })\n",
    "        \n",
    "# print(s2Data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In case if we wanted to see summary of summary, run code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For the chaintype of MapReduce and Refine, we can also get insight into intermediate steps of the pipeline.\n",
    "# # This way you can inspect the results from map_reduce chain type, each top similar chunk summary\n",
    "# intermediateSteps = summary['intermediate_steps']\n",
    "# for step in intermediateSteps:\n",
    "#         display(HTML(\"<b>Chunk Summary:</b> \" + step))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Paid Data - Press Releases - Get the Press Releases for last year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarizePressReleases(llm, docs):\n",
    "    promptTemplate = \"\"\"You are an AI assistant tasked with summarizing company's press releases and performing sentiments on those. \n",
    "                Your summary should accurately capture the key information in the press-releases while avoiding the omission of any domain-specific words. \n",
    "                Please generate a concise and comprehensive summary and sentiment with score with range of 0 to 10. \n",
    "                Your response should be in JSON object with following keys.  All JSON properties are required.\n",
    "                summary: \n",
    "                sentiment:\n",
    "                sentiment score: \n",
    "                {text}\n",
    "                \"\"\"\n",
    "    customPrompt = PromptTemplate(template=promptTemplate, input_variables=[\"text\"])\n",
    "    chainType = \"stuff\"\n",
    "    summaryChain = load_summarize_chain(llm, chain_type=chainType, prompt=customPrompt)\n",
    "    summary = summaryChain({\"input_documents\": docs}, return_only_outputs=True)\n",
    "    outputAnswer = summary['output_text']\n",
    "    return outputAnswer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing data\n",
      "[{'id': 'e8bcd047-14f4-4879-8a38-dedcd50490ec', 'symbol': 'AMZN', 'cik': '1018724', 'step': '3', 'description': 'Press Releases', 'insertedDate': '2023-07-18', 'pibData': '[{\\'releaseDate\\': \\'2023-07-11 03:00:00\\', \\'title\\': \\'TINECO IS REDUCING PRICES ON THE OCCASION OF AMAZON PRIME DAY\\', \\'summary\\': \\'Tineco, a leading pioneer in floor care and smart home appliances, will be offering selected products at heavily discounted prices on Amazon Prime Day on July 11 and 12. The offer includes cordless vacuum cleaners, carpet cleaners, and combo power kit vacuum cleaners.\\', \\'sentiment\\': \\'Positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2023-07-11 02:00:00\\', \\'title\\': \\'TINECO UNLEASHES UNBEATABLE PRICES FOR AMAZON PRIME DAY!\\', \\'summary\\': \\'Tineco is participating in Amazon Prime Day with exclusive deals on their Floor One S5 vacuum cleaner.\\', \\'sentiment\\': \\'positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2023-07-07 22:29:00\\', \\'title\\': \\'AUTOMATED INVESTMENTS ANNOUNCES FULLY AUTOMATED AMAZON FBA STORES\\', \\'summary\\': \\'Automated Investments, a leading automation agency in the e-commerce industry, has launched its fully automated Amazon FBA stores. The company, founded by entrepreneurs Oz Levi and Shawn Megira, aims to empower investors with business opportunities and harness the power of automation.\\', \\'sentiment\\': \\'positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2023-07-03 18:01:00\\', \\'title\\': \\'AMAZON ROLLS OUT FIRST ELECTRIC DELIVERY VANS FROM RIVIAN IN EUROPE\\', \\'summary\\': \\'Amazon has introduced its new custom electric delivery vans from Rivian in Europe, with over 300 vans being deployed in Munich, Berlin, and Dusseldorf. This adds to the existing fleet of thousands of electric vans already in operation in Europe, including over 1,000 in Germany. Amazon plans to invest over €1 billion to further electrify its delivery fleet.\\', \\'sentiment\\': \\'Positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2023-06-29 09:55:00\\', \\'title\\': \\'AMAZON MUSIC CURATES PERFORMANCES FROM 2 CHAINZ, BLXST, AJR, ESLABON ARMADO, ARMANI WHITE, DJ E ROCK, AND MORE AT NBA CON\\', \\'summary\\': \\'Amazon Music will curate three days of live music for the first NBA Con event held at the Mandalay Bay Convention Center in Las Vegas. The lineup includes artists such as 2 Chainz, BLXST, AJR, Eslabon Armado, Armani White, and Vegas.\\', \\'sentiment\\': \\'Positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2023-06-29 09:05:00\\', \\'title\\': \\'SKYLAR COLLABORATES WITH AMAZON PRIME VIDEO TO CAPTURE THE SCENTS OF THE SUMMER I TURNED PRETTY\\', \\'summary\\': \"Skylar, a maker of clean fragrances, has announced its collaboration with the Amazon Prime Video series, The Summer I Turned Pretty. Skylar is the official fragrance for the series, allowing viewers to experience the story\\'s magic through scent and be transported to the world of Belly, Conrad, and Jeremiah.\", \\'sentiment\\': \\'positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2023-06-29 08:10:00\\', \\'title\\': \\'AMAZON RETURNS AVAILABLE AT STAPLES U.S. RETAIL STORES\\', \\'summary\\': \\'Staples announced that all Staples U.S. retail locations will accept free, label-free, box-free returns for Amazon customers by July 31, 2023. Eligible unpackaged, unlabeled Amazon items can be dropped off at the full-service shipping area inside Staples locations, providing a convenient return option. Customers will receive a coupon for special savings after completing their return.\\', \\'sentiment\\': \\'positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2023-06-28 06:30:00\\', \\'title\\': \\'AIERA, VIA NASDAQ DATA LINK, NOW DELIVERS WALL STREET EVENT SUMMARIES THROUGH AMAZON ALEXA-ENABLED DEVICES\\', \\'summary\\': \\'Aiera, the leading financial event intelligence platform, has partnered with Nasdaq Data Link to deliver its advanced summarization insights via Amazon Alexa.\\', \\'sentiment\\': \\'Positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2023-06-27 06:00:00\\', \\'title\\': \\'SMALL-BUSINESS OWNERS NOW GET BUSINESS PRIME DUO FOR FREE WITH THEIR PRIME MEMBERSHIP\\', \\'summary\\': \\'Amazon Business announces that Business Prime Duo, previously $69 per year, is now free for Amazon Prime members who also purchase for businesses. Business Prime Duo is an Amazon Business membership that provides small-business owners with business buying tools, access to business-only pricing, and fast, free business delivery.\\', \\'sentiment\\': \\'positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2023-06-08 09:55:00\\', \\'title\\': \\'GIGAMON ANNOUNCES DEEP OBSERVABILITY INTEGRATION WITH AMAZON SECURITY LAKE\\', \\'summary\\': \"Gigamon has announced that its Deep Observability Pipeline now efficiently delivers network-derived Application Metadata Intelligence (AMI) into Amazon Security Lake from Amazon Web Services (AWS). Amazon Security Lake centralizes an organization\\'s security data from various sources into a purpose-built data lake.\", \\'sentiment\\': \\'Positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2023-06-06 14:00:00\\', \\'title\\': \\'ROVIO ENTERTAINMENT CORP.: PRIME VIDEO AND AMAZON KIDS+ SET TO RELEASE ANGRY BIRDS MYSTERY ISLAND ANIMATED SERIES FROM ROVIO ENTERTAINMENT CORPORATION\\', \\'summary\\': \\'Prime Video and Amazon Kids+ will be releasing the Angry Birds Mystery Island animated series created by Rovio Entertainment Corporation.\\', \\'sentiment\\': \\'Positive\\', \\'sentimentScore\\': 8.7}, {\\'releaseDate\\': \\'2023-06-05 11:36:00\\', \\'title\\': \\'GENERAL GALACTIC SYSTEMS INC. ANNOUNCES THE AVAILABILITY OF ITS CRYSTAL WATER MONITOR POOL & HOT TUB CARE SOLUTION IN THE AMAZON STORE\\', \\'summary\\': \"General Galactic Systems Inc. announces the availability of the Crystal Water System in the Amazon store. The Crystal Water Monitoring System maintains proper water chemistry balance in your pool or hot tub water by using intelligent sensors to gather pH, ORP, and temperature readings over 1000 times per week. Combined with a state-of-the-art mobile app, the Crystal Water Monitor connects directly through WiFi and your home\\'s I.\", \\'sentiment\\': \\'positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2023-06-01 08:00:00\\', \\'title\\': \\'MINUTE MEDIA ANNOUNCES INTEGRATION WITH AMAZON PUBLISHER SERVICES TRANSPARENT AD MARKETPLACE (TAM)\\', \\'summary\\': \"Minute Media has announced the integration of its supply-side platform (SSP) with Amazon Publisher Services (APS) Transparent Ad Marketplace (TAM), providing increased monetization and unique demand for display and video ads to Minute Media\\'s publishing partners.\", \\'sentiment\\': \\'positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2023-05-31 10:00:00\\', \\'title\\': \\'STELLAR CYBER ANNOUNCES SUPPORT FOR AMAZON SECURITY LAKE TO SPEED DATA PROCESSING AND THREAT DETECTION\\', \\'summary\\': \"Stellar Cyber announces support for the Amazon Security Lake from Amazon Web Services (AWS), allowing organizations to ingest data from the lake into Stellar Cyber\\'s Open XDR platform for enhanced data analysis and faster threat detection.\", \\'sentiment\\': \\'positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2023-05-30 16:43:00\\', \\'title\\': \\'SOC PRIME LAUNCHES INTEGRATION WITH AMAZON SECURITY LAKE TO SUPERCHARGE SECURITY OPERATIONS\\', \\'summary\\': \\'SOC Prime integrates with Amazon Security Lake to drive cost-efficient, zero-trust, and multi-cloud security backed by collective expertise.\\', \\'sentiment\\': \\'Positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2023-05-23 09:38:00\\', \\'title\\': \"INTRODUCING THE ALL-NEW FIRE MAX 11: AMAZON\\'S BIGGEST AND MOST POWERFUL TABLET YET\", \\'summary\\': \\'Amazon has announced the new Fire Max 11, which is their biggest and most powerful tablet yet. It features an 11-inch screen, a powerful octa-core processor, and 4 GB RAM. The tablet starts at $229.99 and also offers an optional magnetic attach keyboard and stylus for enhanced productivity and creativity.\\', \\'sentiment\\': \\'Positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2023-05-23 00:27:00\\', \\'title\\': \"AMAZON\\'S U.S. SMALL BUSINESS EMPOWERMENT REPORT SHOWS CONTINUED SALES GROWTH FOR INDEPENDENT SELLERS\", \\'summary\\': \"Amazon releases its annual U.S. Small Business Empowerment Report, highlighting its investments and initiatives to support independent sellers and boost sales and job creation. Currently, over 60% of sales in Amazon\\'s store come from independent sellers, mostly small and medium-sized businesses.\", \\'sentiment\\': \\'positive\\', \\'sentimentScore\\': 9.2}, {\\'releaseDate\\': \\'2023-05-17 10:15:00\\', \\'title\\': \\'AMAZON INTRODUCES FOUR ALL-NEW ECHO DEVICES; SALES OF ALEXA-ENABLED DEVICES SURPASS HALF A BILLION\\', \\'summary\\': \\'Amazon has introduced a new lineup of Echo products, including the Echo Pop, Echo Show 5, Echo Show 5 Kids, and Echo Buds. They have also made Echo Auto available in several countries. Customers worldwide have purchased over half a billion Alexa-enabled devices.\\', \\'sentiment\\': \\'Positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2023-05-17 08:00:00\\', \\'title\\': \\'HOME IMPROVEMENT RETAILERS COMPETE WITH AMAZON AND WIN, J.D. POWER FINDS\\', \\'summary\\': \\'J.D. Power reports that home improvement retailers are successfully competing with Amazon.\\', \\'sentiment\\': \\'positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2023-05-17 05:00:00\\', \\'title\\': \\'ELAVON SIGNS EXCLUSIVE DEAL WITH AMAZON-APPROVED PARTNER THE DIGITAL LINE (TDL) TO LAUNCH NEW RANGE OF DIGITAL SERVICES IN HOSPITALITY INDUSTRY\\', \\'summary\\': \\'Global payments provider Elavon has partnered with The Digital Line (TDL) to develop a voice-activated solution for the hospitality industry called Audico. The solution utilizes the Amazon Alexa device to offer various voice-driven services. Elavon is the exclusive payments provider for Audico in the hospitality sector worldwide.\\', \\'sentiment\\': \\'positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2023-05-05 08:30:00\\', \\'title\\': \\'LIFEYIELD EXPANDS MANAGEMENT RANKS WITH PROMOTIONS; ADOPTS AMAZON WEB SERVICES FOR SCALABILITY AND OPERATIONAL EXCELLENCE\\', \\'summary\\': \\'LifeYield, a fintech leader in tax-efficient investing and income optimization, has announced the promotions of two product leaders to its senior management team. It has also adopted Amazon Web Services for cloud computing.\\', \\'sentiment\\': \\'positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2023-05-02 13:30:00\\', \\'title\\': \\'AMAZON BUSINESS KICKS OFF ITS SMALL BUSINESS MONTH WITH SMALL BUSINESS GRANTS DESIGNED TO SPUR INNOVATION AND GROWTH\\', \\'summary\\': \\'Amazon Business has announced the launch of small business grants and a new survey on small business data.\\', \\'sentiment\\': \\'Neutral\\', \\'sentimentScore\\': 5.0}, {\\'releaseDate\\': \\'2023-05-02 13:00:00\\', \\'title\\': \\'AMAZON OFFICIALLY LAUNCHES NEW STATE-OF-THE-ART FULFILLMENT CENTER IN WINDSOR\\', \\'summary\\': \\'Amazon celebrates the official opening of its new fulfillment center in Windsor, Connecticut\\', \\'sentiment\\': \\'Positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2023-05-01 11:38:00\\', \\'title\\': \\'SELLERCLOUD INTRODUCES NEW TOOLS FOR AMAZON SELLERS\\', \\'summary\\': \"SellerCloud, the omnichannel e-commerce growth platform, has introduced new tools to assist Amazon sellers in improving efficiency, automating workflows, and scaling. These tools include the ability to bulk ship orders using Amazon\\'s buy shipping, which enables sellers to take advantage of discounted shipping rates with major providers.\", \\'sentiment\\': \\'Positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2023-04-20 09:01:00\\', \\'title\\': \\'AMAZON ANNOUNCES ANTI-COUNTERFEITING EXCHANGE TO HELP ELIMINATE COUNTERFEITS ACROSS THE RETAIL INDUSTRY\\', \\'summary\\': \\'Amazon has announced the Anti-Counterfeiting Exchange (ACX), a collaboration aimed at improving online shopping safety and making it harder for counterfeiters to sell their goods across different stores. ACX enables participating stores to share information about confirmed counterfeiters.\\', \\'sentiment\\': \\'Positive\\', \\'sentimentScore\\': 8.5}]'}]\n"
     ]
    }
   ],
   "source": [
    "# For now we are calling API to get data, but otherwise we need to ensure the data is not persisted in our \n",
    "# index repository before calling again, if it is persisted then we need to delete it first\n",
    "step = \"3\"\n",
    "s3Data = []\n",
    "r = findPibData(SearchService, SearchKey, pibIndexName, cik, step, returnFields=['id', 'symbol', 'cik', 'step', 'description', 'insertedDate',\n",
    "                                                                   'pibData'])\n",
    "if r.get_count() == 0:\n",
    "    counter = 0\n",
    "    pressReleasesList = []\n",
    "    pressReleaseIndexName = 'pressreleases'\n",
    "    # Create the index if it does not exist\n",
    "    createPressReleaseIndex(SearchService, SearchKey, pressReleaseIndexName)\n",
    "    print(f\"Processing ticker : {symbol}\")\n",
    "    pr = pressReleases(apikey=apikey, symbol=symbol, limit=25)\n",
    "    for pressRelease in pr:\n",
    "        symbol = pressRelease['symbol']\n",
    "        releaseDate = pressRelease['date']\n",
    "        title = pressRelease['title']\n",
    "        content = pressRelease['text']\n",
    "        todayYmd = today.strftime(\"%Y-%m-%d\")\n",
    "        id = f\"{symbol}-{counter}\"\n",
    "        pressReleasesList.append({\n",
    "            \"id\": id,\n",
    "            \"symbol\": symbol,\n",
    "            \"releaseDate\": releaseDate,\n",
    "            \"title\": title,\n",
    "            \"content\": content,\n",
    "        })\n",
    "        counter = counter + 1\n",
    "\n",
    "    mergeDocs(SearchService, SearchKey, pressReleaseIndexName, pressReleasesList)\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=50)\n",
    "    rawPressReleasesDoc = [Document(page_content=t['content']) for t in pressReleasesList[:25]]\n",
    "    pressReleasesDocs = splitter.split_documents(rawPressReleasesDoc)\n",
    "    print(\"Number of documents chunks generated from Press releases : \", len(pressReleasesDocs))\n",
    "\n",
    "    pressReleasesPib = []\n",
    "    last25PressReleases = pressReleasesList[:25]\n",
    "    i = 0\n",
    "    for pDocs in pressReleasesDocs:\n",
    "        outputAnswer = summarizePressReleases(llmChat, [pDocs])\n",
    "        jsonStep = json.loads(outputAnswer)\n",
    "        pressReleasesPib.append({\n",
    "                \"releaseDate\": last25PressReleases[i]['releaseDate'],\n",
    "                \"title\": last25PressReleases[i]['title'],\n",
    "                \"summary\": jsonStep['summary'],\n",
    "                \"sentiment\": jsonStep['sentiment'],\n",
    "                \"sentimentScore\": jsonStep['sentiment score']\n",
    "        })\n",
    "        i = i + 1\n",
    "    \n",
    "    s3Data.append({\n",
    "                'id' : str(uuid.uuid4()),\n",
    "                'symbol': symbol,\n",
    "                'cik': cik,\n",
    "                'step': step,\n",
    "                'description': 'Press Releases',\n",
    "                'insertedDate': today.strftime(\"%Y-%m-%d\"),\n",
    "                'pibData' : str(pressReleasesPib)\n",
    "        })\n",
    "    mergeDocs(SearchService, SearchKey, pibIndexName, s3Data)\n",
    "else:\n",
    "    print('Found existing data')\n",
    "    for s in r:\n",
    "        s3Data.append(\n",
    "            {\n",
    "                'id' : s['id'],\n",
    "                'symbol': s['symbol'],\n",
    "                'cik': s['cik'],\n",
    "                'step': s['step'],\n",
    "                'description': s['description'],\n",
    "                'insertedDate': s['insertedDate'],\n",
    "                'pibData' : s['pibData']\n",
    "            })\n",
    "\n",
    "print(s3Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Paid Data - Get Stock News - Limit it to cover for current year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search index stocknews already exists\n",
      "Processing ticker : AAPL\n",
      "Total docs: 5000\n",
      "\tIndexed 1000 sections, 1000 succeeded\n",
      "\tIndexed 1000 sections, 1000 succeeded\n",
      "\tIndexed 1000 sections, 1000 succeeded\n",
      "\tIndexed 1000 sections, 1000 succeeded\n",
      "\tIndexed 1000 sections, 1000 succeeded\n"
     ]
    }
   ],
   "source": [
    "# For now we are calling API to get data, but otherwise we need to ensure the data is not persisted in our \n",
    "# index repository before calling again, if it is persisted then we need to delete it first\n",
    "counter = 0\n",
    "stockNewsList = []\n",
    "stockNewsIndexName = 'stocknews'\n",
    "# Create the index if it does not exist\n",
    "createStockNewsIndex(SearchService, SearchKey, stockNewsIndexName)\n",
    "print(f\"Processing ticker : {symbol}\")\n",
    "sn = stockNews(apikey=apikey, tickers=symbol, limit=5000)\n",
    "for news in sn:\n",
    "    symbol = news['symbol']\n",
    "    publishedDate = news['publishedDate']\n",
    "    title = news['title']\n",
    "    image = news['image']\n",
    "    site = news['site']\n",
    "    content = news['text']\n",
    "    url = news['url']\n",
    "    todayYmd = today.strftime(\"%Y-%m-%d\")\n",
    "    id = f\"{symbol}-{todayYmd}-{counter}\"\n",
    "    stockNewsList.append({\n",
    "        \"id\": id,\n",
    "        \"symbol\": symbol,\n",
    "        \"publishedDate\": publishedDate,\n",
    "        \"title\": title,\n",
    "        \"image\": image,\n",
    "        \"site\": site,\n",
    "        \"content\": content,\n",
    "        \"url\": url,\n",
    "    })\n",
    "    counter = counter + 1\n",
    "mergeDocs(SearchService, SearchKey, stockNewsIndexName, stockNewsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents chunks generated from Press releases :  16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group our news by Date and summarize the content and sentimet per day\n",
    "stocksDf = pd.DataFrame.from_dict(pd.json_normalize(stockNewsList))\n",
    "stocksDf['publishedDate'] = pd.to_datetime(stocksDf['publishedDate']).dt.date\n",
    "stocksNewsDailyDf = stocksDf.sort_values('publishedDate').groupby('publishedDate')['content'].apply('\\n'.join).reset_index()\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=50)\n",
    "rawNewsDocs = [Document(page_content=row['content']) for index, row in stocksNewsDailyDf.tail(10).iterrows()]\n",
    "newsDocs = splitter.split_documents(rawNewsDocs)\n",
    "print(\"Number of documents chunks generated from Press releases : \", len(newsDocs))\n",
    "\n",
    "# With the data indexed, let's summarize the information\n",
    "promptTemplate = \"\"\"You are an AI assistant tasked with summarizing news related to company and performing sentiments on those. \n",
    "        Your summary should accurately capture the key information in the document while avoiding the omission of any domain-specific words. \n",
    "        Please generate a concise and comprehensive summary and sentiment with score with range of 0 to 10. Your response should be in JSON format with following keys.\n",
    "        summary: \n",
    "        sentiment:\n",
    "        sentiment score:\n",
    "        Please remember to use clear language and maintain the integrity of the original information without missing any important details.\n",
    "        {text}\n",
    "        \"\"\"\n",
    "customPrompt = PromptTemplate(template=promptTemplate, input_variables=[\"text\"])\n",
    "chainType = \"map_reduce\"\n",
    "summaryChain = load_summarize_chain(llm, chain_type=chainType, return_intermediate_steps=True, \n",
    "                                    map_prompt=customPrompt, combine_prompt=customPrompt)\n",
    "summary = summaryChain({\"input_documents\": newsDocs}, return_only_outputs=True)\n",
    "outputAnswer = summary['output_text']\n",
    "print(outputAnswer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b> \n",
       "Summary: Goldman Sachs is reportedly in discussions with American Express to take over its credit card and other collaborations with Apple, which recently became the first public company to close a trading day with a market cap over $3 trillion. Apple has achieved success in consumer tech and AI is a growing part of its business. Warren Buffett has nearly half of his portfolio in the tech giant, while stocks like Nvidia have soared but are trading at pricey valuations. The U.S. Supreme Court recently dismantled Biden's student loan forgiveness, leaving winners and losers.\n",
       "\n",
       "Sentiment: Neutral\n",
       "\n",
       "Sentiment Score: 5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b> \n",
       "{\n",
       "    \"summary\": \"Apple Inc. has surpassed a market value of $3 trillion and is reportedly looking to take its battle with Epic Games to the Supreme Court. Apple is also exploring the game-changing potential of the Vision Pro, its mixed reality headset, and has lowered its production targets for the device. The tech behemoth does not expect to start selling the device until early next year, and stellar gains in the first half point to more strength ahead.\",\n",
       "    \"sentiment\": \"positive\",\n",
       "    \"sentiment score\": 8\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b> \n",
       "Summary: Apple Inc. is reducing production targets for its Vision Pro headset due to manufacturers struggling with its complex design. Apple's market valuation recently soared to $3 trillion, and tech stocks are forecasted to embark on a resurgence in the second half of the year.\n",
       "Sentiment: Positive\n",
       "Sentiment Score: 8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b> \n",
       "Summary: Apple Inc. NASDAQ: AAPL, Microsoft Corp. NASDAQ: MSFT, Nvidia Corp. NASDAQ: NVDA, Broadcom Inc. NASDAQ: AVGO and Adobe Inc. NASDAQ: ADBE posted double-digit price increases in the second quarter due to the AI boom. AT&T stock is being sold at a discounted price due to slumping profits. Apple is scaling back the manufacturing of its Vision Pro goggles for 2024, and Oracle of Omaha has doubled up the average annual total return of the S&P 500 since becoming CEO nearly 60 years ago. Apple Component Supplier Stocks have gained 13% year-to-date, and Apple is reportedly slashing production goals for its Vision Pro headset due to manufacturers struggling with its complex design.\n",
       "\n",
       "Sentiment: Neutral\n",
       "Sentiment Score: 5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b> \n",
       "{\n",
       "    \"summary\": \"Apple (AAPL) made Wall Street history as the first company to reach a market capitalization of $3 trillion at the close on Jun 30. However, the company has cut its target for production of its Vision Pro augmented-reality headset just four weeks after the launch of the US$5,000 apiece goggles to huge fanfare due to the complexity of the tech involved.\",\n",
       "    \"sentiment\": \"positive\",\n",
       "    \"sentiment score\": 8\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b> \n",
       "Summary: Apple lost an appeal in a long-running patent dispute, Invesco QQQ is up 40% year-to-date, Xreal has shipped 200,000 augmented reality glasses, and new investors should wait for a potential pullback in Apple stock due to negative global economic sentiment. Alphabet's Google, Amazon, Apple, Meta Platforms and Microsoft have notified the European Commission that they qualify as gatekeepers under new EU tech rules.\n",
       "\n",
       "Sentiment: Neutral\n",
       "\n",
       "Sentiment Score: 5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b> \n",
       "{\n",
       "    \"summary\": \"Seven tech giants, including Amazon and Apple, have informed the European Union that they meet the threshold to come under new rules to curb their market dominance, according to Brussels.\",\n",
       "    \"sentiment\": \"positive\",\n",
       "    \"sentiment score\": 8\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b> \n",
       "Summary: Barclays downgraded shares of laser maker Lumentum to Underweight from Equal Weight, Wedbush analyst Dan Ives believes that ChatGPT will be the \"next leg of growth\" for Microsoft, Apple (AAPL) lost its long legal fight over patent terms, The Goldman Sachs Group is reportedly in talks with American Express Co. regarding its Apple Inc. credit card and other consumer-focused products connected with Apple, Intuitive Surgical's robotic systems are improving patient outcomes, ExxonMobil is quickly becoming a leader in low-carbon energy solutions, and five U.S. corporate behemoths have taken solid ESG initiatives. Giant of contract electronics manufacturing sees revenue drop almost 20% year over year in June.\n",
       "\n",
       "Sentiment: Neutral\n",
       "Sentiment Score: 5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b> \n",
       "Summary: Analysts recommend buying Apple stock, but the average 12-month price target for the stock doesn't reflect much enthusiasm. The Dow Jones Industrial Average fell 1.1%, or 366 points, Thursday due to strong labor market data. Single-stock ETFs have become popular in the past year, and the latest developments in artificial intelligence continue to make headlines. Kopin Co. NASDAQ: KOPN stock is still trading down over 80% from its post-COVID highs in 2021, and Apple declined below the $3 trillion market cap level on Thursday.\n",
       "\n",
       "Sentiment: Negative\n",
       "Sentiment Score: 4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b> \n",
       "{\n",
       "    \"summary\": \"Apple is planning to launch its Vision Pro headset with appointments and in-store promotion in select US markets early next year. On Friday, the U.S. stock market remained significantly overvalued based on Warren Buffett's market indicator concept. Momentum stocks offer investors the opportunity to capitalize on strong and continued upward price changes, but it is an inherently and undeniably risky trading method. An institutional investor is a legal entity that pools money from multiple investors to invest in various assets and securities.\",\n",
       "    \"sentiment\": \"positive\",\n",
       "    \"sentiment score\": 8\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b> \n",
       "{\n",
       "    \"summary\": \"Growth stocks are stocks that have consistently outperformed the market over a long period of time and are a great addition to any investor's portfolio.\",\n",
       "    \"sentiment\": \"Positive\",\n",
       "    \"sentiment score\": 10\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b> \n",
       "Summary: Apple is planning to require an appointment to purchase its upcoming Vision Pro headset. U.S. stock investors are uncertain about the rest of 2023, but Apple's installed base is growing and Netflix has rebounded from last year's subscriber declines. Apple and Costco's stocks have risen over 150% since 2018 due to Apple's leading market shares.\n",
       "\n",
       "Sentiment: Positive\n",
       "\n",
       "Sentiment Score: 8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b> \n",
       "{\n",
       "    \"summary\": \"In the short holiday trading week, 3 out of 4 picks gained over 9% with peak gains in ONCY +23.9% and RIG +20.6%. The S&P 500 declined -1.16%. Two new sample Breakout Stocks for Week 28 with better than 10% short-term upside and two Dow 30 Picks were released with average cumulative returns for 2023 up to +113.3% YTD. The streak of weekly picks gaining over 10% in less than a week has reached 253 out of 319 trading weeks (79.3%) not considering multiple gainers or negative MG signals.\",\n",
       "    \"sentiment\": \"positive\",\n",
       "    \"sentiment score\": 10\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b> \n",
       "Summary: Apple reported a downbeat set of earnings for the first half of its fiscal 2023, but scored a few records for iPhone and services revenue. Foxconn Technology Co Ltd (TPE: 2354) is pulling out of a joint venture with Vedanta and Nasdaq plans to rebalance the Nasdaq 100 stock index. Apple shares have skyrocketed almost 50% since Jan. 1 and Dow Jones gained 175 points though Microsoft, Apple plunged.\n",
       "\n",
       "Sentiment: Positive\n",
       "\n",
       "Sentiment Score: 8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b> \n",
       "{\n",
       "    \"summary\": \"Apple (AAPL) has a market capitalization of $2.95 trillion and is expanding Apple News content with the returning season of After the Whistle with Brendan Hunt and Rebecca Lowe. PC sales have declined for six straight quarters, but HP and Apple shipments were resilient. WeChat is China's biggest messaging platform with over 1.2 billion users and opens another retail channel for Apple to sell its products. Jefferies analyst Daniel Fannon cut his earnings estimates for Goldman Sachs Group Inc. and Morgan Stanley ahead of second-quarter updates from the banks. Proprietary data analyzed by KeyBanc suggest Apple faces a slowdown in hardware sales, but there may be bigger forces moving the stock price. Apple Store's official online store went live on Tencent's WeChat mini programme on Tuesday.\",\n",
       "    \"sentiment\": \"positive\",\n",
       "    \"sentiment score\": 8\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b> \n",
       "{\n",
       "    \"summary\": \"Apple Inc. may have seen better monthly sales improvement in June than usual, but an analyst at KeyBanc Capital Markets is still cautious. The Dow Jones moved higher by nearly 1%, as investors anticipate tomorrow's key inflation data.\",\n",
       "    \"sentiment\": \"Cautious\",\n",
       "    \"sentiment score\": 5\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For the chaintype of MapReduce and Refine, we can also get insight into intermediate steps of the pipeline.\n",
    "# This way you can inspect the results from map_reduce chain type, each top similar chunk summary\n",
    "intermediateSteps = summary['intermediate_steps']\n",
    "for step in intermediateSteps:\n",
    "        display(HTML(\"<b>Chunk Summary:</b> \" + step))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Public Data - Get the SEC Filings - Limit it to cover for last 3 year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "filingType = \"10-K\"\n",
    "secFilingsList = secFilings(apikey=apikey, symbol=symbol, filing_type=filingType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "latestFilingDateTime = datetime.strptime(secFilingsList[0]['fillingDate'], '%Y-%m-%d %H:%M:%S')\n",
    "latestFilingDate = latestFilingDateTime.strftime(\"%Y-%m-%d\")\n",
    "secFilingIndexName = 'secdata'\n",
    "secFilingList = []\n",
    "emptyBody = {\n",
    "        \"values\": [\n",
    "            {\n",
    "                \"recordId\": 0,\n",
    "                \"data\": {\n",
    "                    \"text\": \"\"\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "}\n",
    "\n",
    "secExtractBody = {\n",
    "    \"values\": [\n",
    "        {\n",
    "            \"recordId\": 0,\n",
    "            \"data\": {\n",
    "                \"text\": {\n",
    "                    \"edgar_crawler\": {\n",
    "                        \"start_year\": int(currentYear),\n",
    "                        \"end_year\": int(currentYear),\n",
    "                        \"quarters\": [1,2,3,4],\n",
    "                        \"filing_types\": [\n",
    "                            \"10-K\"\n",
    "                        ],\n",
    "                        \"cik_tickers\": [cik],\n",
    "                        \"user_agent\": \"Your name (your email)\",\n",
    "                        \"raw_filings_folder\": \"RAW_FILINGS\",\n",
    "                        \"indices_folder\": \"INDICES\",\n",
    "                        \"filings_metadata_file\": \"FILINGS_METADATA.csv\",\n",
    "                        \"skip_present_indices\": True\n",
    "                    },\n",
    "                    \"extract_items\": {\n",
    "                        \"raw_filings_folder\": \"RAW_FILINGS\",\n",
    "                        \"extracted_filings_folder\": \"EXTRACTED_FILINGS\",\n",
    "                        \"filings_metadata_file\": \"FILINGS_METADATA.csv\",\n",
    "                        \"items_to_extract\": [\"1\",\"1A\",\"1B\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"7A\",\"8\",\"9\",\"9A\",\"9B\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\"],\n",
    "                        \"remove_tables\": True,\n",
    "                        \"skip_extracted_filings\": True\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Check if we have already processed the latest filing, if yes then skip\n",
    "createSecFilingIndex(SearchService, SearchKey, secFilingIndexName)\n",
    "r = findSecFiling(SearchService, SearchKey, secFilingIndexName, cik, filingType, latestFilingDate, returnFields=['id', 'cik', 'company', 'filingType', 'filingDate',\n",
    "                                                                                                                 'periodOfReport', 'sic', 'stateOfInc', 'fiscalYearEnd',\n",
    "                                                                                                                 'filingHtmlIndex', 'htmFilingLink', 'completeTextFilingLink',\n",
    "                                                                                                                 'item1', 'item1A', 'item1B', 'item2', 'item3', 'item4', 'item5',\n",
    "                                                                                                                 'item6', 'item7', 'item7A', 'item8', 'item9', 'item9A', 'item9B',\n",
    "                                                                                                                 'item10', 'item11', 'item12', 'item13', 'item14', 'item15',\n",
    "                                                                                                                 'sourcefile'])\n",
    "if r.get_count() == 0:\n",
    "    # Call Azure Function to perform Web-scraping and store the JSON in our blob\n",
    "    secExtract = requests.post(SecExtractionUrl, json = secExtractBody)\n",
    "    # Once the JSON is created, call the function to process the JSON and store the data in our index\n",
    "    docPersistUrl = SecDocPersistUrl + \"&indexType=cogsearchvs&indexName=\" + secFilingIndexName + \"&embeddingModelType=\" + embeddingModelType\n",
    "    secPersist = requests.post(docPersistUrl, json = emptyBody)\n",
    "    r = findSecFiling(SearchService, SearchKey, secFilingIndexName, cik, filingType, latestFilingDate, returnFields=['id', 'cik', 'company', 'filingType', 'filingDate',\n",
    "                                                                                                                 'periodOfReport', 'sic', 'stateOfInc', 'fiscalYearEnd',\n",
    "                                                                                                                 'filingHtmlIndex', 'htmFilingLink', 'completeTextFilingLink',\n",
    "                                                                                                                 'item1', 'item1A', 'item1B', 'item2', 'item3', 'item4', 'item5',\n",
    "                                                                                                                 'item6', 'item7', 'item7A', 'item8', 'item9', 'item9A', 'item9B',\n",
    "                                                                                                                 'item10', 'item11', 'item12', 'item13', 'item14', 'item15',\n",
    "                                                                                                                 'sourcefile'])\n",
    "\n",
    "# Retrieve the latest filing from our index\n",
    "for filing in r:\n",
    "    secFilingList.append({\n",
    "        \"id\": filing['id'],\n",
    "        \"cik\": filing['cik'],\n",
    "        \"company\": filing['company'],\n",
    "        \"filingType\": filing['filingType'],\n",
    "        \"filingDate\": filing['filingDate'],\n",
    "        \"periodOfReport\": filing['periodOfReport'],\n",
    "        \"sic\": filing['sic'],\n",
    "        \"stateOfInc\": filing['stateOfInc'],\n",
    "        \"fiscalYearEnd\": filing['fiscalYearEnd'],\n",
    "        \"filingHtmlIndex\": filing['filingHtmlIndex'],\n",
    "        \"completeTextFilingLink\": filing['completeTextFilingLink'],\n",
    "        \"item1\": filing['item1'],\n",
    "        \"item1A\": filing['item1A'],\n",
    "        \"item1B\": filing['item1B'],\n",
    "        \"item2\": filing['item2'],\n",
    "        \"item3\": filing['item3'],\n",
    "        \"item4\": filing['item4'],\n",
    "        \"item5\": filing['item5'],\n",
    "        \"item6\": filing['item6'],\n",
    "        \"item7\": filing['item7'],\n",
    "        \"item7A\": filing['item7A'],\n",
    "        \"item8\": filing['item8'],\n",
    "        \"item9\": filing['item9'],\n",
    "        \"item9A\": filing['item9A'],\n",
    "        \"item9B\": filing['item9B'],\n",
    "        \"item10\": filing['item10'],\n",
    "        \"item11\": filing['item11'],\n",
    "        \"item12\": filing['item12'],\n",
    "        \"item13\": filing['item13'],\n",
    "        \"item14\": filing['item14'],\n",
    "        \"item15\": filing['item15'],\n",
    "        \"sourcefile\": filing['sourcefile']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateSummaries(docs):\n",
    "    chainType = \"map_reduce\"\n",
    "    summaryChain = load_summarize_chain(llm, chain_type=chainType)\n",
    "    summary = summaryChain({\"input_documents\": docs}, return_only_outputs=True)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents chunks generated from Item1 :  1\n",
      "Number of documents chunks generated from Item1A :  8\n",
      "Number of documents chunks generated from Item3 :  1\n",
      "Number of documents chunks generated from Item5 :  1\n",
      "Number of documents chunks generated from Item7 :  7\n",
      "Number of documents chunks generated from Item7A :  1\n",
      "Number of documents chunks generated from Item9 :  1\n",
      "Total docs: 1\n",
      "\tIndexed 1 sections, 1 succeeded\n"
     ]
    }
   ],
   "source": [
    "step = \"4\"\n",
    "s4Data = []\n",
    "\n",
    "r = findPibData(SearchService, SearchKey, pibIndexName, cik, step, returnFields=['id', 'symbol', 'cik', 'step', 'description', 'insertedDate',\n",
    "                                                                   'pibData'])\n",
    "\n",
    "if r.get_count() == 0:\n",
    "        secFilingsPib = []\n",
    "\n",
    "        # For different section of extracted data, process summarization and generate common answers to questions\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size=8000, chunk_overlap=0)\n",
    "\n",
    "        # Item 1 - Describes the business of the company\n",
    "        rawItemDocs1 = [Document(page_content=secFilingList[0]['item1'])]\n",
    "        itemDocs1 = splitter.split_documents(rawItemDocs1)\n",
    "        print(\"Number of documents chunks generated from Item1 : \", len(itemDocs1))\n",
    "        summary1 = generateSummaries(itemDocs1)\n",
    "        outputAnswer1 = summary1['output_text']\n",
    "        secFilingsPib.append({\n",
    "                        \"section\": \"item1\",\n",
    "                        \"summaryType\": \"Business Description\",\n",
    "                        \"summary\": outputAnswer1\n",
    "                })\n",
    "\n",
    "        # Item 1A - Risk Factors\n",
    "        rawItemDocs2 = [Document(page_content=secFilingList[0]['item1A'])]\n",
    "        itemDocs2 = splitter.split_documents(rawItemDocs2)\n",
    "        print(\"Number of documents chunks generated from Item1A : \", len(itemDocs2))\n",
    "        summary2 = generateSummaries(itemDocs2)\n",
    "        outputAnswer2 = summary2['output_text']\n",
    "        secFilingsPib.append({\n",
    "                        \"section\": \"item1A\",\n",
    "                        \"summaryType\": \"Risk Factors\",\n",
    "                        \"summary\": outputAnswer2\n",
    "                })\n",
    "\n",
    "        rawItemDocs2 = [Document(page_content=secFilingList[0]['item3'])]\n",
    "        itemDocs2 = splitter.split_documents(rawItemDocs2)\n",
    "        print(\"Number of documents chunks generated from Item3 : \", len(itemDocs2))\n",
    "        summary2 = generateSummaries(itemDocs2)\n",
    "        outputAnswer2 = summary2['output_text']\n",
    "        secFilingsPib.append({\n",
    "                        \"section\": \"item3\",\n",
    "                        \"summaryType\": \"Legal Proceedings\",\n",
    "                        \"summary\": outputAnswer2\n",
    "                })\n",
    "\n",
    "        # Item 6 - Consolidated Financial Data\n",
    "        rawItemDocs3 = [Document(page_content=secFilingList[0]['item5'])]\n",
    "        itemDocs3 = splitter.split_documents(rawItemDocs3)\n",
    "        print(\"Number of documents chunks generated from Item5 : \", len(itemDocs3))\n",
    "        summary3 = generateSummaries(itemDocs3)\n",
    "        outputAnswer3 = summary3['output_text']\n",
    "        secFilingsPib.append({\n",
    "                        \"section\": \"item5\",\n",
    "                        \"summaryType\": \"Market\",\n",
    "                        \"summary\": outputAnswer3\n",
    "                })\n",
    "\n",
    "        # Item 7 - Management's Discussion and Analysis of Financial Condition and Results of Operations\n",
    "        rawItemDocs4 = [Document(page_content=secFilingList[0]['item7'])]\n",
    "        itemDocs4 = splitter.split_documents(rawItemDocs4)\n",
    "        print(\"Number of documents chunks generated from Item7 : \", len(itemDocs4))\n",
    "        summary4 = generateSummaries(itemDocs4)\n",
    "        outputAnswer4 = summary4['output_text']\n",
    "        secFilingsPib.append({\n",
    "                        \"section\": \"item7\",\n",
    "                        \"summaryType\": \"Management Discussion\",\n",
    "                        \"summary\": outputAnswer4\n",
    "                })\n",
    "\n",
    "        # Item 7a - Market risk disclosures\n",
    "        rawItemDocs5 = [Document(page_content=secFilingList[0]['item7A'])]\n",
    "        itemDocs5= splitter.split_documents(rawItemDocs5)\n",
    "        print(\"Number of documents chunks generated from Item7A : \", len(itemDocs5))\n",
    "        summary5 = generateSummaries(itemDocs5)\n",
    "        outputAnswer5 = summary5['output_text']\n",
    "        secFilingsPib.append({\n",
    "                        \"section\": \"item7A\",\n",
    "                        \"summaryType\": \"Risk Disclosures\",\n",
    "                        \"summary\": outputAnswer5\n",
    "                })\n",
    "\n",
    "        # Item 9 - Disagreements with accountants and changes in accounting\n",
    "        section9 = secFilingList[0]['item9'] + \"\\n \" + secFilingList[0]['item9A'] + \"\\n \" + secFilingList[0]['item9B']\n",
    "        rawItemDocs6 = [Document(page_content=section9)]\n",
    "        itemDocs6 = splitter.split_documents(rawItemDocs6)\n",
    "        print(\"Number of documents chunks generated from Item9 : \", len(itemDocs6))\n",
    "        summary6 = generateSummaries(itemDocs6)\n",
    "        outputAnswer6 = summary6['output_text']\n",
    "        secFilingsPib.append({\n",
    "                        \"section\": \"item9\",\n",
    "                        \"summaryType\": \"Accounting Disclosures\",\n",
    "                        \"summary\": outputAnswer6\n",
    "                })\n",
    "        \n",
    "        s4Data.append({\n",
    "                'id' : str(uuid.uuid4()),\n",
    "                'symbol': symbol,\n",
    "                'cik': cik,\n",
    "                'step': step,\n",
    "                'description': 'SEC Filings',\n",
    "                'insertedDate': today.strftime(\"%Y-%m-%d\"),\n",
    "                'pibData' : str(secFilingsPib)\n",
    "        })\n",
    "        mergeDocs(SearchService, SearchKey, pibIndexName, s4Data)\n",
    "else:\n",
    "        print(\"Step 4 data already exists in the index\")\n",
    "        for item in r:\n",
    "                s4Data.append({\n",
    "                        'id' : item['id'],\n",
    "                        'symbol': item['symbol'],\n",
    "                        'cik': item['cik'],\n",
    "                        'step': item['step'],\n",
    "                        'description': item['description'],\n",
    "                        'insertedDate': item['insertedDate'],\n",
    "                        'pibData' : item['pibData']\n",
    "                })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Private Data - Equity Research Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azure.search.documents import SearchClient\n",
    "# from azure.core.credentials import AzureKeyCredential\n",
    "# step = \"5\"\n",
    "# searchClient = SearchClient(endpoint=f\"https://{SearchService}.search.windows.net\",\n",
    "#         index_name=pibIndexName,\n",
    "#         credential=AzureKeyCredential(SearchKey))\n",
    "# r = searchClient.search(  \n",
    "#     search_text=\"\",\n",
    "#     filter=\"cik eq '\" + cik + \"' and step eq '\" + step + \"'\",\n",
    "#     select=[\"id\"],\n",
    "#     semantic_configuration_name=\"semanticConfig\",\n",
    "#     include_total_count=True\n",
    "# )\n",
    "# if r.get_count() > 0:\n",
    "#     for doc in r:\n",
    "#         searchClient.delete_documents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total docs: 1\n",
      "\tIndexed 1 sections, 1 succeeded\n"
     ]
    }
   ],
   "source": [
    "step = \"5\"\n",
    "s5Data = []\n",
    "symbol = 'MSFT'\n",
    "cik = '789019'\n",
    "\n",
    "r = findPibData(SearchService, SearchKey, pibIndexName, cik, step, returnFields=['id', 'symbol', 'cik', 'step', 'description', 'insertedDate',\n",
    "                                                                   'pibData'])\n",
    "\n",
    "if r.get_count() == 0:\n",
    "    companyRating = rating(apikey=apikey, symbol=symbol)\n",
    "    fScore = financialScore(apikey=apikey, symbol=symbol)\n",
    "    esgScores = esgScore(apikey=apikey, symbol=symbol)\n",
    "    esgRating = esgRatings(apikey=apikey, symbol=symbol)\n",
    "    ugConsensus = upgradeDowngrades(apikey=apikey, symbol=symbol)\n",
    "    priceConsensus = priceTarget(apikey=apikey, symbol=symbol)\n",
    "    #ratingsDf = pd.DataFrame.from_dict(pd.json_normalize(companyRating))\n",
    "    researchReport = []\n",
    "\n",
    "    researchReport.append({\n",
    "        \"key\": \"Overall Recommendation\",\n",
    "        \"value\": companyRating[0]['ratingRecommendation']\n",
    "    })\n",
    "    researchReport.append({\n",
    "        \"key\": \"DCF Recommendation\",\n",
    "        \"value\": companyRating[0]['ratingDetailsDCFRecommendation']\n",
    "    })\n",
    "    researchReport.append({\n",
    "        \"key\": \"ROE Recommendation\",\n",
    "        \"value\": companyRating[0]['ratingDetailsROERecommendation']\n",
    "    })\n",
    "    researchReport.append({\n",
    "        \"key\": \"ROA Recommendation\",\n",
    "        \"value\": companyRating[0]['ratingDetailsROARecommendation']\n",
    "    })\n",
    "    researchReport.append({\n",
    "        \"key\": \"PB Recommendation\",\n",
    "        \"value\": companyRating[0]['ratingDetailsPBRecommendation']\n",
    "    })\n",
    "    researchReport.append({\n",
    "        \"key\": \"PE Recommendation\",\n",
    "        \"value\": companyRating[0]['ratingDetailsPERecommendation']\n",
    "    })\n",
    "    researchReport.append({\n",
    "        \"key\": \"Altman ZScore\",\n",
    "        \"value\": fScore[0]['altmanZScore']\n",
    "    })\n",
    "    researchReport.append({\n",
    "        \"key\": \"Piotroski Score\",\n",
    "        \"value\": fScore[0]['piotroskiScore']\n",
    "    })\n",
    "    researchReport.append({\n",
    "        \"key\": \"Environmental Score\",\n",
    "        \"value\": esgScores[0]['environmentalScore']\n",
    "    })\n",
    "    researchReport.append({\n",
    "        \"key\": \"Social Score\",\n",
    "        \"value\": esgScores[0]['socialScore']\n",
    "    })\n",
    "    researchReport.append({\n",
    "        \"key\": \"Governance Score\",\n",
    "        \"value\": esgScores[0]['governanceScore']\n",
    "    })\n",
    "    researchReport.append({\n",
    "        \"key\": \"ESG Score\",\n",
    "        \"value\": esgScores[0]['ESGScore']\n",
    "    })\n",
    "    researchReport.append({\n",
    "        \"key\": \"ESG RIsk Rating\",\n",
    "        \"value\": esgRating[0]['ESGRiskRating']\n",
    "    })\n",
    "    researchReport.append({\n",
    "        \"key\": \"Analyst Consensus Buy\",\n",
    "        \"value\": ugConsensus[0]['buy']\n",
    "    })\n",
    "    researchReport.append({\n",
    "        \"key\": \"Analyst Consensus Sell\",\n",
    "        \"value\": ugConsensus[0]['sell']\n",
    "    })\n",
    "    researchReport.append({\n",
    "        \"key\": \"Analyst Consensus Strong Buy\",\n",
    "        \"value\": ugConsensus[0]['strongBuy']\n",
    "    })\n",
    "    researchReport.append({\n",
    "        \"key\": \"Analyst Consensus Strong Sell\",\n",
    "        \"value\": ugConsensus[0]['strongSell']\n",
    "    })\n",
    "    researchReport.append({\n",
    "        \"key\": \"Analyst Consensus Hold\",\n",
    "        \"value\": ugConsensus[0]['hold']\n",
    "    })\n",
    "    researchReport.append({\n",
    "        \"key\": \"Analyst Consensus\",\n",
    "        \"value\": ugConsensus[0]['consensus']\n",
    "    })\n",
    "    # researchReport.append({\n",
    "    #     \"key\": \"Price Target Consensus\",\n",
    "    #     \"value\": priceConsensus[0]['targetConsensus']\n",
    "    # })\n",
    "    # researchReport.append({\n",
    "    #     \"key\": \"Price Target Median\",\n",
    "    #     \"value\": priceConsensus[0]['targetMedian']\n",
    "    # })\n",
    "  \n",
    "    s5Data.append({\n",
    "                'id' : str(uuid.uuid4()),\n",
    "                'symbol': symbol,\n",
    "                'cik': cik,\n",
    "                'step': step,\n",
    "                'description': 'Research Report',\n",
    "                'insertedDate': today.strftime(\"%Y-%m-%d\"),\n",
    "                'pibData' : str(researchReport)\n",
    "        })\n",
    "    mergeDocs(SearchService, SearchKey, pibIndexName, s5Data)\n",
    "else:\n",
    "    for s in r:\n",
    "        s5Data.append(\n",
    "            {\n",
    "                'id' : s['id'],\n",
    "                'symbol': s['symbol'],\n",
    "                'cik': s['cik'],\n",
    "                'step': s['step'],\n",
    "                'description': s['description'],\n",
    "                'insertedDate': s['insertedDate'],\n",
    "                'pibData' : s['pibData']\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "searchClient = SearchClient(endpoint=f\"https://{SearchService}.search.windows.net\",\n",
    "    index_name=pibIndexName,\n",
    "    credential=AzureKeyCredential(SearchKey))\n",
    "\n",
    "r = searchClient.search(  \n",
    "    search_text=\"\",\n",
    "    filter=\"cik eq '\" + \"789019\" + \"' and step eq '\" + \"2\" + \"'\",\n",
    "    select=[\"id\"],\n",
    "    semantic_configuration_name=\"semanticConfig\",\n",
    "    include_total_count=True\n",
    ")\n",
    "if r.get_count() > 0:\n",
    "    for doc in r:\n",
    "        searchClient.delete_documents(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Paid Data - Investor Presentations - Financial Reports (Balance Sheet, Income Statement and Cash Flow) for last 3 years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deletePibData(SearchService, SearchKey, pibIndexName, \"896159\", \"1\", returnFields=['id', 'symbol', 'cik', 'step', 'description', 'insertedDate',\n",
    "#                                                                     'pibData'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
