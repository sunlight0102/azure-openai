{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "import json  \n",
    "import openai\n",
    "from Utilities.envVars import *\n",
    "import uuid\n",
    "\n",
    "# Set OpenAI API key and endpoint\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = OpenAiVersion\n",
    "openai_api_key = OpenAiKey\n",
    "assert openai_api_key, \"ERROR: Azure OpenAI Key is missing\"\n",
    "openai.api_key = openai_api_key\n",
    "openAiEndPoint = f\"{OpenAiEndPoint}\"\n",
    "assert openAiEndPoint, \"ERROR: Azure OpenAI Endpoint is missing\"\n",
    "assert \"openai.azure.com\" in openAiEndPoint.lower(), \"ERROR: Azure OpenAI Endpoint should be in the form: \\n\\n\\t<your unique endpoint identifier>.openai.azure.com\"\n",
    "openai.api_base = openAiEndPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "embeddingModelType = \"azureopenai\"\n",
    "temperature = 0\n",
    "tokenLength = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.utilities import BingSearchAPIWrapper\n",
    "from langchain.docstore.document import Document\n",
    "import pandas as pd\n",
    "from langchain.prompts import PromptTemplate\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import timedelta\n",
    "import typing\n",
    "from langchain.chat_models import AzureChatOpenAI, ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "# Import required libraries\n",
    "# Import required libraries\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import (\n",
    "    PDFMinerLoader,\n",
    "    UnstructuredFileLoader,\n",
    ")\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from IPython.display import display, HTML\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from Utilities.pibCopilot import createSearchIndex, indexSections, findFileInIndex, performCogSearch, mergeDocs, createProspectusSummary, findTopicSummaryInIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flexibility to change the call to OpenAI or Azure OpenAI\n",
    "if (embeddingModelType == 'azureopenai'):\n",
    "    openai.api_type = \"azure\"\n",
    "    openai.api_key = OpenAiKey\n",
    "    openai.api_version = OpenAiVersion\n",
    "    openai.api_base = OpenAiEndPoint\n",
    "\n",
    "    llm = AzureChatOpenAI(\n",
    "                openai_api_base=openai.api_base,\n",
    "                openai_api_version=OpenAiVersion,\n",
    "                deployment_name=OpenAiChat16k,\n",
    "                temperature=temperature,\n",
    "                openai_api_key=OpenAiKey,\n",
    "                openai_api_type=\"azure\",\n",
    "                max_tokens=tokenLength)\n",
    "    \n",
    "    logging.info(\"LLM Setup done\")\n",
    "    embeddings = OpenAIEmbeddings(deployment=OpenAiEmbedding, openai_api_key=OpenAiKey, openai_api_type=\"azure\")\n",
    "elif embeddingModelType == \"openai\":\n",
    "    openai.api_type = \"open_ai\"\n",
    "    openai.api_base = \"https://api.openai.com/v1\"\n",
    "    openai.api_version = '2020-11-07' \n",
    "    openai.api_key = OpenAiApiKey\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=OpenAiApiKey)\n",
    "\n",
    "    llm = ChatOpenAI(temperature=temperature,\n",
    "        openai_api_key=OpenAiApiKey,\n",
    "        model_name=\"gpt-3.5-turbo\",\n",
    "        max_tokens=tokenLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the file name and the namespace for the index\n",
    "fileName = \"Bumble Bee.pdf\"\n",
    "pdfPath = \"Data/PDF/\" + fileName\n",
    "# Load the PDF with Document Loader available from Langchain\n",
    "loader = PDFMinerLoader(pdfPath)\n",
    "rawDocs = loader.load()\n",
    "# Set the source \n",
    "for doc in rawDocs:\n",
    "    doc.metadata['source'] = pdfPath\n",
    "\n",
    "textSplitter = RecursiveCharacterTextSplitter(chunk_size=8000, chunk_overlap=1000)\n",
    "docs = textSplitter.split_documents(rawDocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents chunks generated from PDF :  162\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of documents chunks generated from PDF : \", len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found in index\n"
     ]
    }
   ],
   "source": [
    "indexName = 'prospectus'\n",
    "r = findFileInIndex(SearchService, SearchKey, indexName, fileName)\n",
    "if r.get_count() == 0:\n",
    "    # Call Helper function to create Index and Index the sections\n",
    "    createSearchIndex(SearchService, SearchKey, indexName)\n",
    "    indexSections(OpenAiEndPoint, OpenAiKey, OpenAiVersion, OpenAiApiKey, SearchService, SearchKey, embeddingModelType, OpenAiEmbedding, fileName, indexName, docs)\n",
    "else:\n",
    "    print(\"Found in index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarizeTopic(llm, query, promptTemplate):\n",
    "    r = performCogSearch(OpenAiEndPoint, OpenAiKey, OpenAiVersion, OpenAiApiKey, SearchService, SearchKey, embeddingModelType, OpenAiEmbedding, query, indexName, 3)\n",
    "    if r == None:\n",
    "        resultsDoc = [Document(page_content=\"No results found\")]\n",
    "    else :\n",
    "        resultsDoc = [\n",
    "                Document(page_content=doc['content'], metadata={\"id\": doc['id'], \"source\": doc['sourcefile']})\n",
    "                for doc in r\n",
    "                ]\n",
    "        \n",
    "    customPrompt = PromptTemplate(template=promptTemplate, input_variables=[\"text\"])\n",
    "    chainType = \"map_reduce\"\n",
    "    summaryChain = load_summarize_chain(llm, chain_type=chainType, return_intermediate_steps=True, \n",
    "                                        map_prompt=customPrompt, combine_prompt=customPrompt)\n",
    "    summary = summaryChain({\"input_documents\": resultsDoc}, return_only_outputs=True)\n",
    "    outputAnswer = summary['output_text']\n",
    "    return outputAnswer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "promptTemplate = \"\"\"You are an AI assistant tasked with summarizing documents from large documents that contains information about Initial Public Offerings. \n",
    "            IPO document contains sections with information about the company, its business, strategies, risk, management structure, financials, and other information.\n",
    "            Your summary should accurately capture the key information in the document while avoiding the omission of any domain-specific words. \n",
    "            Please generate a concise and comprehensive summary that includes details. \n",
    "            Ensure that the summary is easy to understand and provides an accurate representation. \n",
    "            Begin the summary with a brief introduction, followed by the main points.\n",
    "            Generate the summary with minumum of 7 paragraphs and maximum of 10 paragraphs.\n",
    "            Please remember to use clear language and maintain the integrity of the original information without missing any important details:\n",
    "            {text}\n",
    "\n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating prospectussummary search index\n",
      "Total docs: 4\n",
      "\tIndexed 4 sections, 4 succeeded\n"
     ]
    }
   ],
   "source": [
    "prospectusSummaryIndexName = 'prospectussummary'\n",
    "createProspectusSummary(SearchService, SearchKey, prospectusSummaryIndexName)\n",
    "topicSummary = []\n",
    "\n",
    "selectedTopics = [\n",
    "        \"Strengths\",\n",
    "        \"Growth Strategy\",\n",
    "        \"Investment Risk\",\n",
    "        \"Intellectual Property\"\n",
    "    ]\n",
    "\n",
    "for topic in selectedTopics:\n",
    "    r = findTopicSummaryInIndex(SearchService, SearchKey, prospectusSummaryIndexName, fileName, 'prospectus', topic)\n",
    "    if r.get_count() == 0:\n",
    "        answer = summarizeTopic(llm, topic, promptTemplate)\n",
    "        if \"I don't know\" not in answer:\n",
    "            topicSummary.append({\n",
    "                'id' : str(uuid.uuid4()),\n",
    "                'fileName': fileName,\n",
    "                'docType': 'prospectus',\n",
    "                'topic': topic,\n",
    "                'summary': answer\n",
    "        })\n",
    "\n",
    "mergeDocs(SearchService, SearchKey, prospectusSummaryIndexName, topicSummary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
