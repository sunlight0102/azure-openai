{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Talk and ask about SQL\n",
    "So far we demonstrated the of Open AI to help answer questions over the document, chat over the document and summarize the large document.  The focus so far was primarily on the unstructured nature of the documents.   Now we want to start looking into asking business questions by performing advanced data analytic tasks on a business database. Examples of questions are:\n",
    "\n",
    "- Simple: Which Shipper can ship the order\n",
    "- More difficult: Display Product by Category\n",
    "- Advanced: Number of units in stock by category and supplier continent\n",
    "\n",
    "For the notebook we will focus on two different applications:\n",
    "- SQL Query Writing Assistant: a simple application that translate business question into SQL query language then execute and display result.\n",
    "- Data Analysis Assistant: a more sophisticated application to perform advanced data analytics such as statisical analysis and forecasting. Here we demonstrate the use of [Chain of Thought](https://arxiv.org/abs/2201.11903) and [React](https://arxiv.org/abs/2210.03629) techniques to perform multi-step processing where the next step in the chain also depends on the observation/result from the previous step.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-requisite\n",
    "\n",
    "Deploy SQL server and [Create a empty SQL Database](https://learn.microsoft.com/en-us/azure/azure-sql/database/single-database-create-quickstart?view=azuresql&tabs=azure-portal).  Once the SQL Database is created, run [Northwind SQL](../Deployment/northwind.sql) script to create the Northwind database\n",
    "\n",
    "Also ensure that you have the following environment variables created and configured:\n",
    "- SynapseName: Synapse workspace name\n",
    "- SynapsePool: Synapse pool name\n",
    "- SynapseUser: Synapse user name\n",
    "- SynapsePassword: Synapse password\n",
    "\n",
    "Microsoft ODBC driver"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "import json  \n",
    "import openai\n",
    "from Utilities.envVars import *\n",
    "\n",
    "# Set Search Service endpoint, index name, and API key from environment variables\n",
    "indexName = SearchIndex\n",
    "\n",
    "# Set OpenAI API key and endpoint\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = OpenAiVersion\n",
    "openai_api_key = OpenAiKey\n",
    "assert openai_api_key, \"ERROR: Azure OpenAI Key is missing\"\n",
    "openai.api_key = openai_api_key\n",
    "openAiEndPoint = f\"https://{OpenAiService}.openai.azure.com\"\n",
    "assert openAiEndPoint, \"ERROR: Azure OpenAI Endpoint is missing\"\n",
    "assert \"openai.azure.com\" in openAiEndPoint.lower(), \"ERROR: Azure OpenAI Endpoint should be in the form: \\n\\n\\t<your unique endpoint identifier>.openai.azure.com\"\n",
    "openai.api_base = openAiEndPoint\n",
    "davincimodel = OpenAiDavinci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the needed Python packages\n",
    "import urllib\n",
    "from langchain.llms.openai import AzureOpenAI, OpenAI\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain.schema import AgentAction\n",
    "\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "embeddingModelType = \"azureopenai\"\n",
    "temperature = 0.3\n",
    "tokenLength = 1000\n",
    "\n",
    "if (embeddingModelType == 'azureopenai'):\n",
    "    openai.api_type = \"azure\"\n",
    "    openai.api_key = OpenAiKey\n",
    "    openai.api_version = OpenAiVersion\n",
    "    openai.api_base = f\"https://{OpenAiService}.openai.azure.com\"\n",
    "\n",
    "    llm = AzureOpenAI(deployment_name=OpenAiDavinci,\n",
    "            temperature=temperature,\n",
    "            openai_api_key=OpenAiKey,\n",
    "            max_tokens=tokenLength,\n",
    "            batch_size=10, \n",
    "            max_retries=12)\n",
    "\n",
    "    logging.info(\"LLM Setup done\")\n",
    "    embeddings = OpenAIEmbeddings(model=OpenAiEmbedding, chunk_size=1, openai_api_key=OpenAiKey)\n",
    "elif embeddingModelType == \"openai\":\n",
    "    openai.api_type = \"open_ai\"\n",
    "    openai.api_base = \"https://api.openai.com/v1\"\n",
    "    openai.api_version = '2020-11-07' \n",
    "    openai.api_key = OpenAiApiKey\n",
    "    llm = OpenAI(temperature=temperature,\n",
    "            openai_api_key=OpenAiApiKey,\n",
    "            max_tokens=tokenLength)\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=OpenAiApiKey)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example demonstrates the use of the `SQLDatabaseChain` for answering questions over a database.\n",
    "\n",
    "Under the hood, LangChain uses SQLAlchemy to connect to SQL databases. The SQLDatabaseChain can therefore be used with any SQL dialect supported by SQLAlchemy, such as MS SQL, MySQL, MariaDB, PostgreSQL, Oracle SQL, Databricks and SQLite. \n",
    "\n",
    "NOTE: For data-sensitive projects, you can specify return_direct=True in the SQLDatabaseChain initialization to directly return the output of the SQL query without any additional formatting. This prevents the LLM from seeing any contents within the database. Note, however, the LLM still has access to the database scheme (i.e. dialect, table and key names) by default.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "synapseConnectionString = \"Driver={{ODBC Driver 17 for SQL Server}};Server=tcp:{};\" \\\n",
    "                \"Database={};Uid={};Pwd={};Encrypt=yes;TrustServerCertificate=no;\" \\\n",
    "                \"Connection Timeout=30;\".format(SynapseName, SynapsePool, SynapseUser, SynapsePassword)\n",
    "params = urllib.parse.quote_plus(synapseConnectionString)\n",
    "sqlConnectionString = 'mssql+pyodbc:///?odbc_connect={}'.format(params)\n",
    "db = SQLDatabase.from_uri(sqlConnectionString)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concept here is using Agents as Toolkits.  In the scenario agent is applied to a specific use-case of interacting with SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create the custom prompt that we want to use for our SQL Agent\n",
    "SqlPrefix = \"\"\"You are an agent designed to interact with a SQL database.\n",
    "        Given an input question, create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer.\n",
    "        Always limit your query to at most {top_k} results using the SELECT TOP in SQL Server syntax.\n",
    "        You can order the results by a relevant column to return the most interesting examples in the database.\n",
    "        Never query for all the columns from a specific table, only ask for a the few relevant columns given the question.\n",
    "        If you get a \"no such table\" error, rewrite your query by using the table in quotes.\n",
    "        DO NOT use a column name that does not exist in the table.\n",
    "        You have access to tools for interacting with the database.\n",
    "        Only use the below tools. Only use the information returned by the below tools to construct your final answer.\n",
    "        You MUST double check your query before executing it. If you get an error while executing a query, rewrite a different query and try again.\n",
    "        Observations from the database should be in the form of a JSON with following keys: \"column_name\", \"column_value\"\n",
    "        DO NOT try to execute the query more than three times.\n",
    "        DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\n",
    "        If the question does not seem related to the database, just return \"I don't know\" as the answer.\n",
    "        If you cannot find a way to answer the question, just return the best answer you can find after trying at least three times.\"\"\"\n",
    "\n",
    "SqlSuffix = \"\"\"Begin!\n",
    "    Question: {input}\n",
    "    Thought: I should look at the tables in the database to see what I can query.\n",
    "    {agent_scratchpad}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mOrders, Categories, Territories, Region, Employees, Customers, EmployeeTerritories, CustomerDemographics, Products, Shippers, Suppliers, sysdiagrams, OrderDetails, CustomerCustomerDemo\u001b[0m\n",
      "Thought:\n",
      "Observation: \u001b[33;1m\u001b[1;3m\n",
      "CREATE TABLE [Shippers] (\n",
      "\t[ShipperID] INTEGER NOT NULL IDENTITY(1,1), \n",
      "\t[CompanyName] NVARCHAR(40) COLLATE SQL_Latin1_General_CP1_CI_AS NOT NULL, \n",
      "\t[Phone] NVARCHAR(24) COLLATE SQL_Latin1_General_CP1_CI_AS NULL, \n",
      "\tCONSTRAINT [PK_Shippers] PRIMARY KEY ([ShipperID])\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from Shippers table:\n",
      "ShipperID\tCompanyName\tPhone\n",
      "1\tSpeedy Express\t(503) 555-9831\n",
      "2\tUnited Package\t(503) 555-3199\n",
      "3\tFederal Shipping\t(503) 555-9931\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE [Orders] (\n",
      "\t[OrderID] INTEGER NOT NULL IDENTITY(1,1), \n",
      "\t[CustomerID] NCHAR(5) COLLATE SQL_Latin1_General_CP1_CI_AS NULL, \n",
      "\t[EmployeeID] INTEGER NULL, \n",
      "\t[OrderDate] DATETIME NULL, \n",
      "\t[RequiredDate] DATETIME NULL, \n",
      "\t[ShippedDate] DATETIME NULL, \n",
      "\t[ShipVia] INTEGER NULL, \n",
      "\t[Freight] MONEY NULL DEFAULT ((0)), \n",
      "\t[ShipName] NVARCHAR(40) COLLATE SQL_Latin1_General_CP1_CI_AS NULL, \n",
      "\t[ShipAddress] NVARCHAR(60) COLLATE SQL_Latin1_General_CP1_CI_AS NULL, \n",
      "\t[ShipCity] NVARCHAR(15) COLLATE SQL_Latin1_General_CP1_CI_AS NULL, \n",
      "\t[ShipRegion] NVARCHAR(15) COLLATE SQL_Latin1_General_CP1_CI_AS NULL, \n",
      "\t[ShipPostalCode] NVARCHAR(10) COLLATE SQL_Latin1_General_CP1_CI_AS NULL, \n",
      "\t[ShipCountry] NVARCHAR(15) COLLATE SQL_Latin1_General_CP1_CI_AS NULL, \n",
      "\tCONSTRAINT [PK_Orders] PRIMARY KEY ([OrderID]), \n",
      "\tCONSTRAINT [FK_Orders_Customers] FOREIGN KEY([CustomerID]) REFERENCES [Customers] ([CustomerID]), \n",
      "\tCONSTRAINT [FK_Orders_Employees] FOREIGN KEY([EmployeeID]) REFERENCES [Employees] ([EmployeeID]), \n",
      "\tCONSTRAINT [FK_Orders_Shippers] FOREIGN KEY([ShipVia]) REFERENCES [Shippers] ([ShipperID])\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from Orders table:\n",
      "OrderID\tCustomerID\tEmployeeID\tOrderDate\tRequiredDate\tShippedDate\tShipVia\tFreight\tShipName\tShipAddress\tShipCity\tShipRegion\tShipPostalCode\tShipCountry\n",
      "10248\tVINET\t5\t1996-07-04 00:00:00\t1996-08-01 00:00:00\t1996-07-16 00:00:00\t3\t32.3800\tVins et alcools Chevalier\t59 rue de l'Abbaye\tReims\tNone\t51100\tFrance\n",
      "10249\tTOMSP\t6\t1996-07-05 00:00:00\t1996-08-16 00:00:00\t1996-07-10 00:00:00\t1\t11.6100\tToms Spezialitäten\tLuisenstr. 48\tMünster\tNone\t44087\tGermany\n",
      "10250\tHANAR\t4\t1996-07-08 00:00:00\t1996-08-05 00:00:00\t1996-07-12 00:00:00\t2\t65.8300\tHanari Carnes\tRua do Paço, 67\tRio de Janeiro\tRJ\t05454-876\tBrazil\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE [Products] (\n",
      "\t[ProductID] INTEGER NOT NULL IDENTITY(1,1), \n",
      "\t[ProductName] NVARCHAR(40) COLLATE SQL_Latin1_General_CP1_CI_AS NOT NULL, \n",
      "\t[SupplierID] INTEGER NULL, \n",
      "\t[CategoryID] INTEGER NULL, \n",
      "\t[QuantityPerUnit] NVARCHAR(20) COLLATE SQL_Latin1_General_CP1_CI_AS NULL, \n",
      "\t[UnitPrice] MONEY NULL DEFAULT ((0)), \n",
      "\t[UnitsInStock] SMALLINT NULL DEFAULT ((0)), \n",
      "\t[UnitsOnOrder] SMALLINT NULL DEFAULT ((0)), \n",
      "\t[ReorderLevel] SMALLINT NULL DEFAULT ((0)), \n",
      "\t[Discontinued] BIT NOT NULL DEFAULT ((0)), \n",
      "\tCONSTRAINT [PK_Products] PRIMARY KEY ([ProductID]), \n",
      "\tCONSTRAINT [FK_Products_Categories] FOREIGN KEY([CategoryID]) REFERENCES [Categories] ([CategoryID]), \n",
      "\tCONSTRAINT [FK_Products_Suppliers] FOREIGN KEY([SupplierID]) REFERENCES [Suppliers] ([SupplierID])\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from Products table:\n",
      "ProductID\tProductName\tSupplierID\tCategoryID\tQuantityPerUnit\tUnitPrice\tUnitsInStock\tUnitsOnOrder\tReorderLevel\tDiscontinued\n",
      "1\tChai\t1\t1\t10 boxes x 20 bags\t18.0000\t39\t0\t10\tFalse\n",
      "2\tChang\t1\t1\t24 - 12 oz bottles\t19.0000\t17\t40\t25\tFalse\n",
      "3\tAniseed Syrup\t1\t2\t12 - 550 ml bottles\t10.0000\t13\t70\t25\tFalse\n",
      "*/\u001b[0m\n",
      "Thought:\n",
      "Observation: \u001b[36;1m\u001b[1;3m[('Speedy Express',), ('Speedy Express',), ('Speedy Express',)]\u001b[0m\n",
      "Thought:"
     ]
    }
   ],
   "source": [
    "topK = 3\n",
    "question = \"Which Shipper can ship the product?\"\n",
    "\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "agentExecutor = create_sql_agent(\n",
    "        llm=llm,\n",
    "        toolkit=toolkit,\n",
    "        verbose=True,\n",
    "        prefix=SqlPrefix, \n",
    "        #suffix=SqlSuffix,\n",
    "        top_k=topK,\n",
    "        kwargs={\"return_intermediate_steps\": True}\n",
    "    )\n",
    "agentExecutor.return_intermediate_steps = True\n",
    "\n",
    "logging.info(\"Agent Setup done\")\n",
    "answer = agentExecutor._call({\"input\":question})\n",
    "intermediateSteps = answer['intermediate_steps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer : The Shipper that can ship the product is Speedy Express.\n",
      "Observation : [('Speedy Express',), ('Speedy Express',), ('Speedy Express',)]\n",
      "SQL Query : SELECT TOP 3 Shippers.CompanyName FROM Orders INNER JOIN Shippers ON Orders.ShipVia = Shippers.ShipperID\n"
     ]
    }
   ],
   "source": [
    "observation = ''\n",
    "for item in intermediateSteps:\n",
    "    agentAction: AgentAction = item[0]\n",
    "    if (agentAction.tool == 'query_sql_db'):\n",
    "        toolInput = str(agentAction.tool_input)\n",
    "        observation = item[1]\n",
    "\n",
    "print(\"Answer : \" + answer['output'])\n",
    "print(\"Observation : \" + observation)\n",
    "print(\"SQL Query : \" + toolInput)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test using GPT 3.5 turbo and with custom code & Prompt outside of Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "\n",
    "def executeQuery(query, limit=10000):  \n",
    "    engine = create_engine(sqlConnectionString)\n",
    "    result = pd.read_sql_query(query, engine)\n",
    "    result = result.infer_objects()\n",
    "    for col in result.columns:  \n",
    "        if 'date' in col.lower():  \n",
    "            result[col] = pd.to_datetime(result[col], errors=\"ignore\")  \n",
    "\n",
    "    if limit is not None:  \n",
    "        result = result.head(limit)  # limit to save memory  \n",
    "    # session.close()  \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTableSchema():\n",
    "    sqlQuery = \"\"\"  \n",
    "    SELECT C.TABLE_NAME, C.COLUMN_NAME, C.DATA_TYPE, T.TABLE_TYPE, T.TABLE_SCHEMA  \n",
    "    FROM INFORMATION_SCHEMA.COLUMNS C  \n",
    "    JOIN INFORMATION_SCHEMA.TABLES T ON C.TABLE_NAME = T.TABLE_NAME AND C.TABLE_SCHEMA = T.TABLE_SCHEMA  \n",
    "    WHERE T.TABLE_TYPE = 'BASE TABLE'  \n",
    "    \"\"\"  \n",
    "    \n",
    "    # Execute the SQL query and store the results in a DataFrame  \n",
    "    df = executeQuery(sqlQuery, limit=None)  \n",
    "    output=[]\n",
    "    # Initialize variables to store table and column information  \n",
    "    curTable = ''  \n",
    "    columns = []  \n",
    "    \n",
    "    # Loop through the query results and output the table and column information  \n",
    "    for index, row in df.iterrows():\n",
    "        tableName = f\"{row['TABLE_SCHEMA']}.{row['TABLE_NAME']}\" \n",
    "        colName = row['COLUMN_NAME']  \n",
    "        dataType = row['DATA_TYPE']   \n",
    "        if \" \" in tableName:\n",
    "            tableName= f\"[{tableName}]\" \n",
    "        colName = row['COLUMN_NAME']  \n",
    "        if \" \" in colName:\n",
    "            colName= f\"[{colName}]\" \n",
    "\n",
    "        # If the table name has changed, output the previous table's information  \n",
    "        if curTable != tableName and curTable != '':  \n",
    "            output.append(f\"table: {curTable}, columns: {', '.join(columns)}\")  \n",
    "            columns = []  \n",
    "        \n",
    "        # Add the current column information to the list of columns for the current table  \n",
    "        columns.append(f\"{colName} {dataType}\")  \n",
    "        \n",
    "        # Update the current table name  \n",
    "        curTable = tableName  \n",
    "    \n",
    "    # Output the last table's information  \n",
    "    output.append(f\"table: {curTable}, columns: {', '.join(columns)}\")\n",
    "    output = \"\\n \".join(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callLlm(embeddingModelType, prompt, stop):\n",
    "    if (embeddingModelType == 'azureopenai'):\n",
    "        openai.api_type = \"azure\"\n",
    "        openai.api_key = OpenAiKey\n",
    "        openai.api_version = OpenAiVersion\n",
    "        openai.api_base = f\"https://{OpenAiService}.openai.azure.com\"\n",
    "        response = openai.ChatCompletion.create(\n",
    "            engine=OpenAiChat, \n",
    "            messages = prompt,\n",
    "            temperature=temperature,\n",
    "            max_tokens=tokenLength,\n",
    "            stop=stop\n",
    "            )\n",
    "        logging.info(\"LLM Setup done\")\n",
    "        llmOutput = response['choices'][0]['message']['content']\n",
    "    elif embeddingModelType == \"openai\":\n",
    "        openai.api_type = \"open_ai\"\n",
    "        openai.api_base = \"https://api.openai.com/v1\"\n",
    "        openai.api_version = '2020-11-07' \n",
    "        openai.api_key = OpenAiApiKey\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\", \n",
    "            messages = prompt,\n",
    "            temperature=temperature,\n",
    "            max_tokens=tokenLength,\n",
    "            stop=stop\n",
    "            )\n",
    "        llmOutput = response['choices'][0]['message']['content']\n",
    "    return llmOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractOutput(textInput, extractPattern):\n",
    "    output={}\n",
    "    if len(textInput)==0:\n",
    "        return output\n",
    "    for pattern in extractPattern: \n",
    "        if \"sql\" in pattern[1]:\n",
    "\n",
    "            sql_query=\"\"\n",
    "            sql_result = re.findall(pattern[1], textInput, re.DOTALL)\n",
    "\n",
    "            if len(sql_result)>0:\n",
    "                sql_query=sql_result[0]\n",
    "                output[pattern[0]]= sql_query\n",
    "            else:\n",
    "                return output\n",
    "            text_before = textInput.split(sql_query)[0].strip(\"\\n\").strip(\"```sql\").strip(\"\\n\")\n",
    "\n",
    "            if text_before is not None and len(text_before)>0:\n",
    "                output[\"text_before\"]=text_before\n",
    "            text_after =textInput.split(sql_query)[1].strip(\"\\n\").strip(\"```\")\n",
    "            if text_after is not None and len(text_after)>0:\n",
    "                output[\"text_after\"]=text_after\n",
    "            return output\n",
    "\n",
    "        if \"python\" in pattern[1]:\n",
    "            result = re.findall(pattern[1], textInput, re.DOTALL)\n",
    "            if len(result)>0:\n",
    "                output[pattern[0]]= result[0]\n",
    "        else:\n",
    "\n",
    "            result = re.search(pattern[1], textInput,re.DOTALL)\n",
    "            if result:  \n",
    "                output[result.group(1)]= result.group(2)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNextSteps(extractPattern, embeddingModelType, updatedUserContent, chatHistory, stop):\n",
    "    oldUserContent=\"\"\n",
    "    if len(chatHistory)>1:\n",
    "        oldUserContent= chatHistory.pop() #removing old history\n",
    "        oldUserContent=oldUserContent['content']+\"\\n\"\n",
    "    chatHistory.append({\"role\": \"user\", \"content\": oldUserContent+updatedUserContent})\n",
    "    #print(\"prompt input \", chatHistory)\n",
    "    n=0\n",
    "    try:\n",
    "        llmOutput = callLlm(embeddingModelType, chatHistory, stop)\n",
    "        #print(\"llmOutput \\n\", llmOutput)\n",
    "    except Exception as e:\n",
    "        time.sleep(8) #sleep for 8 seconds\n",
    "        while n<5:\n",
    "            try:\n",
    "                llmOutput = callLlm(embeddingModelType, chatHistory, stop)\n",
    "            except Exception as e:\n",
    "                n +=1\n",
    "                print(\"error calling open AI, I am retrying 5 attempts , attempt \", n)\n",
    "                time.sleep(8) #sleep for 8 seconds\n",
    "                print(e)\n",
    "\n",
    "        llmOutput = \"OPENAI_ERROR\"\n",
    "        print(\"llmOutput: \", llmOutput)\n",
    "    output = extractOutput(llmOutput, extractPattern)\n",
    "    if len(output)==0 and llmOutput != \"OPENAI_ERROR\": #wrong output format\n",
    "        llmOutput = \"WRONG_OUTPUT_FORMAT\"\n",
    "    return llmOutput,output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For first use-case test it as SQL Query Writing Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sysDefaultMessage =\"\"\"\n",
    "    You are an agent designed to interact with a SQL database with schema detail in <<data_sources>>.\n",
    "    Given an input question, create a syntactically correct {sql_engine} query to run, then look at the results of the query and return the answer.\n",
    "    You can order the results by a relevant column to return the most interesting examples in the database.\n",
    "    Never query for all the columns from a specific table, only ask for a the few relevant columns given the question.\n",
    "    You MUST double check your query before executing it. If you get an error while executing a query, rewrite the query and try again.\n",
    "    DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\n",
    "    Remember to format SQL query as in ```sql\\n SQL QUERY HERE ``` in your response.\n",
    "    \n",
    "    \"\"\"\n",
    "fewShotExamples=\"\"\n",
    "sqlEngine = 'sqlserver'\n",
    "extractPattern=[('sql',r\"```sql\\n(.*?)```\")]\n",
    "\n",
    "# get Table Schema\n",
    "tableSchema  = getTableSchema()\n",
    "sysMessage = f\"\"\"\n",
    "        <<data_sources>>\n",
    "        {tableSchema}\n",
    "        {sysDefaultMessage.format(sql_engine=sqlEngine)}\n",
    "        {fewShotExamples}\n",
    "        \"\"\"\n",
    "tokenLength=1000\n",
    "temperature=0\n",
    "embeddingModelType = \"azureopenai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAnswer(newInput, chatHistory):\n",
    "    maxSteps=15\n",
    "    count=1\n",
    "    while count<= maxSteps:\n",
    "        llmOutput,nextSteps = getNextSteps(extractPattern, embeddingModelType, newInput, chatHistory, stop=[\"Observation:\", f\"Thought {count+1}\"])\n",
    "        if llmOutput=='OPENAI_ERROR':\n",
    "            print(\"Error Calling Azure Open AI, probably due to max service limit, please try again\")\n",
    "            break\n",
    "        elif llmOutput=='WRONG_OUTPUT_FORMAT': #just have open AI try again till the right output comes\n",
    "            count +=1\n",
    "            continue\n",
    "        output =None\n",
    "        error= False\n",
    "\n",
    "        newInput += f\"\\n{llmOutput}\"\n",
    "        for key, value in nextSteps.items():\n",
    "            newInput += f\"\\n{value}\"\n",
    "            \n",
    "            if \"SQL\" in key.upper():\n",
    "                print(\"SQL Code : \")\n",
    "                print(value)\n",
    "                try:\n",
    "                    output = executeQuery(value)\n",
    "                except Exception as e:\n",
    "                    newInput +=\"Encounter following error, can you try again?\\n\"+str(e)\n",
    "                    error=str(e)\n",
    "            else:\n",
    "                print(\"Non-SQL Value : \")\n",
    "                print(value)\n",
    "        print(\"Prompt & Chat History : \")\n",
    "        print(chatHistory)\n",
    "\n",
    "        if output is not None:\n",
    "            print(\"Output : \")\n",
    "            print(output)\n",
    "            break\n",
    "\n",
    "        if error:\n",
    "            print(error)\n",
    "\n",
    "        count +=1\n",
    "        if count>= maxSteps:\n",
    "            print(\"Cannot handle the question, please change the question and try again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Code : \n",
      "SELECT s.CompanyName, s.Phone\n",
      "FROM Shippers s\n",
      "JOIN Products p ON s.ShipperID = p.SupplierID\n",
      "WHERE p.ProductName = 'product_name';\n",
      "\n",
      "Non-SQL Value : \n",
      "To answer this question, we need to know the available shippers in the database and their contact information. We also need to know the products available in the database and their corresponding supplier. Assuming we have this information, we can join the `Shippers` and `Products` tables on the `ShipperID` and `SupplierID` columns respectively, and filter by the desired product. Here's the SQL query:\n",
      "Non-SQL Value : \n",
      "\n",
      "\n",
      "Replace `product_name` with the name of the desired product. This query will return the name and phone number of the shipper that can ship the desired product.\n",
      "Prompt & Chat History : \n",
      "[{'role': 'system', 'content': '\\n        <<data_sources>>\\n        table: dbo.sysdiagrams, columns: name nvarchar, principal_id int, diagram_id int, version int, definition varbinary\\n table: dbo.Employees, columns: EmployeeID int, LastName nvarchar, FirstName nvarchar, Title nvarchar, TitleOfCourtesy nvarchar, BirthDate datetime, HireDate datetime, Address nvarchar, City nvarchar, Region nvarchar, PostalCode nvarchar, Country nvarchar, HomePhone nvarchar, Extension nvarchar, Photo image, Notes ntext, ReportsTo int, PhotoPath nvarchar\\n table: dbo.Categories, columns: CategoryID int, CategoryName nvarchar, Description ntext, Picture image\\n table: dbo.Customers, columns: CustomerID nchar, CompanyName nvarchar, ContactName nvarchar, ContactTitle nvarchar, Address nvarchar, City nvarchar, Region nvarchar, PostalCode nvarchar, Country nvarchar, Phone nvarchar, Fax nvarchar\\n table: dbo.Shippers, columns: ShipperID int, CompanyName nvarchar, Phone nvarchar\\n table: dbo.Suppliers, columns: SupplierID int, CompanyName nvarchar, ContactName nvarchar, ContactTitle nvarchar, Address nvarchar, City nvarchar, Region nvarchar, PostalCode nvarchar, Country nvarchar, Phone nvarchar, Fax nvarchar, HomePage ntext\\n table: dbo.Orders, columns: OrderID int, CustomerID nchar, EmployeeID int, OrderDate datetime, RequiredDate datetime, ShippedDate datetime, ShipVia int, Freight money, ShipName nvarchar, ShipAddress nvarchar, ShipCity nvarchar, ShipRegion nvarchar, ShipPostalCode nvarchar, ShipCountry nvarchar\\n table: dbo.Products, columns: ProductID int, ProductName nvarchar, SupplierID int, CategoryID int, QuantityPerUnit nvarchar, UnitPrice money, UnitsInStock smallint, UnitsOnOrder smallint, ReorderLevel smallint, Discontinued bit\\n table: dbo.OrderDetails, columns: OrderID int, ProductID int, UnitPrice money, Quantity smallint, Discount real\\n table: dbo.CustomerCustomerDemo, columns: CustomerID nchar, CustomerTypeID nchar\\n table: dbo.CustomerDemographics, columns: CustomerTypeID nchar, CustomerDesc ntext\\n table: dbo.Region, columns: RegionID int, RegionDescription nchar\\n table: dbo.Territories, columns: TerritoryID nvarchar, TerritoryDescription nchar, RegionID int\\n table: dbo.EmployeeTerritories, columns: EmployeeID int, TerritoryID nvarchar\\n        \\n    You are an agent designed to interact with a SQL database with schema detail in <<data_sources>>.\\n    Given an input question, create a syntactically correct sqlserver query to run, then look at the results of the query and return the answer.\\n    You can order the results by a relevant column to return the most interesting examples in the database.\\n    Never query for all the columns from a specific table, only ask for a the few relevant columns given the question.\\n    You MUST double check your query before executing it. If you get an error while executing a query, rewrite the query and try again.\\n    DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\\n    Remember to format SQL query as in ```sql\\n SQL QUERY HERE ``` in your response.\\n    \\n    \\n        \\n        '}, {'role': 'user', 'content': 'Question: Which Shipper can ship the product?'}]\n",
      "Output : \n",
      "Empty DataFrame\n",
      "Columns: [CompanyName, Phone]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "chatHistory =  [{\"role\": \"system\", \"content\": sysMessage}]\n",
    "question = \"Which Shipper can ship the product?\"\n",
    "newInput= f\"Question: {question}\"\n",
    "getAnswer(newInput, chatHistory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Code : \n",
      "SELECT c.CategoryName, s.Country, SUM(p.UnitsInStock) AS TotalUnitsInStock\n",
      "FROM dbo.Products p\n",
      "JOIN dbo.Suppliers s ON p.SupplierID = s.SupplierID\n",
      "JOIN dbo.Categories c ON p.CategoryID = c.CategoryID\n",
      "GROUP BY c.CategoryName, s.Country\n",
      "ORDER BY TotalUnitsInStock DESC\n",
      "\n",
      "Non-SQL Value : \n",
      " \n",
      "This query joins the Products, Suppliers, and Categories tables to get the category name, supplier country, and total units in stock for each combination of category and supplier continent. The results are grouped by category and supplier country and ordered by total units in stock in descending order.\n",
      "Prompt & Chat History : \n",
      "[{'role': 'system', 'content': '\\n        <<data_sources>>\\n        table: dbo.sysdiagrams, columns: name nvarchar, principal_id int, diagram_id int, version int, definition varbinary\\n table: dbo.Employees, columns: EmployeeID int, LastName nvarchar, FirstName nvarchar, Title nvarchar, TitleOfCourtesy nvarchar, BirthDate datetime, HireDate datetime, Address nvarchar, City nvarchar, Region nvarchar, PostalCode nvarchar, Country nvarchar, HomePhone nvarchar, Extension nvarchar, Photo image, Notes ntext, ReportsTo int, PhotoPath nvarchar\\n table: dbo.Categories, columns: CategoryID int, CategoryName nvarchar, Description ntext, Picture image\\n table: dbo.Customers, columns: CustomerID nchar, CompanyName nvarchar, ContactName nvarchar, ContactTitle nvarchar, Address nvarchar, City nvarchar, Region nvarchar, PostalCode nvarchar, Country nvarchar, Phone nvarchar, Fax nvarchar\\n table: dbo.Shippers, columns: ShipperID int, CompanyName nvarchar, Phone nvarchar\\n table: dbo.Suppliers, columns: SupplierID int, CompanyName nvarchar, ContactName nvarchar, ContactTitle nvarchar, Address nvarchar, City nvarchar, Region nvarchar, PostalCode nvarchar, Country nvarchar, Phone nvarchar, Fax nvarchar, HomePage ntext\\n table: dbo.Orders, columns: OrderID int, CustomerID nchar, EmployeeID int, OrderDate datetime, RequiredDate datetime, ShippedDate datetime, ShipVia int, Freight money, ShipName nvarchar, ShipAddress nvarchar, ShipCity nvarchar, ShipRegion nvarchar, ShipPostalCode nvarchar, ShipCountry nvarchar\\n table: dbo.Products, columns: ProductID int, ProductName nvarchar, SupplierID int, CategoryID int, QuantityPerUnit nvarchar, UnitPrice money, UnitsInStock smallint, UnitsOnOrder smallint, ReorderLevel smallint, Discontinued bit\\n table: dbo.OrderDetails, columns: OrderID int, ProductID int, UnitPrice money, Quantity smallint, Discount real\\n table: dbo.CustomerCustomerDemo, columns: CustomerID nchar, CustomerTypeID nchar\\n table: dbo.CustomerDemographics, columns: CustomerTypeID nchar, CustomerDesc ntext\\n table: dbo.Region, columns: RegionID int, RegionDescription nchar\\n table: dbo.Territories, columns: TerritoryID nvarchar, TerritoryDescription nchar, RegionID int\\n table: dbo.EmployeeTerritories, columns: EmployeeID int, TerritoryID nvarchar\\n        \\n    You are an agent designed to interact with a SQL database with schema detail in <<data_sources>>.\\n    Given an input question, create a syntactically correct sqlserver query to run, then look at the results of the query and return the answer.\\n    You can order the results by a relevant column to return the most interesting examples in the database.\\n    Never query for all the columns from a specific table, only ask for a the few relevant columns given the question.\\n    You MUST double check your query before executing it. If you get an error while executing a query, rewrite the query and try again.\\n    DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\\n    Remember to format SQL query as in ```sql\\n SQL QUERY HERE ``` in your response.\\n    \\n    \\n        \\n        '}, {'role': 'user', 'content': 'Question: Number of units in stock by category and supplier continent'}]\n",
      "Output : \n",
      "      CategoryName      Country  TotalUnitsInStock\n",
      "0       Condiments          USA                259\n",
      "1          Seafood       Sweden                224\n",
      "2          Seafood          USA                208\n",
      "3        Beverages          USA                183\n",
      "4   Grains/Cereals       Sweden                165\n",
      "5   Dairy Products       Norway                164\n",
      "6      Confections      Germany                140\n",
      "7     Meat/Poultry       Canada                136\n",
      "8        Beverages      Germany                125\n",
      "9       Condiments       Canada                113\n",
      "10  Dairy Products        Spain                108\n",
      "11         Seafood      Denmark                100\n",
      "12  Dairy Products       France                 98\n",
      "13       Beverages       France                 86\n",
      "14     Confections      Finland                 75\n",
      "15     Confections           UK                 74\n",
      "16         Seafood       France                 62\n",
      "17       Beverages      Finland                 57\n",
      "18  Grains/Cereals        Italy                 57\n",
      "19       Beverages           UK                 56\n",
      "20         Seafood        Japan                 55\n",
      "21     Confections  Netherlands                 51\n",
      "22         Seafood    Australia                 42\n",
      "23         Produce        Japan                 39\n",
      "24      Condiments        Japan                 39\n",
      "25  Grains/Cereals    Australia                 38\n",
      "26      Condiments      Germany                 32\n",
      "27    Meat/Poultry        Japan                 29\n",
      "28     Confections    Australia                 29\n",
      "29      Condiments    Singapore                 27\n",
      "30  Grains/Cereals    Singapore                 26\n",
      "31         Produce      Germany                 26\n",
      "32      Condiments    Australia                 24\n",
      "33  Dairy Products        Italy                 23\n",
      "34  Grains/Cereals      Germany                 22\n",
      "35         Produce    Australia                 20\n",
      "36       Beverages       Brazil                 20\n",
      "37     Confections       Canada                 17\n",
      "38       Beverages    Singapore                 17\n",
      "39       Beverages    Australia                 15\n",
      "40         Produce          USA                 15\n",
      "41      Condiments           UK                 13\n",
      "42         Seafood      Germany                 10\n",
      "43    Meat/Poultry      Germany                  0\n",
      "44    Meat/Poultry    Australia                  0\n"
     ]
    }
   ],
   "source": [
    "chatHistory =  [{\"role\": \"system\", \"content\": sysMessage}]\n",
    "question = \"Number of units in stock by category and supplier continent\"\n",
    "newInput= f\"Question: {question}\"\n",
    "getAnswer(newInput, chatHistory)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This time test it as Data Analyst Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "daSysDefaultMessage = \"\"\"\n",
    "        You are a smart AI assistant to help answer business questions based on analyzing data. \n",
    "        You can plan solving the question with one more multiple thought step. At each thought step, you can write python code to analyze data to assist you. Observe what you get at each step to plan for the next step.\n",
    "        You are given following utilities to help you retrieve data and commmunicate your result to end user.\n",
    "        1. executeQuery(sql_query: str): A Python function can query data from the <<data_sources>> given a query which you need to create. The query has to be syntactically correct for {sql_engine} and only use tables and columns under <<data_sources>>. The executeQuery function returns a Python pandas dataframe contain the results of the query.\n",
    "        2. Use plotly library for data visualization. \n",
    "        3. Use observe(label: str, data: any) utility function to observe data under the label for your evaluation. Use observe() function instead of print() as this is executed in streamlit environment. Due to system limitation, you will only see the first 10 rows of the dataset.\n",
    "        4. To communicate with user, use show() function on data, text and plotly figure. show() is a utility function that can render different types of data to end user. Remember, you don't see data with show(), only user does. You see data with observe()\n",
    "            - If you want to show  user a plotly visualization, then use ```show(fig)`` \n",
    "            - If you want to show user data which is a text or a pandas dataframe or a list, use ```show(data)```\n",
    "            - Never use print(). User don't see anything with print()\n",
    "        5. Lastly, don't forget to deal with data quality problem. You should apply data imputation technique to deal with missing data or NAN data.\n",
    "        6. Always follow the flow of Thought: , Observation:, Action: and Answer: as in template below strictly. \n",
    "\n",
    "        \"\"\"\n",
    "daFewShotExamples =\"\"\"\n",
    "        <<Template>>\n",
    "        Question: User Question\n",
    "        Thought 1: Your thought here.\n",
    "        Action: \n",
    "        ```python\n",
    "        #Import neccessary libraries here\n",
    "        import numpy as np\n",
    "        #Query some data \n",
    "        sql_query = \"SOME SQL QUERY\"\n",
    "        step1_df = executeQuery(sql_query)\n",
    "        # Replace NAN with 0. Always have this step\n",
    "        step1_df['Some_Column'] = step1_df['Some_Column'].replace(np.nan,0)\n",
    "        #observe query result\n",
    "        observe(\"some_label\", step1_df) #Always use observe() instead of print\n",
    "        ```\n",
    "        Observation: \n",
    "        step1_df is displayed here\n",
    "        Thought 2: Your thought here\n",
    "        Action:  \n",
    "        ```python\n",
    "        import plotly.express as px \n",
    "        #from step1_df, perform some data analysis action to produce step2_df\n",
    "        #To see the data for yourself the only way is to use observe()\n",
    "        observe(\"some_label\", step2_df) #Always use observe() \n",
    "        #Decide to show it to user.\n",
    "        fig=px.line(step2_df)\n",
    "        #visualize fig object to user.  \n",
    "        show(fig)\n",
    "        #you can also directly display tabular or text data to end user.\n",
    "        show(step2_df)\n",
    "        ```\n",
    "        Observation: \n",
    "        step2_df is displayed here\n",
    "        Answer: Your final answer and comment for the question. Also use Python for computation, never compute result youself.\n",
    "        <</Template>>\n",
    "\n",
    "        \"\"\"\n",
    "sqlEngine = 'sqlserver'\n",
    "daExtractPattern=[(\"Thought:\",r'(Thought \\d+):\\s*(.*?)(?:\\n|$)'), ('Action:',r\"```python\\n(.*?)```\"),(\"Answer:\",r'([Aa]nswer:) (.*)')]\n",
    "\n",
    "# get Table Schema\n",
    "tableSchema  = getTableSchema()\n",
    "daSysMessage = f\"\"\"\n",
    "        <<data_sources>>\n",
    "        {tableSchema}\n",
    "        {daSysDefaultMessage.format(sql_engine=sqlEngine)}\n",
    "        {daFewShotExamples}\n",
    "        \"\"\"\n",
    "tokenLength=1000\n",
    "temperature=0\n",
    "embeddingModelType = \"openai\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDaAnswer(extractPattern, newInput, chatHistory):\n",
    "\n",
    "    from plotly.graph_objects import Figure\n",
    "    import numpy as np\n",
    "    import plotly.express as px\n",
    "    import plotly.graph_objs as go\n",
    "    import pandas as pd\n",
    "\n",
    "    def show(data):\n",
    "        #if type(data) is Figure:\n",
    "        #    plotly_chart(data)\n",
    "        #else:\n",
    "        print(data)\n",
    "        if type(data) is not Figure:\n",
    "            print('observation: this was shown to user',data)\n",
    "\n",
    "    def observe(name, data):\n",
    "        try:\n",
    "            data = data[:10] # limit the print out observation to 15 rows\n",
    "        except:\n",
    "            pass\n",
    "        print(f'observation:{name}', data)\n",
    "    \n",
    "    def executeQuery(query, limit=10000):  \n",
    "        engine = create_engine(sqlConnectionString)\n",
    "        result = pd.read_sql_query(query, engine)\n",
    "        result = result.infer_objects()\n",
    "        for col in result.columns:  \n",
    "            if 'date' in col.lower():  \n",
    "                result[col] = pd.to_datetime(result[col], errors=\"ignore\")  \n",
    "\n",
    "        if limit is not None:  \n",
    "            result = result.head(limit)  # limit to save memory  \n",
    "        # session.close()  \n",
    "        return result\n",
    "        \n",
    "    maxSteps=15\n",
    "    count=1\n",
    "    finish = False\n",
    "    while not finish:\n",
    "        llmOutput,nextSteps = getNextSteps(extractPattern, embeddingModelType, newInput, chatHistory, stop=[\"Observation:\", f\"Thought {count+1}\"])\n",
    "        if llmOutput=='OPENAI_ERROR':\n",
    "            print(\"Error Calling Azure Open AI, probably due to max service limit, please try again\")\n",
    "            break\n",
    "        elif llmOutput=='WRONG_OUTPUT_FORMAT': #just have open AI try again till the right output comes\n",
    "            count +=1\n",
    "            continue\n",
    "\n",
    "        newInput += f\"\\n{llmOutput}\"\n",
    "        for key, value in nextSteps.items():\n",
    "            newInput += f\"\\n{value}\"\n",
    "            \n",
    "            if \"ACTION\" in key.upper():\n",
    "                print(\"SQL Code : \")\n",
    "                print(key)\n",
    "                print(value)\n",
    "                observations =[]\n",
    "                serialized_obs=[]\n",
    "                try:\n",
    "                    exec(value, locals())\n",
    "                    if \"observation:\" in key:\n",
    "                        observations.append((key.split(\":\")[1],observation))\n",
    "                        if type(observation) is pd:\n",
    "                            serialized_obs.append((key.split(\":\")[1],observation.to_string()))\n",
    "                        elif type(observation) is not Figure:\n",
    "                            serialized_obs.append({key.split(\":\")[1]:str(observation)})\n",
    "                except Exception as e:\n",
    "                    observations.append((\"Error:\",str(e)))\n",
    "                    serialized_obs.append({\"\\nEncounter following error, can you try again?\\n:\":str(e)+\"\\nAction:\"})\n",
    "                \n",
    "                for observation in observations:\n",
    "                    print(observation[0])\n",
    "                    print(observation[1])\n",
    "                obs = f\"\\nObservation on the first 10 rows of data: {serialized_obs}\"\n",
    "                newInput += obs\n",
    "            else:\n",
    "                print(key)\n",
    "                print(value)\n",
    "            if \"Answer\" in key:\n",
    "                print(\"Answer is given, finish\")\n",
    "                finish= True\n",
    "        print(\"Prompt & Chat History : \")\n",
    "        print(chatHistory)\n",
    "\n",
    "        count +=1\n",
    "        if count>= maxSteps:\n",
    "            print(\"Cannot handle the question, please change the question and try again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought 1\n",
      "We need to join the Products and Categories table to get the Product by Category. \n",
      "SQL Code : \n",
      "Action:\n",
      "#Import neccessary libraries here\n",
      "import numpy as np\n",
      "import plotly.express as px\n",
      "\n",
      "#Query some data \n",
      "sql_query = \"SELECT p.ProductName, c.CategoryName FROM dbo.Products p JOIN dbo.Categories c ON p.CategoryID = c.CategoryID\"\n",
      "product_by_category_df = executeQuery(sql_query)\n",
      "\n",
      "# Replace NAN with 0. Always have this step\n",
      "product_by_category_df = product_by_category_df.replace(np.nan,0)\n",
      "\n",
      "#observe query result\n",
      "observe(\"Product by Category\", product_by_category_df) #Always use observe() instead of print\n",
      "\n",
      "observation:Product by Category                        ProductName  CategoryName\n",
      "0                             Chai     Beverages\n",
      "1                            Chang     Beverages\n",
      "2                    Aniseed Syrup    Condiments\n",
      "3     Chef Anton's Cajun Seasoning    Condiments\n",
      "4           Chef Anton's Gumbo Mix    Condiments\n",
      "5     Grandma's Boysenberry Spread    Condiments\n",
      "6  Uncle Bob's Organic Dried Pears       Produce\n",
      "7       Northwoods Cranberry Sauce    Condiments\n",
      "8                  Mishi Kobe Niku  Meat/Poultry\n",
      "9                            Ikura       Seafood\n",
      "Prompt & Chat History : \n",
      "[{'role': 'system', 'content': '\\n        <<data_sources>>\\n        table: dbo.sysdiagrams, columns: name nvarchar, principal_id int, diagram_id int, version int, definition varbinary\\n table: dbo.Employees, columns: EmployeeID int, LastName nvarchar, FirstName nvarchar, Title nvarchar, TitleOfCourtesy nvarchar, BirthDate datetime, HireDate datetime, Address nvarchar, City nvarchar, Region nvarchar, PostalCode nvarchar, Country nvarchar, HomePhone nvarchar, Extension nvarchar, Photo image, Notes ntext, ReportsTo int, PhotoPath nvarchar\\n table: dbo.Categories, columns: CategoryID int, CategoryName nvarchar, Description ntext, Picture image\\n table: dbo.Customers, columns: CustomerID nchar, CompanyName nvarchar, ContactName nvarchar, ContactTitle nvarchar, Address nvarchar, City nvarchar, Region nvarchar, PostalCode nvarchar, Country nvarchar, Phone nvarchar, Fax nvarchar\\n table: dbo.Shippers, columns: ShipperID int, CompanyName nvarchar, Phone nvarchar\\n table: dbo.Suppliers, columns: SupplierID int, CompanyName nvarchar, ContactName nvarchar, ContactTitle nvarchar, Address nvarchar, City nvarchar, Region nvarchar, PostalCode nvarchar, Country nvarchar, Phone nvarchar, Fax nvarchar, HomePage ntext\\n table: dbo.Orders, columns: OrderID int, CustomerID nchar, EmployeeID int, OrderDate datetime, RequiredDate datetime, ShippedDate datetime, ShipVia int, Freight money, ShipName nvarchar, ShipAddress nvarchar, ShipCity nvarchar, ShipRegion nvarchar, ShipPostalCode nvarchar, ShipCountry nvarchar\\n table: dbo.Products, columns: ProductID int, ProductName nvarchar, SupplierID int, CategoryID int, QuantityPerUnit nvarchar, UnitPrice money, UnitsInStock smallint, UnitsOnOrder smallint, ReorderLevel smallint, Discontinued bit\\n table: dbo.OrderDetails, columns: OrderID int, ProductID int, UnitPrice money, Quantity smallint, Discount real\\n table: dbo.CustomerCustomerDemo, columns: CustomerID nchar, CustomerTypeID nchar\\n table: dbo.CustomerDemographics, columns: CustomerTypeID nchar, CustomerDesc ntext\\n table: dbo.Region, columns: RegionID int, RegionDescription nchar\\n table: dbo.Territories, columns: TerritoryID nvarchar, TerritoryDescription nchar, RegionID int\\n table: dbo.EmployeeTerritories, columns: EmployeeID int, TerritoryID nvarchar\\n        \\n        You are a smart AI assistant to help answer business questions based on analyzing data. \\n        You can plan solving the question with one more multiple thought step. At each thought step, you can write python code to analyze data to assist you. Observe what you get at each step to plan for the next step.\\n        You are given following utilities to help you retrieve data and commmunicate your result to end user.\\n        1. executeQuery(sql_query: str): A Python function can query data from the <<data_sources>> given a query which you need to create. The query has to be syntactically correct for sqlserver and only use tables and columns under <<data_sources>>. The executeQuery function returns a Python pandas dataframe contain the results of the query.\\n        2. Use plotly library for data visualization. \\n        3. Use observe(label: str, data: any) utility function to observe data under the label for your evaluation. Use observe() function instead of print() as this is executed in streamlit environment. Due to system limitation, you will only see the first 10 rows of the dataset.\\n        4. To communicate with user, use show() function on data, text and plotly figure. show() is a utility function that can render different types of data to end user. Remember, you don\\'t see data with show(), only user does. You see data with observe()\\n            - If you want to show  user a plotly visualization, then use ```show(fig)`` \\n            - If you want to show user data which is a text or a pandas dataframe or a list, use ```show(data)```\\n            - Never use print(). User don\\'t see anything with print()\\n        5. Lastly, don\\'t forget to deal with data quality problem. You should apply data imputation technique to deal with missing data or NAN data.\\n        6. Always follow the flow of Thought: , Observation:, Action: and Answer: as in template below strictly. \\n\\n        \\n        \\n        <<Template>>\\n        Question: User Question\\n        Thought 1: Your thought here.\\n        Action: \\n        ```python\\n        #Import neccessary libraries here\\n        import numpy as np\\n        #Query some data \\n        sql_query = \"SOME SQL QUERY\"\\n        step1_df = executeQuery(sql_query)\\n        # Replace NAN with 0. Always have this step\\n        step1_df[\\'Some_Column\\'] = step1_df[\\'Some_Column\\'].replace(np.nan,0)\\n        #observe query result\\n        observe(\"some_label\", step1_df) #Always use observe() instead of print\\n        ```\\n        Observation: \\n        step1_df is displayed here\\n        Thought 2: Your thought here\\n        Action:  \\n        ```python\\n        import plotly.express as px \\n        #from step1_df, perform some data analysis action to produce step2_df\\n        #To see the data for yourself the only way is to use observe()\\n        observe(\"some_label\", step2_df) #Always use observe() \\n        #Decide to show it to user.\\n        fig=px.line(step2_df)\\n        #visualize fig object to user.  \\n        show(fig)\\n        #you can also directly display tabular or text data to end user.\\n        show(step2_df)\\n        ```\\n        Observation: \\n        step2_df is displayed here\\n        Answer: Your final answer and comment for the question. Also use Python for computation, never compute result youself.\\n        <</Template>>\\n\\n        \\n        '}, {'role': 'user', 'content': 'Question: Display Product by Category'}]\n",
      "Thought 1\n",
      "We need to join the Products and Categories table to get the Product by Category. \n",
      "SQL Code : \n",
      "Action:\n",
      "#Import neccessary libraries here\n",
      "import numpy as np\n",
      "import plotly.express as px\n",
      "\n",
      "#Query some data \n",
      "sql_query = \"SELECT p.ProductName, c.CategoryName FROM dbo.Products p JOIN dbo.Categories c ON p.CategoryID = c.CategoryID\"\n",
      "product_by_category_df = executeQuery(sql_query)\n",
      "\n",
      "# Replace NAN with 0. Always have this step\n",
      "product_by_category_df = product_by_category_df.replace(np.nan,0)\n",
      "\n",
      "#observe query result\n",
      "observe(\"Product by Category\", product_by_category_df) #Always use observe() instead of print\n",
      "\n",
      "#Group by Category and count the number of products in each category\n",
      "product_by_category_count_df = product_by_category_df.groupby('CategoryName').count().reset_index()\n",
      "\n",
      "#observe query result\n",
      "observe(\"Product by Category Count\", product_by_category_count_df) #Always use observe() instead of print\n",
      "\n",
      "#Visualize the result\n",
      "fig = px.bar(product_by_category_count_df, x='CategoryName', y='ProductName', title='Product Count by Category')\n",
      "show(fig)\n",
      "\n",
      "observation:Product by Category                        ProductName  CategoryName\n",
      "0                             Chai     Beverages\n",
      "1                            Chang     Beverages\n",
      "2                    Aniseed Syrup    Condiments\n",
      "3     Chef Anton's Cajun Seasoning    Condiments\n",
      "4           Chef Anton's Gumbo Mix    Condiments\n",
      "5     Grandma's Boysenberry Spread    Condiments\n",
      "6  Uncle Bob's Organic Dried Pears       Produce\n",
      "7       Northwoods Cranberry Sauce    Condiments\n",
      "8                  Mishi Kobe Niku  Meat/Poultry\n",
      "9                            Ikura       Seafood\n",
      "observation:Product by Category Count      CategoryName  ProductName\n",
      "0       Beverages           12\n",
      "1      Condiments           12\n",
      "2     Confections           13\n",
      "3  Dairy Products           10\n",
      "4  Grains/Cereals            7\n",
      "5    Meat/Poultry            6\n",
      "6         Produce            5\n",
      "7         Seafood           12\n",
      "Figure({\n",
      "    'data': [{'alignmentgroup': 'True',\n",
      "              'hovertemplate': 'CategoryName=%{x}<br>ProductName=%{y}<extra></extra>',\n",
      "              'legendgroup': '',\n",
      "              'marker': {'color': '#636efa', 'pattern': {'shape': ''}},\n",
      "              'name': '',\n",
      "              'offsetgroup': '',\n",
      "              'orientation': 'v',\n",
      "              'showlegend': False,\n",
      "              'textposition': 'auto',\n",
      "              'type': 'bar',\n",
      "              'x': array(['Beverages', 'Condiments', 'Confections', 'Dairy Products',\n",
      "                          'Grains/Cereals', 'Meat/Poultry', 'Produce', 'Seafood'], dtype=object),\n",
      "              'xaxis': 'x',\n",
      "              'y': array([12, 12, 13, 10,  7,  6,  5, 12], dtype=int64),\n",
      "              'yaxis': 'y'}],\n",
      "    'layout': {'barmode': 'relative',\n",
      "               'legend': {'tracegroupgap': 0},\n",
      "               'template': '...',\n",
      "               'title': {'text': 'Product Count by Category'},\n",
      "               'xaxis': {'anchor': 'y', 'domain': [0.0, 1.0], 'title': {'text': 'CategoryName'}},\n",
      "               'yaxis': {'anchor': 'x', 'domain': [0.0, 1.0], 'title': {'text': 'ProductName'}}}\n",
      "})\n",
      "Answer:\n",
      "The bar chart shows the count of products in each category. The category with the highest number of products is Confections, followed by Seafood and Dairy Products. The category with the lowest number of products is Meat/Poultry.\n",
      "Answer is given, finish\n",
      "Prompt & Chat History : \n",
      "[{'role': 'system', 'content': '\\n        <<data_sources>>\\n        table: dbo.sysdiagrams, columns: name nvarchar, principal_id int, diagram_id int, version int, definition varbinary\\n table: dbo.Employees, columns: EmployeeID int, LastName nvarchar, FirstName nvarchar, Title nvarchar, TitleOfCourtesy nvarchar, BirthDate datetime, HireDate datetime, Address nvarchar, City nvarchar, Region nvarchar, PostalCode nvarchar, Country nvarchar, HomePhone nvarchar, Extension nvarchar, Photo image, Notes ntext, ReportsTo int, PhotoPath nvarchar\\n table: dbo.Categories, columns: CategoryID int, CategoryName nvarchar, Description ntext, Picture image\\n table: dbo.Customers, columns: CustomerID nchar, CompanyName nvarchar, ContactName nvarchar, ContactTitle nvarchar, Address nvarchar, City nvarchar, Region nvarchar, PostalCode nvarchar, Country nvarchar, Phone nvarchar, Fax nvarchar\\n table: dbo.Shippers, columns: ShipperID int, CompanyName nvarchar, Phone nvarchar\\n table: dbo.Suppliers, columns: SupplierID int, CompanyName nvarchar, ContactName nvarchar, ContactTitle nvarchar, Address nvarchar, City nvarchar, Region nvarchar, PostalCode nvarchar, Country nvarchar, Phone nvarchar, Fax nvarchar, HomePage ntext\\n table: dbo.Orders, columns: OrderID int, CustomerID nchar, EmployeeID int, OrderDate datetime, RequiredDate datetime, ShippedDate datetime, ShipVia int, Freight money, ShipName nvarchar, ShipAddress nvarchar, ShipCity nvarchar, ShipRegion nvarchar, ShipPostalCode nvarchar, ShipCountry nvarchar\\n table: dbo.Products, columns: ProductID int, ProductName nvarchar, SupplierID int, CategoryID int, QuantityPerUnit nvarchar, UnitPrice money, UnitsInStock smallint, UnitsOnOrder smallint, ReorderLevel smallint, Discontinued bit\\n table: dbo.OrderDetails, columns: OrderID int, ProductID int, UnitPrice money, Quantity smallint, Discount real\\n table: dbo.CustomerCustomerDemo, columns: CustomerID nchar, CustomerTypeID nchar\\n table: dbo.CustomerDemographics, columns: CustomerTypeID nchar, CustomerDesc ntext\\n table: dbo.Region, columns: RegionID int, RegionDescription nchar\\n table: dbo.Territories, columns: TerritoryID nvarchar, TerritoryDescription nchar, RegionID int\\n table: dbo.EmployeeTerritories, columns: EmployeeID int, TerritoryID nvarchar\\n        \\n        You are a smart AI assistant to help answer business questions based on analyzing data. \\n        You can plan solving the question with one more multiple thought step. At each thought step, you can write python code to analyze data to assist you. Observe what you get at each step to plan for the next step.\\n        You are given following utilities to help you retrieve data and commmunicate your result to end user.\\n        1. executeQuery(sql_query: str): A Python function can query data from the <<data_sources>> given a query which you need to create. The query has to be syntactically correct for sqlserver and only use tables and columns under <<data_sources>>. The executeQuery function returns a Python pandas dataframe contain the results of the query.\\n        2. Use plotly library for data visualization. \\n        3. Use observe(label: str, data: any) utility function to observe data under the label for your evaluation. Use observe() function instead of print() as this is executed in streamlit environment. Due to system limitation, you will only see the first 10 rows of the dataset.\\n        4. To communicate with user, use show() function on data, text and plotly figure. show() is a utility function that can render different types of data to end user. Remember, you don\\'t see data with show(), only user does. You see data with observe()\\n            - If you want to show  user a plotly visualization, then use ```show(fig)`` \\n            - If you want to show user data which is a text or a pandas dataframe or a list, use ```show(data)```\\n            - Never use print(). User don\\'t see anything with print()\\n        5. Lastly, don\\'t forget to deal with data quality problem. You should apply data imputation technique to deal with missing data or NAN data.\\n        6. Always follow the flow of Thought: , Observation:, Action: and Answer: as in template below strictly. \\n\\n        \\n        \\n        <<Template>>\\n        Question: User Question\\n        Thought 1: Your thought here.\\n        Action: \\n        ```python\\n        #Import neccessary libraries here\\n        import numpy as np\\n        #Query some data \\n        sql_query = \"SOME SQL QUERY\"\\n        step1_df = executeQuery(sql_query)\\n        # Replace NAN with 0. Always have this step\\n        step1_df[\\'Some_Column\\'] = step1_df[\\'Some_Column\\'].replace(np.nan,0)\\n        #observe query result\\n        observe(\"some_label\", step1_df) #Always use observe() instead of print\\n        ```\\n        Observation: \\n        step1_df is displayed here\\n        Thought 2: Your thought here\\n        Action:  \\n        ```python\\n        import plotly.express as px \\n        #from step1_df, perform some data analysis action to produce step2_df\\n        #To see the data for yourself the only way is to use observe()\\n        observe(\"some_label\", step2_df) #Always use observe() \\n        #Decide to show it to user.\\n        fig=px.line(step2_df)\\n        #visualize fig object to user.  \\n        show(fig)\\n        #you can also directly display tabular or text data to end user.\\n        show(step2_df)\\n        ```\\n        Observation: \\n        step2_df is displayed here\\n        Answer: Your final answer and comment for the question. Also use Python for computation, never compute result youself.\\n        <</Template>>\\n\\n        \\n        '}, {'role': 'user', 'content': 'Question: Display Product by Category\\nQuestion: Display Product by Category\\nThought 1: We need to join the Products and Categories table to get the Product by Category. \\n\\nAction:\\n```python\\n#Import neccessary libraries here\\nimport numpy as np\\nimport plotly.express as px\\n\\n#Query some data \\nsql_query = \"SELECT p.ProductName, c.CategoryName FROM dbo.Products p JOIN dbo.Categories c ON p.CategoryID = c.CategoryID\"\\nproduct_by_category_df = executeQuery(sql_query)\\n\\n# Replace NAN with 0. Always have this step\\nproduct_by_category_df = product_by_category_df.replace(np.nan,0)\\n\\n#observe query result\\nobserve(\"Product by Category\", product_by_category_df) #Always use observe() instead of print\\n```\\n\\n\\nWe need to join the Products and Categories table to get the Product by Category. \\n#Import neccessary libraries here\\nimport numpy as np\\nimport plotly.express as px\\n\\n#Query some data \\nsql_query = \"SELECT p.ProductName, c.CategoryName FROM dbo.Products p JOIN dbo.Categories c ON p.CategoryID = c.CategoryID\"\\nproduct_by_category_df = executeQuery(sql_query)\\n\\n# Replace NAN with 0. Always have this step\\nproduct_by_category_df = product_by_category_df.replace(np.nan,0)\\n\\n#observe query result\\nobserve(\"Product by Category\", product_by_category_df) #Always use observe() instead of print\\n\\nObservation on the first 10 rows of data: []\\nQuestion: Display Product by Category\\nThought 1: We need to join the Products and Categories table to get the Product by Category. \\n\\nAction:\\n```python\\n#Import neccessary libraries here\\nimport numpy as np\\nimport plotly.express as px\\n\\n#Query some data \\nsql_query = \"SELECT p.ProductName, c.CategoryName FROM dbo.Products p JOIN dbo.Categories c ON p.CategoryID = c.CategoryID\"\\nproduct_by_category_df = executeQuery(sql_query)\\n\\n# Replace NAN with 0. Always have this step\\nproduct_by_category_df = product_by_category_df.replace(np.nan,0)\\n\\n#observe query result\\nobserve(\"Product by Category\", product_by_category_df) #Always use observe() instead of print\\n```\\n\\n\\nWe need to join the Products and Categories table to get the Product by Category. \\n#Import neccessary libraries here\\nimport numpy as np\\nimport plotly.express as px\\n\\n#Query some data \\nsql_query = \"SELECT p.ProductName, c.CategoryName FROM dbo.Products p JOIN dbo.Categories c ON p.CategoryID = c.CategoryID\"\\nproduct_by_category_df = executeQuery(sql_query)\\n\\n# Replace NAN with 0. Always have this step\\nproduct_by_category_df = product_by_category_df.replace(np.nan,0)\\n\\n#observe query result\\nobserve(\"Product by Category\", product_by_category_df) #Always use observe() instead of print\\n\\nObservation on the first 10 rows of data: []'}]\n"
     ]
    }
   ],
   "source": [
    "daChatHistory =  [{\"role\": \"system\", \"content\": daSysMessage}]\n",
    "#daQuestion = \"Number of units in stock by category and supplier continent\"\n",
    "daQuestion = \"Display Product by Category\"\n",
    "daNewInput= f\"Question: {daQuestion}\"\n",
    "getDaAnswer(daExtractPattern, daNewInput, daChatHistory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
