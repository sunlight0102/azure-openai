{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Talk and ask about SQL\n",
    "So far we demonstrated the of Open AI to help answer questions over the document, chat over the document and summarize the large document.  The focus so far was primarily on the unstructured nature of the documents.   Now we want to start looking into asking business questions by performing advanced data analytic tasks on a business database. Examples of questions are:\n",
    "\n",
    "- Simple: Which Shipper can ship the order\n",
    "- More difficult: Display Product by Category\n",
    "- Advanced: Number of units in stock by category and supplier continent\n",
    "\n",
    "For the notebook we will focus on two different applications:\n",
    "- SQL Query Writing Assistant: a simple application that translate business question into SQL query language then execute and display result.\n",
    "- Data Analysis Assistant: a more sophisticated application to perform advanced data analytics such as statisical analysis and forecasting. Here we demonstrate the use of [Chain of Thought](https://arxiv.org/abs/2201.11903) and [React](https://arxiv.org/abs/2210.03629) techniques to perform multi-step processing where the next step in the chain also depends on the observation/result from the previous step.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-requisite\n",
    "\n",
    "Deploy SQL server and [Create a empty SQL Database](https://learn.microsoft.com/en-us/azure/azure-sql/database/single-database-create-quickstart?view=azuresql&tabs=azure-portal).  Once the SQL Database is created, run [Northwind SQL](../Deployment/northwind.sql) script to create the Northwind database\n",
    "\n",
    "Also ensure that you have the following environment variables created and configured:\n",
    "- SynapseName: Synapse workspace name\n",
    "- SynapsePool: Synapse pool name\n",
    "- SynapseUser: Synapse user name\n",
    "- SynapsePassword: Synapse password\n",
    "\n",
    "Microsoft ODBC driver"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "import json  \n",
    "import openai\n",
    "from Utilities.envVars import *\n",
    "\n",
    "# Set Search Service endpoint, index name, and API key from environment variables\n",
    "indexName = SearchIndex\n",
    "\n",
    "# Set OpenAI API key and endpoint\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = OpenAiVersion\n",
    "openai_api_key = OpenAiKey\n",
    "assert openai_api_key, \"ERROR: Azure OpenAI Key is missing\"\n",
    "openai.api_key = openai_api_key\n",
    "openAiEndPoint = f\"https://{OpenAiService}.openai.azure.com\"\n",
    "assert openAiEndPoint, \"ERROR: Azure OpenAI Endpoint is missing\"\n",
    "assert \"openai.azure.com\" in openAiEndPoint.lower(), \"ERROR: Azure OpenAI Endpoint should be in the form: \\n\\n\\t<your unique endpoint identifier>.openai.azure.com\"\n",
    "openai.api_base = openAiEndPoint\n",
    "davincimodel = OpenAiDavinci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the needed Python packages\n",
    "import urllib\n",
    "from langchain.llms.openai import AzureOpenAI, OpenAI\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain.schema import AgentAction\n",
    "\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "embeddingModelType = \"azureopenai\"\n",
    "temperature = 0.3\n",
    "tokenLength = 1000\n",
    "\n",
    "if (embeddingModelType == 'azureopenai'):\n",
    "    openai.api_type = \"azure\"\n",
    "    openai.api_key = OpenAiKey\n",
    "    openai.api_version = OpenAiVersion\n",
    "    openai.api_base = f\"https://{OpenAiService}.openai.azure.com\"\n",
    "\n",
    "    llm = AzureOpenAI(deployment_name=OpenAiDavinci,\n",
    "            temperature=temperature,\n",
    "            openai_api_key=OpenAiKey,\n",
    "            max_tokens=tokenLength,\n",
    "            batch_size=10, \n",
    "            max_retries=12)\n",
    "\n",
    "    logging.info(\"LLM Setup done\")\n",
    "    embeddings = OpenAIEmbeddings(model=OpenAiEmbedding, chunk_size=1, openai_api_key=OpenAiKey)\n",
    "elif embeddingModelType == \"openai\":\n",
    "    openai.api_type = \"open_ai\"\n",
    "    openai.api_base = \"https://api.openai.com/v1\"\n",
    "    openai.api_version = '2020-11-07' \n",
    "    openai.api_key = OpenAiApiKey\n",
    "    llm = OpenAI(temperature=temperature,\n",
    "            openai_api_key=OpenAiApiKey,\n",
    "            max_tokens=tokenLength)\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=OpenAiApiKey)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example demonstrates the use of the `SQLDatabaseChain` for answering questions over a database.\n",
    "\n",
    "Under the hood, LangChain uses SQLAlchemy to connect to SQL databases. The SQLDatabaseChain can therefore be used with any SQL dialect supported by SQLAlchemy, such as MS SQL, MySQL, MariaDB, PostgreSQL, Oracle SQL, Databricks and SQLite. \n",
    "\n",
    "NOTE: For data-sensitive projects, you can specify return_direct=True in the SQLDatabaseChain initialization to directly return the output of the SQL query without any additional formatting. This prevents the LLM from seeing any contents within the database. Note, however, the LLM still has access to the database scheme (i.e. dialect, table and key names) by default.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "synapseConnectionString = \"Driver={{ODBC Driver 17 for SQL Server}};Server=tcp:{};\" \\\n",
    "                \"Database={};Uid={};Pwd={};Encrypt=yes;TrustServerCertificate=no;\" \\\n",
    "                \"Connection Timeout=30;\".format(SynapseName, SynapsePool, SynapseUser, SynapsePassword)\n",
    "params = urllib.parse.quote_plus(synapseConnectionString)\n",
    "sqlConnectionString = 'mssql+pyodbc:///?odbc_connect={}'.format(params)\n",
    "db = SQLDatabase.from_uri(sqlConnectionString)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concept here is using Agents as Toolkits.  In the scenario agent is applied to a specific use-case of interacting with SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create the custom prompt that we want to use for our SQL Agent\n",
    "SqlPrefix = \"\"\"You are an agent designed to interact with a SQL database.\n",
    "        Given an input question, create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer.\n",
    "        Always limit your query to at most {top_k} results using the SELECT TOP in SQL Server syntax.\n",
    "        You can order the results by a relevant column to return the most interesting examples in the database.\n",
    "        Never query for all the columns from a specific table, only ask for a the few relevant columns given the question.\n",
    "        If you get a \"no such table\" error, rewrite your query by using the table in quotes.\n",
    "        DO NOT use a column name that does not exist in the table.\n",
    "        You have access to tools for interacting with the database.\n",
    "        Only use the below tools. Only use the information returned by the below tools to construct your final answer.\n",
    "        You MUST double check your query before executing it. If you get an error while executing a query, rewrite a different query and try again.\n",
    "        Observations from the database should be in the form of a JSON with following keys: \"column_name\", \"column_value\"\n",
    "        DO NOT try to execute the query more than three times.\n",
    "        DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\n",
    "        If the question does not seem related to the database, just return \"I don't know\" as the answer.\n",
    "        If you cannot find a way to answer the question, just return the best answer you can find after trying at least three times.\"\"\"\n",
    "\n",
    "SqlSuffix = \"\"\"Begin!\n",
    "    Question: {input}\n",
    "    Thought: I should look at the tables in the database to see what I can query.\n",
    "    {agent_scratchpad}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mTerritories, Orders, Products, CustomerCustomerDemo, Shippers, Suppliers, CustomerDemographics, Region, sysdiagrams, OrderDetails, EmployeeTerritories, Customers, Categories, Employees\u001b[0m\n",
      "Thought:\n",
      "Observation: \u001b[33;1m\u001b[1;3m\n",
      "CREATE TABLE [Shippers] (\n",
      "\t[ShipperID] INTEGER NOT NULL IDENTITY(1,1), \n",
      "\t[CompanyName] NVARCHAR(40) COLLATE SQL_Latin1_General_CP1_CI_AS NOT NULL, \n",
      "\t[Phone] NVARCHAR(24) COLLATE SQL_Latin1_General_CP1_CI_AS NULL, \n",
      "\tCONSTRAINT [PK_Shippers] PRIMARY KEY ([ShipperID])\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from Shippers table:\n",
      "ShipperID\tCompanyName\tPhone\n",
      "1\tSpeedy Express\t(503) 555-9831\n",
      "2\tUnited Package\t(503) 555-3199\n",
      "3\tFederal Shipping\t(503) 555-9931\n",
      "*/\u001b[0m\n",
      "Thought:\n",
      "Observation: \u001b[36;1m\u001b[1;3m[('Speedy Express',), ('United Package',), ('Federal Shipping',)]\u001b[0m\n",
      "Thought:"
     ]
    }
   ],
   "source": [
    "topK = 3\n",
    "question = \"Which Shipper can ship the product?\"\n",
    "\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "agentExecutor = create_sql_agent(\n",
    "        llm=llm,\n",
    "        toolkit=toolkit,\n",
    "        verbose=True,\n",
    "        prefix=SqlPrefix, \n",
    "        #suffix=SqlSuffix,\n",
    "        top_k=topK,\n",
    "        kwargs={\"return_intermediate_steps\": True}\n",
    "    )\n",
    "agentExecutor.return_intermediate_steps = True\n",
    "\n",
    "logging.info(\"Agent Setup done\")\n",
    "answer = agentExecutor._call({\"input\":question})\n",
    "intermediateSteps = answer['intermediate_steps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer : Speedy Express, United Package, and Federal Shipping can ship the product.\n",
      "Observation : [('Speedy Express',), ('United Package',), ('Federal Shipping',)]\n",
      "SQL Query : SELECT TOP 3 CompanyName FROM Shippers\n"
     ]
    }
   ],
   "source": [
    "observation = ''\n",
    "for item in intermediateSteps:\n",
    "    agentAction: AgentAction = item[0]\n",
    "    if (agentAction.tool == 'query_sql_db'):\n",
    "        toolInput = str(agentAction.tool_input)\n",
    "        observation = item[1]\n",
    "\n",
    "print(\"Answer : \" + answer['output'])\n",
    "print(\"Observation : \" + observation)\n",
    "print(\"SQL Query : \" + toolInput)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We covered the concept of SQLAgent, let's now look at the implementation of the SQLAgent (that uses SQLDatabaseChain) and how it can be used to interact with SQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseSequentialChain chain...\u001b[0m\n",
      "Table names to use:\n",
      "\u001b[33;1m\u001b[1;3m['Products', 'Categories']\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "Display Product by Category\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT Products.ProductName, Categories.CategoryName\n",
      "     FROM Products\n",
      "     INNER JOIN Categories\n",
      "     ON Products.CategoryID = Categories.CategoryID;\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[('Chai', 'Beverages'), ('Chang', 'Beverages'), ('Aniseed Syrup', 'Condiments'), (\"Chef Anton's Cajun Seasoning\", 'Condiments'), (\"Chef Anton's Gumbo Mix\", 'Condiments'), (\"Grandma's Boysenberry Spread\", 'Condiments'), (\"Uncle Bob's Organic Dried Pears\", 'Produce'), ('Northwoods Cranberry Sauce', 'Condiments'), ('Mishi Kobe Niku', 'Meat/Poultry'), ('Ikura', 'Seafood'), ('Queso Cabrales', 'Dairy Products'), ('Queso Manchego La Pastora', 'Dairy Products'), ('Konbu', 'Seafood'), ('Tofu', 'Produce'), ('Genen Shouyu', 'Condiments'), ('Pavlova', 'Confections'), ('Alice Mutton', 'Meat/Poultry'), ('Carnarvon Tigers', 'Seafood'), ('Teatime Chocolate Biscuits', 'Confections'), (\"Sir Rodney's Marmalade\", 'Confections'), (\"Sir Rodney's Scones\", 'Confections'), (\"Gustaf's Knäckebröd\", 'Grains/Cereals'), ('Tunnbröd', 'Grains/Cereals'), ('Guaraná Fantástica', 'Beverages'), ('NuNuCa Nuß-Nougat-Creme', 'Confections'), ('Gumbär Gummibärchen', 'Confections'), ('Schoggi Schokolade', 'Confections'), ('Rössle Sauerkraut', 'Produce'), ('Thüringer Rostbratwurst', 'Meat/Poultry'), ('Nord-Ost Matjeshering', 'Seafood'), ('Gorgonzola Telino', 'Dairy Products'), ('Mascarpone Fabioli', 'Dairy Products'), ('Geitost', 'Dairy Products'), ('Sasquatch Ale', 'Beverages'), ('Steeleye Stout', 'Beverages'), ('Inlagd Sill', 'Seafood'), ('Gravad lax', 'Seafood'), ('Côte de Blaye', 'Beverages'), ('Chartreuse verte', 'Beverages'), ('Boston Crab Meat', 'Seafood'), (\"Jack's New England Clam Chowder\", 'Seafood'), ('Singaporean Hokkien Fried Mee', 'Grains/Cereals'), ('Ipoh Coffee', 'Beverages'), ('Gula Malacca', 'Condiments'), ('Rogede sild', 'Seafood'), ('Spegesild', 'Seafood'), ('Zaanse koeken', 'Confections'), ('Chocolade', 'Confections'), ('Maxilaku', 'Confections'), ('Valkoinen suklaa', 'Confections'), ('Manjimup Dried Apples', 'Produce'), ('Filo Mix', 'Grains/Cereals'), ('Perth Pasties', 'Meat/Poultry'), ('Tourtière', 'Meat/Poultry'), ('Pâté chinois', 'Meat/Poultry'), ('Gnocchi di nonna Alice', 'Grains/Cereals'), ('Ravioli Angelo', 'Grains/Cereals'), ('Escargots de Bourgogne', 'Seafood'), ('Raclette Courdavault', 'Dairy Products'), ('Camembert Pierrot', 'Dairy Products'), (\"Sirop d'érable\", 'Condiments'), ('Tarte au sucre', 'Confections'), ('Vegie-spread', 'Condiments'), ('Wimmers gute Semmelknödel', 'Grains/Cereals'), ('Louisiana Fiery Hot Pepper Sauce', 'Condiments'), ('Louisiana Hot Spiced Okra', 'Condiments'), ('Laughing Lumberjack Lager', 'Beverages'), ('Scottish Longbreads', 'Confections'), ('Gudbrandsdalsost', 'Dairy Products'), ('Outback Lager', 'Beverages'), ('Flotemysost', 'Dairy Products'), ('Mozzarella di Giovanni', 'Dairy Products'), ('Röd Kaviar', 'Seafood'), ('Longlife Tofu', 'Produce'), ('Rhönbräu Klosterbier', 'Beverages'), ('Lakkalikööri', 'Beverages'), ('Original Frankfurter grüne Soße', 'Condiments')]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3mThe answer is a list of product names and their corresponding categories: ('Chai', 'Beverages'), ('Chang', 'Beverages'), ('Aniseed Syrup', 'Condiments'), (\"Chef Anton's Cajun Seasoning\", 'Condiments'), (\"Chef Anton's Gumbo Mix\", 'Condiments'), (\"Grandma's Boysenberry Spread\", 'Condiments'), (\"Uncle Bob's Organic Dried Pears\", 'Produce'), ('Northwoods Cranberry Sauce', 'Condiments'), ('Mishi Kobe Niku', 'Meat/Poultry'), ('Ikura', 'Seafood'), ('Queso Cabrales', 'Dairy Products'), ('Queso Manchego La Pastora', 'Dairy Products'), ('Konbu', 'Seafood'), ('Tofu', 'Produce'), ('Genen Shouyu', 'Condiments'), ('Pavlova', 'Confections'), ('Alice Mutton', 'Meat/Poultry'), ('Carnarvon Tigers', 'Seafood'), ('Teatime Chocolate Biscuits', 'Confections'), (\"Sir Rodney's Marmalade\", 'Confections'), (\"Sir Rodney's Scones\", 'Confections'), (\"Gustaf's Knäckebröd\", 'Grains/Cereals'), ('Tunnbröd', 'Grains/Cereals'), ('Guaraná Fantástica', 'Beverages'), ('NuNuCa Nuß-Nougat-Creme', 'Confections'), ('Gumbär Gummibärchen', 'Confections'), ('Schoggi Schokolade', 'Confections'), ('Rössle Sauerkraut', 'Produce'), ('Thüringer Rostbratwurst', 'Meat/Poultry'), ('Nord-Ost Matjeshering', 'Seafood'), ('Gorgonzola Telino', 'Dairy Products'), ('Mascarpone Fabioli', 'Dairy Products'), ('Geitost', 'Dairy Products'), ('Sasquatch Ale', 'Beverages'), ('Steeleye Stout', 'Beverages'), ('Inlagd Sill', 'Seafood'), ('Gravad lax', 'Seafood'), ('Côte de Blaye', 'Beverages'), ('Chartreuse verte', 'Beverages'), ('Boston Crab Meat', 'Seafood'), (\"Jack's New England Clam Chowder\", 'Seafood'), ('Singaporean Hokkien Fried Mee', 'Grains/Cereals'), ('Ipoh Coffee', 'Beverages'), ('Gula Malacca', 'Condiments'), ('Rogede sild', 'Seafood'), ('Spegesild', 'Seafood'), ('Zaanse koeken', 'Confections'), ('Chocolade', 'Confections'), ('Maxilaku', 'Confections'), ('Valkoinen suklaa', 'Confections'), ('Manjimup Dried Apples', 'Produce'), ('Filo Mix', 'Grains/Cereals'), ('Perth Pasties', 'Meat/Poultry'), ('Tourtière', 'Meat/Poultry'), ('Pâté chinois', 'Meat/Poultry'), ('Gnocchi di nonna Alice', 'Grains/Cereals'), ('Ravioli Angelo', 'Grains/Cereals'), ('Escargots de Bourgogne', 'Seafood'), ('Raclette Courdavault', 'Dairy Products'), ('Camembert Pierrot', 'Dairy Products'), (\"Sirop d'érable\", 'Condiments'), ('Tarte au sucre', 'Confections'), ('Vegie-spread', 'Condiments'), ('Wimmers gute Semmelknödel', 'Grains/Cereals'), ('Louisiana Fiery Hot Pepper Sauce', 'Condiments'), ('Louisiana Hot Spiced Okra', 'Condiments'), ('Laughing Lumberjack Lager', 'Beverages'), ('Scottish Longbreads', 'Confections'), ('Gudbrandsdalsost', 'Dairy Products'), ('Outback Lager', 'Beverages'), ('Flotemysost', 'Dairy Products'), ('Mozzarella di Giovanni', 'Dairy Products'), ('Röd Kaviar', 'Seafood'), ('Longlife Tofu', 'Produce'), ('Rhönbräu Klosterbier', 'Beverages'), ('Lakkaliköö\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Answer : The answer is a list of product names and their corresponding categories: ('Chai', 'Beverages'), ('Chang', 'Beverages'), ('Aniseed Syrup', 'Condiments'), (\"Chef Anton's Cajun Seasoning\", 'Condiments'), (\"Chef Anton's Gumbo Mix\", 'Condiments'), (\"Grandma's Boysenberry Spread\", 'Condiments'), (\"Uncle Bob's Organic Dried Pears\", 'Produce'), ('Northwoods Cranberry Sauce', 'Condiments'), ('Mishi Kobe Niku', 'Meat/Poultry'), ('Ikura', 'Seafood'), ('Queso Cabrales', 'Dairy Products'), ('Queso Manchego La Pastora', 'Dairy Products'), ('Konbu', 'Seafood'), ('Tofu', 'Produce'), ('Genen Shouyu', 'Condiments'), ('Pavlova', 'Confections'), ('Alice Mutton', 'Meat/Poultry'), ('Carnarvon Tigers', 'Seafood'), ('Teatime Chocolate Biscuits', 'Confections'), (\"Sir Rodney's Marmalade\", 'Confections'), (\"Sir Rodney's Scones\", 'Confections'), (\"Gustaf's Knäckebröd\", 'Grains/Cereals'), ('Tunnbröd', 'Grains/Cereals'), ('Guaraná Fantástica', 'Beverages'), ('NuNuCa Nuß-Nougat-Creme', 'Confections'), ('Gumbär Gummibärchen', 'Confections'), ('Schoggi Schokolade', 'Confections'), ('Rössle Sauerkraut', 'Produce'), ('Thüringer Rostbratwurst', 'Meat/Poultry'), ('Nord-Ost Matjeshering', 'Seafood'), ('Gorgonzola Telino', 'Dairy Products'), ('Mascarpone Fabioli', 'Dairy Products'), ('Geitost', 'Dairy Products'), ('Sasquatch Ale', 'Beverages'), ('Steeleye Stout', 'Beverages'), ('Inlagd Sill', 'Seafood'), ('Gravad lax', 'Seafood'), ('Côte de Blaye', 'Beverages'), ('Chartreuse verte', 'Beverages'), ('Boston Crab Meat', 'Seafood'), (\"Jack's New England Clam Chowder\", 'Seafood'), ('Singaporean Hokkien Fried Mee', 'Grains/Cereals'), ('Ipoh Coffee', 'Beverages'), ('Gula Malacca', 'Condiments'), ('Rogede sild', 'Seafood'), ('Spegesild', 'Seafood'), ('Zaanse koeken', 'Confections'), ('Chocolade', 'Confections'), ('Maxilaku', 'Confections'), ('Valkoinen suklaa', 'Confections'), ('Manjimup Dried Apples', 'Produce'), ('Filo Mix', 'Grains/Cereals'), ('Perth Pasties', 'Meat/Poultry'), ('Tourtière', 'Meat/Poultry'), ('Pâté chinois', 'Meat/Poultry'), ('Gnocchi di nonna Alice', 'Grains/Cereals'), ('Ravioli Angelo', 'Grains/Cereals'), ('Escargots de Bourgogne', 'Seafood'), ('Raclette Courdavault', 'Dairy Products'), ('Camembert Pierrot', 'Dairy Products'), (\"Sirop d'érable\", 'Condiments'), ('Tarte au sucre', 'Confections'), ('Vegie-spread', 'Condiments'), ('Wimmers gute Semmelknödel', 'Grains/Cereals'), ('Louisiana Fiery Hot Pepper Sauce', 'Condiments'), ('Louisiana Hot Spiced Okra', 'Condiments'), ('Laughing Lumberjack Lager', 'Beverages'), ('Scottish Longbreads', 'Confections'), ('Gudbrandsdalsost', 'Dairy Products'), ('Outback Lager', 'Beverages'), ('Flotemysost', 'Dairy Products'), ('Mozzarella di Giovanni', 'Dairy Products'), ('Röd Kaviar', 'Seafood'), ('Longlife Tofu', 'Produce'), ('Rhönbräu Klosterbier', 'Beverages'), ('Lakkaliköö\n",
      "toolInput : {'input': 'Display Product by Category\\nSQLQuery:SELECT Products.ProductName, Categories.CategoryName\\n     FROM Products\\n     INNER JOIN Categories\\n     ON Products.CategoryID = Categories.CategoryID;\\nSQLResult: [(\\'Chai\\', \\'Beverages\\'), (\\'Chang\\', \\'Beverages\\'), (\\'Aniseed Syrup\\', \\'Condiments\\'), (\"Chef Anton\\'s Cajun Seasoning\", \\'Condiments\\'), (\"Chef Anton\\'s Gumbo Mix\", \\'Condiments\\'), (\"Grandma\\'s Boysenberry Spread\", \\'Condiments\\'), (\"Uncle Bob\\'s Organic Dried Pears\", \\'Produce\\'), (\\'Northwoods Cranberry Sauce\\', \\'Condiments\\'), (\\'Mishi Kobe Niku\\', \\'Meat/Poultry\\'), (\\'Ikura\\', \\'Seafood\\'), (\\'Queso Cabrales\\', \\'Dairy Products\\'), (\\'Queso Manchego La Pastora\\', \\'Dairy Products\\'), (\\'Konbu\\', \\'Seafood\\'), (\\'Tofu\\', \\'Produce\\'), (\\'Genen Shouyu\\', \\'Condiments\\'), (\\'Pavlova\\', \\'Confections\\'), (\\'Alice Mutton\\', \\'Meat/Poultry\\'), (\\'Carnarvon Tigers\\', \\'Seafood\\'), (\\'Teatime Chocolate Biscuits\\', \\'Confections\\'), (\"Sir Rodney\\'s Marmalade\", \\'Confections\\'), (\"Sir Rodney\\'s Scones\", \\'Confections\\'), (\"Gustaf\\'s Knäckebröd\", \\'Grains/Cereals\\'), (\\'Tunnbröd\\', \\'Grains/Cereals\\'), (\\'Guaraná Fantástica\\', \\'Beverages\\'), (\\'NuNuCa Nuß-Nougat-Creme\\', \\'Confections\\'), (\\'Gumbär Gummibärchen\\', \\'Confections\\'), (\\'Schoggi Schokolade\\', \\'Confections\\'), (\\'Rössle Sauerkraut\\', \\'Produce\\'), (\\'Thüringer Rostbratwurst\\', \\'Meat/Poultry\\'), (\\'Nord-Ost Matjeshering\\', \\'Seafood\\'), (\\'Gorgonzola Telino\\', \\'Dairy Products\\'), (\\'Mascarpone Fabioli\\', \\'Dairy Products\\'), (\\'Geitost\\', \\'Dairy Products\\'), (\\'Sasquatch Ale\\', \\'Beverages\\'), (\\'Steeleye Stout\\', \\'Beverages\\'), (\\'Inlagd Sill\\', \\'Seafood\\'), (\\'Gravad lax\\', \\'Seafood\\'), (\\'Côte de Blaye\\', \\'Beverages\\'), (\\'Chartreuse verte\\', \\'Beverages\\'), (\\'Boston Crab Meat\\', \\'Seafood\\'), (\"Jack\\'s New England Clam Chowder\", \\'Seafood\\'), (\\'Singaporean Hokkien Fried Mee\\', \\'Grains/Cereals\\'), (\\'Ipoh Coffee\\', \\'Beverages\\'), (\\'Gula Malacca\\', \\'Condiments\\'), (\\'Rogede sild\\', \\'Seafood\\'), (\\'Spegesild\\', \\'Seafood\\'), (\\'Zaanse koeken\\', \\'Confections\\'), (\\'Chocolade\\', \\'Confections\\'), (\\'Maxilaku\\', \\'Confections\\'), (\\'Valkoinen suklaa\\', \\'Confections\\'), (\\'Manjimup Dried Apples\\', \\'Produce\\'), (\\'Filo Mix\\', \\'Grains/Cereals\\'), (\\'Perth Pasties\\', \\'Meat/Poultry\\'), (\\'Tourtière\\', \\'Meat/Poultry\\'), (\\'Pâté chinois\\', \\'Meat/Poultry\\'), (\\'Gnocchi di nonna Alice\\', \\'Grains/Cereals\\'), (\\'Ravioli Angelo\\', \\'Grains/Cereals\\'), (\\'Escargots de Bourgogne\\', \\'Seafood\\'), (\\'Raclette Courdavault\\', \\'Dairy Products\\'), (\\'Camembert Pierrot\\', \\'Dairy Products\\'), (\"Sirop d\\'érable\", \\'Condiments\\'), (\\'Tarte au sucre\\', \\'Confections\\'), (\\'Vegie-spread\\', \\'Condiments\\'), (\\'Wimmers gute Semmelknödel\\', \\'Grains/Cereals\\'), (\\'Louisiana Fiery Hot Pepper Sauce\\', \\'Condiments\\'), (\\'Louisiana Hot Spiced Okra\\', \\'Condiments\\'), (\\'Laughing Lumberjack Lager\\', \\'Beverages\\'), (\\'Scottish Longbreads\\', \\'Confections\\'), (\\'Gudbrandsdalsost\\', \\'Dairy Products\\'), (\\'Outback Lager\\', \\'Beverages\\'), (\\'Flotemysost\\', \\'Dairy Products\\'), (\\'Mozzarella di Giovanni\\', \\'Dairy Products\\'), (\\'Röd Kaviar\\', \\'Seafood\\'), (\\'Longlife Tofu\\', \\'Produce\\'), (\\'Rhönbräu Klosterbier\\', \\'Beverages\\'), (\\'Lakkalikööri\\', \\'Beverages\\'), (\\'Original Frankfurter grüne Soße\\', \\'Condiments\\')]\\nAnswer:', 'top_k': '3', 'dialect': 'mssql', 'table_info': '\\nCREATE TABLE [Categories] (\\n\\t[CategoryID] INTEGER NOT NULL IDENTITY(1,1), \\n\\t[CategoryName] NVARCHAR(15) COLLATE SQL_Latin1_General_CP1_CI_AS NOT NULL, \\n\\t[Description] NTEXT(1073741823) COLLATE SQL_Latin1_General_CP1_CI_AS NULL, \\n\\t[Picture] IMAGE NULL, \\n\\tCONSTRAINT [PK_Categories] PRIMARY KEY ([CategoryID])\\n)\\n\\n/*\\n3 rows from Categories table:\\nCategoryID\\tCategoryName\\tDescription\\tPicture\\n1\\tBeverages\\tSoft drinks, coffees, teas, beers, and ales\\tb\"\\\\x15\\\\x1c/\\\\x00\\\\x02\\\\x00\\\\x00\\\\x00\\\\r\\\\x00\\\\x0e\\\\x00\\\\x14\\\\x00!\\\\x00\\\\xff\\\\xff\\\\xff\\\\xffBitmap Image\\\\x00Paint.Pict\\n2\\tCondiments\\tSweet and savory sauces, relishes, spreads, and seasonings\\tb\"\\\\x15\\\\x1c/\\\\x00\\\\x02\\\\x00\\\\x00\\\\x00\\\\r\\\\x00\\\\x0e\\\\x00\\\\x14\\\\x00!\\\\x00\\\\xff\\\\xff\\\\xff\\\\xffBitmap Image\\\\x00Paint.Pict\\n3\\tConfections\\tDesserts, candies, and sweet breads\\tb\"\\\\x15\\\\x1c/\\\\x00\\\\x02\\\\x00\\\\x00\\\\x00\\\\r\\\\x00\\\\x0e\\\\x00\\\\x14\\\\x00!\\\\x00\\\\xff\\\\xff\\\\xff\\\\xffBitmap Image\\\\x00Paint.Pict\\n*/\\n\\n\\nCREATE TABLE [Products] (\\n\\t[ProductID] INTEGER NOT NULL IDENTITY(1,1), \\n\\t[ProductName] NVARCHAR(40) COLLATE SQL_Latin1_General_CP1_CI_AS NOT NULL, \\n\\t[SupplierID] INTEGER NULL, \\n\\t[CategoryID] INTEGER NULL, \\n\\t[QuantityPerUnit] NVARCHAR(20) COLLATE SQL_Latin1_General_CP1_CI_AS NULL, \\n\\t[UnitPrice] MONEY NULL DEFAULT ((0)), \\n\\t[UnitsInStock] SMALLINT NULL DEFAULT ((0)), \\n\\t[UnitsOnOrder] SMALLINT NULL DEFAULT ((0)), \\n\\t[ReorderLevel] SMALLINT NULL DEFAULT ((0)), \\n\\t[Discontinued] BIT NOT NULL DEFAULT ((0)), \\n\\tCONSTRAINT [PK_Products] PRIMARY KEY ([ProductID]), \\n\\tCONSTRAINT [FK_Products_Categories] FOREIGN KEY([CategoryID]) REFERENCES [Categories] ([CategoryID]), \\n\\tCONSTRAINT [FK_Products_Suppliers] FOREIGN KEY([SupplierID]) REFERENCES [Suppliers] ([SupplierID])\\n)\\n\\n/*\\n3 rows from Products table:\\nProductID\\tProductName\\tSupplierID\\tCategoryID\\tQuantityPerUnit\\tUnitPrice\\tUnitsInStock\\tUnitsOnOrder\\tReorderLevel\\tDiscontinued\\n1\\tChai\\t1\\t1\\t10 boxes x 20 bags\\t18.0000\\t39\\t0\\t10\\tFalse\\n2\\tChang\\t1\\t1\\t24 - 12 oz bottles\\t19.0000\\t17\\t40\\t25\\tFalse\\n3\\tAniseed Syrup\\t1\\t2\\t12 - 550 ml bottles\\t10.0000\\t13\\t70\\t25\\tFalse\\n*/', 'stop': ['\\nSQLResult:']}\n",
      "observation : SELECT Products.ProductName, Categories.CategoryName\n",
      "     FROM Products\n",
      "     INNER JOIN Categories\n",
      "     ON Products.CategoryID = Categories.CategoryID;\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SQLDatabaseSequentialChain\n",
    "sqlDbChainTemplate = \"\"\"Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer.\n",
    "    Use the following format:\n",
    "\n",
    "    Question: \"Question here\"\n",
    "    SQLQuery: \"SQL Query to run\"\n",
    "    SQLResult: \"Result of the SQLQuery\"\n",
    "    Answer: \"Final answer here\"\n",
    "\n",
    "    Only use the following tables:\n",
    "\n",
    "    {table_info}\n",
    "    \n",
    "    Question: {input}\n",
    "\n",
    "    \"\"\"\n",
    "SqlDbChainPrompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"table_info\", \"dialect\"], template=sqlDbChainTemplate\n",
    ")\n",
    "\n",
    "# SqlDbChain = SQLDatabaseChain(llm=llm, database=db, prompt=SqlPrompt, verbose=True, return_intermediate_steps=True,\n",
    "#                               top_k=topK)\n",
    "SqlDbChain = SQLDatabaseSequentialChain.from_llm(llm, db, verbose=True, return_intermediate_steps=True, \n",
    "                                                    query_prompt=SqlDbChainPrompt, top_k=topK)\n",
    "question = \"Display Product by Category\"\n",
    "answer = SqlDbChain(question)\n",
    "intermediateSteps = answer['intermediate_steps']\n",
    "sqlAnswer = answer['result']\n",
    "toolInput = intermediateSteps[0]\n",
    "observation = intermediateSteps[1]\n",
    "print(\"Answer : \" + sqlAnswer)\n",
    "print(\"toolInput : \" + str(toolInput))\n",
    "print(\"observation : \" + str(observation))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test using GPT 3.5 turbo and with custom code & Prompt outside of Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "\n",
    "def executeQuery(query, limit=10000):  \n",
    "    engine = create_engine(sqlConnectionString)\n",
    "    result = pd.read_sql_query(query, engine)\n",
    "    result = result.infer_objects()\n",
    "    for col in result.columns:  \n",
    "        if 'date' in col.lower():  \n",
    "            result[col] = pd.to_datetime(result[col], errors=\"ignore\")  \n",
    "\n",
    "    if limit is not None:  \n",
    "        result = result.head(limit)  # limit to save memory  \n",
    "    # session.close()  \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTableSchema():\n",
    "    sqlQuery = \"\"\"  \n",
    "    SELECT C.TABLE_NAME, C.COLUMN_NAME, C.DATA_TYPE, T.TABLE_TYPE, T.TABLE_SCHEMA  \n",
    "    FROM INFORMATION_SCHEMA.COLUMNS C  \n",
    "    JOIN INFORMATION_SCHEMA.TABLES T ON C.TABLE_NAME = T.TABLE_NAME AND C.TABLE_SCHEMA = T.TABLE_SCHEMA  \n",
    "    WHERE T.TABLE_TYPE = 'BASE TABLE'  \n",
    "    \"\"\"  \n",
    "    \n",
    "    # Execute the SQL query and store the results in a DataFrame  \n",
    "    df = executeQuery(sqlQuery, limit=None)  \n",
    "    output=[]\n",
    "    # Initialize variables to store table and column information  \n",
    "    curTable = ''  \n",
    "    columns = []  \n",
    "    \n",
    "    # Loop through the query results and output the table and column information  \n",
    "    for index, row in df.iterrows():\n",
    "        tableName = f\"{row['TABLE_SCHEMA']}.{row['TABLE_NAME']}\" \n",
    "        colName = row['COLUMN_NAME']  \n",
    "        dataType = row['DATA_TYPE']   \n",
    "        if \" \" in tableName:\n",
    "            tableName= f\"[{tableName}]\" \n",
    "        colName = row['COLUMN_NAME']  \n",
    "        if \" \" in colName:\n",
    "            colName= f\"[{colName}]\" \n",
    "\n",
    "        # If the table name has changed, output the previous table's information  \n",
    "        if curTable != tableName and curTable != '':  \n",
    "            output.append(f\"table: {curTable}, columns: {', '.join(columns)}\")  \n",
    "            columns = []  \n",
    "        \n",
    "        # Add the current column information to the list of columns for the current table  \n",
    "        columns.append(f\"{colName} {dataType}\")  \n",
    "        \n",
    "        # Update the current table name  \n",
    "        curTable = tableName  \n",
    "    \n",
    "    # Output the last table's information  \n",
    "    output.append(f\"table: {curTable}, columns: {', '.join(columns)}\")\n",
    "    output = \"\\n \".join(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callLlm(embeddingModelType, prompt, stop):\n",
    "    if (embeddingModelType == 'azureopenai'):\n",
    "        openai.api_type = \"azure\"\n",
    "        openai.api_key = OpenAiKey\n",
    "        openai.api_version = OpenAiVersion\n",
    "        openai.api_base = f\"https://{OpenAiService}.openai.azure.com\"\n",
    "        response = openai.ChatCompletion.create(\n",
    "            engine=OpenAiChat, \n",
    "            messages = prompt,\n",
    "            temperature=temperature,\n",
    "            max_tokens=tokenLength,\n",
    "            stop=stop\n",
    "            )\n",
    "        logging.info(\"LLM Setup done\")\n",
    "        llmOutput = response['choices'][0]['message']['content']\n",
    "    elif embeddingModelType == \"openai\":\n",
    "        openai.api_type = \"open_ai\"\n",
    "        openai.api_base = \"https://api.openai.com/v1\"\n",
    "        openai.api_version = '2020-11-07' \n",
    "        openai.api_key = OpenAiApiKey\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\", \n",
    "            messages = prompt,\n",
    "            temperature=temperature,\n",
    "            max_tokens=tokenLength,\n",
    "            stop=stop\n",
    "            )\n",
    "        llmOutput = response['choices'][0]['message']['content']\n",
    "    return llmOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractOutput(textInput, extractPattern):\n",
    "    output={}\n",
    "    if len(textInput)==0:\n",
    "        return output\n",
    "    for pattern in extractPattern: \n",
    "        if \"sql\" in pattern[1]:\n",
    "\n",
    "            sql_query=\"\"\n",
    "            sql_result = re.findall(pattern[1], textInput, re.DOTALL)\n",
    "\n",
    "            if len(sql_result)>0:\n",
    "                sql_query=sql_result[0]\n",
    "                output[pattern[0]]= sql_query\n",
    "            else:\n",
    "                return output\n",
    "            text_before = textInput.split(sql_query)[0].strip(\"\\n\").strip(\"```sql\").strip(\"\\n\")\n",
    "\n",
    "            if text_before is not None and len(text_before)>0:\n",
    "                output[\"text_before\"]=text_before\n",
    "            text_after =textInput.split(sql_query)[1].strip(\"\\n\").strip(\"```\")\n",
    "            if text_after is not None and len(text_after)>0:\n",
    "                output[\"text_after\"]=text_after\n",
    "            return output\n",
    "\n",
    "        if \"python\" in pattern[1]:\n",
    "            result = re.findall(pattern[1], textInput, re.DOTALL)\n",
    "            if len(result)>0:\n",
    "                output[pattern[0]]= result[0]\n",
    "        else:\n",
    "\n",
    "            result = re.search(pattern[1], textInput,re.DOTALL)\n",
    "            if result:  \n",
    "                output[result.group(1)]= result.group(2)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNextSteps(extractPattern, embeddingModelType, updatedUserContent, chatHistory, stop):\n",
    "    oldUserContent=\"\"\n",
    "    if len(chatHistory)>1:\n",
    "        oldUserContent= chatHistory.pop() #removing old history\n",
    "        oldUserContent=oldUserContent['content']+\"\\n\"\n",
    "    chatHistory.append({\"role\": \"user\", \"content\": oldUserContent+updatedUserContent})\n",
    "    #print(\"prompt input \", chatHistory)\n",
    "    n=0\n",
    "    try:\n",
    "        llmOutput = callLlm(embeddingModelType, chatHistory, stop)\n",
    "        #print(\"llmOutput \\n\", llmOutput)\n",
    "    except Exception as e:\n",
    "        time.sleep(8) #sleep for 8 seconds\n",
    "        while n<5:\n",
    "            try:\n",
    "                llmOutput = callLlm(embeddingModelType, chatHistory, stop)\n",
    "            except Exception as e:\n",
    "                n +=1\n",
    "                print(\"error calling open AI, I am retrying 5 attempts , attempt \", n)\n",
    "                time.sleep(8) #sleep for 8 seconds\n",
    "                print(e)\n",
    "\n",
    "        llmOutput = \"OPENAI_ERROR\"\n",
    "        print(\"llmOutput: \", llmOutput)\n",
    "    output = extractOutput(llmOutput, extractPattern)\n",
    "    if len(output)==0 and llmOutput != \"OPENAI_ERROR\": #wrong output format\n",
    "        llmOutput = \"WRONG_OUTPUT_FORMAT\"\n",
    "    return llmOutput,output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For first use-case test it as SQL Query Writing Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sysDefaultMessage =\"\"\"\n",
    "    You are an agent designed to interact with a SQL database with schema detail in <<data_sources>>.\n",
    "    Given an input question, create a syntactically correct {sql_engine} query to run, then look at the results of the query and return the answer.\n",
    "    You can order the results by a relevant column to return the most interesting examples in the database.\n",
    "    Never query for all the columns from a specific table, only ask for a the few relevant columns given the question.\n",
    "    You MUST double check your query before executing it. If you get an error while executing a query, rewrite the query and try again.\n",
    "    DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\n",
    "    Remember to format SQL query as in ```sql\\n SQL QUERY HERE ``` in your response.\n",
    "    \n",
    "    \"\"\"\n",
    "fewShotExamples=\"\"\n",
    "sqlEngine = 'sqlserver'\n",
    "extractPattern=[('sql',r\"```sql\\n(.*?)```\")]\n",
    "\n",
    "# get Table Schema\n",
    "tableSchema  = getTableSchema()\n",
    "sysMessage = f\"\"\"\n",
    "        <<data_sources>>\n",
    "        {tableSchema}\n",
    "        {sysDefaultMessage.format(sql_engine=sqlEngine)}\n",
    "        {fewShotExamples}\n",
    "        \"\"\"\n",
    "tokenLength=1000\n",
    "temperature=0\n",
    "embeddingModelType = \"azureopenai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAnswer(newInput, chatHistory):\n",
    "    maxSteps=15\n",
    "    count=1\n",
    "    while count<= maxSteps:\n",
    "        llmOutput,nextSteps = getNextSteps(extractPattern, embeddingModelType, newInput, chatHistory, stop=[\"Observation:\", f\"Thought {count+1}\"])\n",
    "        if llmOutput=='OPENAI_ERROR':\n",
    "            print(\"Error Calling Azure Open AI, probably due to max service limit, please try again\")\n",
    "            break\n",
    "        elif llmOutput=='WRONG_OUTPUT_FORMAT': #just have open AI try again till the right output comes\n",
    "            count +=1\n",
    "            continue\n",
    "        output =None\n",
    "        error= False\n",
    "\n",
    "        newInput += f\"\\n{llmOutput}\"\n",
    "        for key, value in nextSteps.items():\n",
    "            newInput += f\"\\n{value}\"\n",
    "            \n",
    "            if \"SQL\" in key.upper():\n",
    "                print(\"SQL Code : \")\n",
    "                print(value)\n",
    "                try:\n",
    "                    output = executeQuery(value)\n",
    "                except Exception as e:\n",
    "                    newInput +=\"Encounter following error, can you try again?\\n\"+str(e)\n",
    "                    error=str(e)\n",
    "            else:\n",
    "                print(\"Non-SQL Value : \")\n",
    "                print(value)\n",
    "        print(\"Prompt & Chat History : \")\n",
    "        print(chatHistory)\n",
    "\n",
    "        if output is not None:\n",
    "            print(\"Output : \")\n",
    "            print(output)\n",
    "            break\n",
    "\n",
    "        if error:\n",
    "            print(error)\n",
    "\n",
    "        count +=1\n",
    "        if count>= maxSteps:\n",
    "            print(\"Cannot handle the question, please change the question and try again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Code : \n",
      "SELECT s.ShipperID, s.CompanyName\n",
      "FROM Shippers s\n",
      "JOIN Orders o ON s.ShipperID = o.ShipVia\n",
      "JOIN OrderDetails od ON o.OrderID = od.OrderID\n",
      "JOIN Products p ON od.ProductID = p.ProductID\n",
      "WHERE p.ProductName = '<<product_name>>'\n",
      "\n",
      "Non-SQL Value : \n",
      "To determine which shipper can ship a product, we need to look at the \"Shippers\" table. We also need to consider the \"Products\" table to identify the specific product we are interested in. \n",
      "\n",
      "Here is the SQL query to retrieve the shipper information for a given product:\n",
      "Non-SQL Value : \n",
      "\n",
      "\n",
      "Please replace `<<product_name>>` with the actual name of the product you are interested in.\n",
      "\n",
      "This query joins the \"Shippers\" table with the \"Orders\", \"OrderDetails\", and \"Products\" tables to find the shipper associated with the specified product. The result will include the shipper ID and company name.\n",
      "\n",
      "Please let me know if you need any further assistance.\n",
      "Prompt & Chat History : \n",
      "[{'role': 'system', 'content': '\\n        <<data_sources>>\\n        table: dbo.sysdiagrams, columns: name nvarchar, principal_id int, diagram_id int, version int, definition varbinary\\n table: dbo.Employees, columns: EmployeeID int, LastName nvarchar, FirstName nvarchar, Title nvarchar, TitleOfCourtesy nvarchar, BirthDate datetime, HireDate datetime, Address nvarchar, City nvarchar, Region nvarchar, PostalCode nvarchar, Country nvarchar, HomePhone nvarchar, Extension nvarchar, Photo image, Notes ntext, ReportsTo int, PhotoPath nvarchar\\n table: dbo.Categories, columns: CategoryID int, CategoryName nvarchar, Description ntext, Picture image\\n table: dbo.Customers, columns: CustomerID nchar, CompanyName nvarchar, ContactName nvarchar, ContactTitle nvarchar, Address nvarchar, City nvarchar, Region nvarchar, PostalCode nvarchar, Country nvarchar, Phone nvarchar, Fax nvarchar\\n table: dbo.Shippers, columns: ShipperID int, CompanyName nvarchar, Phone nvarchar\\n table: dbo.Suppliers, columns: SupplierID int, CompanyName nvarchar, ContactName nvarchar, ContactTitle nvarchar, Address nvarchar, City nvarchar, Region nvarchar, PostalCode nvarchar, Country nvarchar, Phone nvarchar, Fax nvarchar, HomePage ntext\\n table: dbo.Orders, columns: OrderID int, CustomerID nchar, EmployeeID int, OrderDate datetime, RequiredDate datetime, ShippedDate datetime, ShipVia int, Freight money, ShipName nvarchar, ShipAddress nvarchar, ShipCity nvarchar, ShipRegion nvarchar, ShipPostalCode nvarchar, ShipCountry nvarchar\\n table: dbo.Products, columns: ProductID int, ProductName nvarchar, SupplierID int, CategoryID int, QuantityPerUnit nvarchar, UnitPrice money, UnitsInStock smallint, UnitsOnOrder smallint, ReorderLevel smallint, Discontinued bit\\n table: dbo.OrderDetails, columns: OrderID int, ProductID int, UnitPrice money, Quantity smallint, Discount real\\n table: dbo.CustomerCustomerDemo, columns: CustomerID nchar, CustomerTypeID nchar\\n table: dbo.CustomerDemographics, columns: CustomerTypeID nchar, CustomerDesc ntext\\n table: dbo.Region, columns: RegionID int, RegionDescription nchar\\n table: dbo.Territories, columns: TerritoryID nvarchar, TerritoryDescription nchar, RegionID int\\n table: dbo.EmployeeTerritories, columns: EmployeeID int, TerritoryID nvarchar\\n        \\n    You are an agent designed to interact with a SQL database with schema detail in <<data_sources>>.\\n    Given an input question, create a syntactically correct sqlserver query to run, then look at the results of the query and return the answer.\\n    You can order the results by a relevant column to return the most interesting examples in the database.\\n    Never query for all the columns from a specific table, only ask for a the few relevant columns given the question.\\n    You MUST double check your query before executing it. If you get an error while executing a query, rewrite the query and try again.\\n    DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\\n    Remember to format SQL query as in ```sql\\n SQL QUERY HERE ``` in your response.\\n    \\n    \\n        \\n        '}, {'role': 'user', 'content': 'Question: Which Shipper can ship the product?'}]\n",
      "Output : \n",
      "Empty DataFrame\n",
      "Columns: [ShipperID, CompanyName]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "chatHistory =  [{\"role\": \"system\", \"content\": sysMessage}]\n",
    "question = \"Which Shipper can ship the product?\"\n",
    "newInput= f\"Question: {question}\"\n",
    "getAnswer(newInput, chatHistory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Code : \n",
      "SELECT c.CategoryName, s.Country AS SupplierContinent, SUM(p.UnitsInStock) AS TotalUnitsInStock\n",
      "FROM Products p\n",
      "JOIN Categories c ON p.CategoryID = c.CategoryID\n",
      "JOIN Suppliers s ON p.SupplierID = s.SupplierID\n",
      "GROUP BY c.CategoryName, s.Country\n",
      "ORDER BY c.CategoryName, s.Country\n",
      "\n",
      "Non-SQL Value : \n",
      "To answer the question, we need to join the \"Products\" table with the \"Categories\" table and the \"Suppliers\" table. We can then group the results by category and supplier continent and calculate the sum of units in stock for each group.\n",
      "\n",
      "Here is the SQL query to retrieve the number of units in stock by category and supplier continent:\n",
      "Non-SQL Value : \n",
      "\n",
      "\n",
      "This query will return the category name, supplier continent, and the total number of units in stock for each combination of category and supplier continent. The results will be ordered by category name and supplier continent.\n",
      "\n",
      "Please note that the \"Country\" column in the \"Suppliers\" table is assumed to represent the supplier's continent. If the column name or the assumption is incorrect, please adjust the query accordingly.\n",
      "Prompt & Chat History : \n",
      "[{'role': 'system', 'content': '\\n        <<data_sources>>\\n        table: dbo.sysdiagrams, columns: name nvarchar, principal_id int, diagram_id int, version int, definition varbinary\\n table: dbo.Employees, columns: EmployeeID int, LastName nvarchar, FirstName nvarchar, Title nvarchar, TitleOfCourtesy nvarchar, BirthDate datetime, HireDate datetime, Address nvarchar, City nvarchar, Region nvarchar, PostalCode nvarchar, Country nvarchar, HomePhone nvarchar, Extension nvarchar, Photo image, Notes ntext, ReportsTo int, PhotoPath nvarchar\\n table: dbo.Categories, columns: CategoryID int, CategoryName nvarchar, Description ntext, Picture image\\n table: dbo.Customers, columns: CustomerID nchar, CompanyName nvarchar, ContactName nvarchar, ContactTitle nvarchar, Address nvarchar, City nvarchar, Region nvarchar, PostalCode nvarchar, Country nvarchar, Phone nvarchar, Fax nvarchar\\n table: dbo.Shippers, columns: ShipperID int, CompanyName nvarchar, Phone nvarchar\\n table: dbo.Suppliers, columns: SupplierID int, CompanyName nvarchar, ContactName nvarchar, ContactTitle nvarchar, Address nvarchar, City nvarchar, Region nvarchar, PostalCode nvarchar, Country nvarchar, Phone nvarchar, Fax nvarchar, HomePage ntext\\n table: dbo.Orders, columns: OrderID int, CustomerID nchar, EmployeeID int, OrderDate datetime, RequiredDate datetime, ShippedDate datetime, ShipVia int, Freight money, ShipName nvarchar, ShipAddress nvarchar, ShipCity nvarchar, ShipRegion nvarchar, ShipPostalCode nvarchar, ShipCountry nvarchar\\n table: dbo.Products, columns: ProductID int, ProductName nvarchar, SupplierID int, CategoryID int, QuantityPerUnit nvarchar, UnitPrice money, UnitsInStock smallint, UnitsOnOrder smallint, ReorderLevel smallint, Discontinued bit\\n table: dbo.OrderDetails, columns: OrderID int, ProductID int, UnitPrice money, Quantity smallint, Discount real\\n table: dbo.CustomerCustomerDemo, columns: CustomerID nchar, CustomerTypeID nchar\\n table: dbo.CustomerDemographics, columns: CustomerTypeID nchar, CustomerDesc ntext\\n table: dbo.Region, columns: RegionID int, RegionDescription nchar\\n table: dbo.Territories, columns: TerritoryID nvarchar, TerritoryDescription nchar, RegionID int\\n table: dbo.EmployeeTerritories, columns: EmployeeID int, TerritoryID nvarchar\\n        \\n    You are an agent designed to interact with a SQL database with schema detail in <<data_sources>>.\\n    Given an input question, create a syntactically correct sqlserver query to run, then look at the results of the query and return the answer.\\n    You can order the results by a relevant column to return the most interesting examples in the database.\\n    Never query for all the columns from a specific table, only ask for a the few relevant columns given the question.\\n    You MUST double check your query before executing it. If you get an error while executing a query, rewrite the query and try again.\\n    DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\\n    Remember to format SQL query as in ```sql\\n SQL QUERY HERE ``` in your response.\\n    \\n    \\n        \\n        '}, {'role': 'user', 'content': 'Question: Number of units in stock by category and supplier continent'}]\n",
      "Output : \n",
      "      CategoryName SupplierContinent  TotalUnitsInStock\n",
      "0        Beverages         Australia                 15\n",
      "1        Beverages            Brazil                 20\n",
      "2        Beverages           Finland                 57\n",
      "3        Beverages            France                 86\n",
      "4        Beverages           Germany                125\n",
      "5        Beverages         Singapore                 17\n",
      "6        Beverages                UK                 56\n",
      "7        Beverages               USA                183\n",
      "8       Condiments         Australia                 24\n",
      "9       Condiments            Canada                113\n",
      "10      Condiments           Germany                 32\n",
      "11      Condiments             Japan                 39\n",
      "12      Condiments         Singapore                 27\n",
      "13      Condiments                UK                 13\n",
      "14      Condiments               USA                259\n",
      "15     Confections         Australia                 29\n",
      "16     Confections            Canada                 17\n",
      "17     Confections           Finland                 75\n",
      "18     Confections           Germany                140\n",
      "19     Confections       Netherlands                 51\n",
      "20     Confections                UK                 74\n",
      "21  Dairy Products            France                 98\n",
      "22  Dairy Products             Italy                 23\n",
      "23  Dairy Products            Norway                164\n",
      "24  Dairy Products             Spain                108\n",
      "25  Grains/Cereals         Australia                 38\n",
      "26  Grains/Cereals           Germany                 22\n",
      "27  Grains/Cereals             Italy                 57\n",
      "28  Grains/Cereals         Singapore                 26\n",
      "29  Grains/Cereals            Sweden                165\n",
      "30    Meat/Poultry         Australia                  0\n",
      "31    Meat/Poultry            Canada                136\n",
      "32    Meat/Poultry           Germany                  0\n",
      "33    Meat/Poultry             Japan                 29\n",
      "34         Produce         Australia                 20\n",
      "35         Produce           Germany                 26\n",
      "36         Produce             Japan                 39\n",
      "37         Produce               USA                 15\n",
      "38         Seafood         Australia                 42\n",
      "39         Seafood           Denmark                100\n",
      "40         Seafood            France                 62\n",
      "41         Seafood           Germany                 10\n",
      "42         Seafood             Japan                 55\n",
      "43         Seafood            Sweden                224\n",
      "44         Seafood               USA                208\n"
     ]
    }
   ],
   "source": [
    "chatHistory =  [{\"role\": \"system\", \"content\": sysMessage}]\n",
    "question = \"Number of units in stock by category and supplier continent\"\n",
    "newInput= f\"Question: {question}\"\n",
    "getAnswer(newInput, chatHistory)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This time test it as Data Analyst Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "daSysDefaultMessage = \"\"\"\n",
    "        You are a smart AI assistant to help answer business questions based on analyzing data. \n",
    "        You can plan solving the question with one more multiple thought step. At each thought step, you can write python code to analyze data to assist you. Observe what you get at each step to plan for the next step.\n",
    "        You are given following utilities to help you retrieve data and commmunicate your result to end user.\n",
    "        1. executeQuery(sql_query: str): A Python function can query data from the <<data_sources>> given a query which you need to create. The query has to be syntactically correct for {sql_engine} and only use tables and columns under <<data_sources>>. The executeQuery function returns a Python pandas dataframe contain the results of the query.\n",
    "        2. Use plotly library for data visualization. \n",
    "        3. Use observe(label: str, data: any) utility function to observe data under the label for your evaluation. Use observe() function instead of print() as this is executed in streamlit environment. Due to system limitation, you will only see the first 10 rows of the dataset.\n",
    "        4. To communicate with user, use show() function on data, text and plotly figure. show() is a utility function that can render different types of data to end user. Remember, you don't see data with show(), only user does. You see data with observe()\n",
    "            - If you want to show  user a plotly visualization, then use ```show(fig)`` \n",
    "            - If you want to show user data which is a text or a pandas dataframe or a list, use ```show(data)```\n",
    "            - Never use print(). User don't see anything with print()\n",
    "        5. Lastly, don't forget to deal with data quality problem. You should apply data imputation technique to deal with missing data or NAN data.\n",
    "        6. Always follow the flow of Thought: , Observation:, Action: and Answer: as in template below strictly. \n",
    "\n",
    "        \"\"\"\n",
    "daFewShotExamples =\"\"\"\n",
    "        <<Template>>\n",
    "        Question: User Question\n",
    "        Thought 1: Your thought here.\n",
    "        Action: \n",
    "        ```python\n",
    "        #Import neccessary libraries here\n",
    "        import numpy as np\n",
    "        #Query some data \n",
    "        sql_query = \"SOME SQL QUERY\"\n",
    "        step1_df = executeQuery(sql_query)\n",
    "        # Replace NAN with 0. Always have this step\n",
    "        step1_df['Some_Column'] = step1_df['Some_Column'].replace(np.nan,0)\n",
    "        #observe query result\n",
    "        observe(\"some_label\", step1_df) #Always use observe() instead of print\n",
    "        ```\n",
    "        Observation: \n",
    "        step1_df is displayed here\n",
    "        Thought 2: Your thought here\n",
    "        Action:  \n",
    "        ```python\n",
    "        import plotly.express as px \n",
    "        #from step1_df, perform some data analysis action to produce step2_df\n",
    "        #To see the data for yourself the only way is to use observe()\n",
    "        observe(\"some_label\", step2_df) #Always use observe() \n",
    "        #Decide to show it to user.\n",
    "        fig=px.line(step2_df)\n",
    "        #visualize fig object to user.  \n",
    "        show(fig)\n",
    "        #you can also directly display tabular or text data to end user.\n",
    "        show(step2_df)\n",
    "        ```\n",
    "        Observation: \n",
    "        step2_df is displayed here\n",
    "        Answer: Your final answer and comment for the question. Also use Python for computation, never compute result youself.\n",
    "        <</Template>>\n",
    "\n",
    "        \"\"\"\n",
    "sqlEngine = 'sqlserver'\n",
    "daExtractPattern=[(\"Thought:\",r'(Thought \\d+):\\s*(.*?)(?:\\n|$)'), ('Action:',r\"```python\\n(.*?)```\"),(\"Answer:\",r'([Aa]nswer:) (.*)')]\n",
    "\n",
    "# get Table Schema\n",
    "tableSchema  = getTableSchema()\n",
    "daSysMessage = f\"\"\"\n",
    "        <<data_sources>>\n",
    "        {tableSchema}\n",
    "        {daSysDefaultMessage.format(sql_engine=sqlEngine)}\n",
    "        {daFewShotExamples}\n",
    "        \"\"\"\n",
    "tokenLength=1000\n",
    "temperature=0\n",
    "embeddingModelType = \"openai\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDaAnswer(extractPattern, newInput, chatHistory):\n",
    "\n",
    "    from plotly.graph_objects import Figure\n",
    "    import numpy as np\n",
    "    import plotly.express as px\n",
    "    import plotly.graph_objs as go\n",
    "    import pandas as pd\n",
    "\n",
    "    def show(data):\n",
    "        #if type(data) is Figure:\n",
    "        #    plotly_chart(data)\n",
    "        #else:\n",
    "        print(data)\n",
    "        if type(data) is not Figure:\n",
    "            print('observation: this was shown to user',data)\n",
    "\n",
    "    def observe(name, data):\n",
    "        try:\n",
    "            data = data[:10] # limit the print out observation to 15 rows\n",
    "        except:\n",
    "            pass\n",
    "        print(f'observation:{name}', data)\n",
    "    \n",
    "    def executeQuery(query, limit=10000):  \n",
    "        engine = create_engine(sqlConnectionString)\n",
    "        result = pd.read_sql_query(query, engine)\n",
    "        result = result.infer_objects()\n",
    "        for col in result.columns:  \n",
    "            if 'date' in col.lower():  \n",
    "                result[col] = pd.to_datetime(result[col], errors=\"ignore\")  \n",
    "\n",
    "        if limit is not None:  \n",
    "            result = result.head(limit)  # limit to save memory  \n",
    "        # session.close()  \n",
    "        return result\n",
    "        \n",
    "    maxSteps=15\n",
    "    count=1\n",
    "    finish = False\n",
    "    while not finish:\n",
    "        llmOutput,nextSteps = getNextSteps(extractPattern, embeddingModelType, newInput, chatHistory, stop=[\"Observation:\", f\"Thought {count+1}\"])\n",
    "        if llmOutput=='OPENAI_ERROR':\n",
    "            print(\"Error Calling Azure Open AI, probably due to max service limit, please try again\")\n",
    "            break\n",
    "        elif llmOutput=='WRONG_OUTPUT_FORMAT': #just have open AI try again till the right output comes\n",
    "            count +=1\n",
    "            continue\n",
    "\n",
    "        newInput += f\"\\n{llmOutput}\"\n",
    "        for key, value in nextSteps.items():\n",
    "            newInput += f\"\\n{value}\"\n",
    "            \n",
    "            if \"ACTION\" in key.upper():\n",
    "                print(\"SQL Code : \")\n",
    "                print(key)\n",
    "                print(value)\n",
    "                observations =[]\n",
    "                serialized_obs=[]\n",
    "                try:\n",
    "                    exec(value, locals())\n",
    "                    if \"observation:\" in key:\n",
    "                        observations.append((key.split(\":\")[1],observation))\n",
    "                        if type(observation) is pd:\n",
    "                            serialized_obs.append((key.split(\":\")[1],observation.to_string()))\n",
    "                        elif type(observation) is not Figure:\n",
    "                            serialized_obs.append({key.split(\":\")[1]:str(observation)})\n",
    "                except Exception as e:\n",
    "                    observations.append((\"Error:\",str(e)))\n",
    "                    serialized_obs.append({\"\\nEncounter following error, can you try again?\\n:\":str(e)+\"\\nAction:\"})\n",
    "                \n",
    "                for observation in observations:\n",
    "                    print(observation[0])\n",
    "                    print(observation[1])\n",
    "                obs = f\"\\nObservation on the first 10 rows of data: {serialized_obs}\"\n",
    "                newInput += obs\n",
    "            else:\n",
    "                print(key)\n",
    "                print(value)\n",
    "            if \"Answer\" in key:\n",
    "                print(\"Answer is given, finish\")\n",
    "                finish= True\n",
    "        print(\"Prompt & Chat History : \")\n",
    "        print(chatHistory)\n",
    "\n",
    "        count +=1\n",
    "        if count>= maxSteps:\n",
    "            print(\"Cannot handle the question, please change the question and try again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought 1\n",
      "To display products by category, I need to retrieve data from the \"Products\" and \"Categories\" tables. I can join these two tables on the \"CategoryID\" column to get the desired result.\n",
      "SQL Code : \n",
      "Action:\n",
      "# Query the data from the Products and Categories tables\n",
      "sql_query = \"SELECT p.ProductName, c.CategoryName FROM dbo.Products p JOIN dbo.Categories c ON p.CategoryID = c.CategoryID\"\n",
      "product_category_df = executeQuery(sql_query)\n",
      "\n",
      "# Replace NaN values with empty string\n",
      "product_category_df = product_category_df.fillna('')\n",
      "\n",
      "# Observe the query result\n",
      "observe(\"Product Category Data\", product_category_df)\n",
      "\n",
      "observation:Product Category Data                        ProductName  CategoryName\n",
      "0                             Chai     Beverages\n",
      "1                            Chang     Beverages\n",
      "2                    Aniseed Syrup    Condiments\n",
      "3     Chef Anton's Cajun Seasoning    Condiments\n",
      "4           Chef Anton's Gumbo Mix    Condiments\n",
      "5     Grandma's Boysenberry Spread    Condiments\n",
      "6  Uncle Bob's Organic Dried Pears       Produce\n",
      "7       Northwoods Cranberry Sauce    Condiments\n",
      "8                  Mishi Kobe Niku  Meat/Poultry\n",
      "9                            Ikura       Seafood\n",
      "Prompt & Chat History : \n",
      "[{'role': 'system', 'content': '\\n        <<data_sources>>\\n        table: dbo.sysdiagrams, columns: name nvarchar, principal_id int, diagram_id int, version int, definition varbinary\\n table: dbo.Employees, columns: EmployeeID int, LastName nvarchar, FirstName nvarchar, Title nvarchar, TitleOfCourtesy nvarchar, BirthDate datetime, HireDate datetime, Address nvarchar, City nvarchar, Region nvarchar, PostalCode nvarchar, Country nvarchar, HomePhone nvarchar, Extension nvarchar, Photo image, Notes ntext, ReportsTo int, PhotoPath nvarchar\\n table: dbo.Categories, columns: CategoryID int, CategoryName nvarchar, Description ntext, Picture image\\n table: dbo.Customers, columns: CustomerID nchar, CompanyName nvarchar, ContactName nvarchar, ContactTitle nvarchar, Address nvarchar, City nvarchar, Region nvarchar, PostalCode nvarchar, Country nvarchar, Phone nvarchar, Fax nvarchar\\n table: dbo.Shippers, columns: ShipperID int, CompanyName nvarchar, Phone nvarchar\\n table: dbo.Suppliers, columns: SupplierID int, CompanyName nvarchar, ContactName nvarchar, ContactTitle nvarchar, Address nvarchar, City nvarchar, Region nvarchar, PostalCode nvarchar, Country nvarchar, Phone nvarchar, Fax nvarchar, HomePage ntext\\n table: dbo.Orders, columns: OrderID int, CustomerID nchar, EmployeeID int, OrderDate datetime, RequiredDate datetime, ShippedDate datetime, ShipVia int, Freight money, ShipName nvarchar, ShipAddress nvarchar, ShipCity nvarchar, ShipRegion nvarchar, ShipPostalCode nvarchar, ShipCountry nvarchar\\n table: dbo.Products, columns: ProductID int, ProductName nvarchar, SupplierID int, CategoryID int, QuantityPerUnit nvarchar, UnitPrice money, UnitsInStock smallint, UnitsOnOrder smallint, ReorderLevel smallint, Discontinued bit\\n table: dbo.OrderDetails, columns: OrderID int, ProductID int, UnitPrice money, Quantity smallint, Discount real\\n table: dbo.CustomerCustomerDemo, columns: CustomerID nchar, CustomerTypeID nchar\\n table: dbo.CustomerDemographics, columns: CustomerTypeID nchar, CustomerDesc ntext\\n table: dbo.Region, columns: RegionID int, RegionDescription nchar\\n table: dbo.Territories, columns: TerritoryID nvarchar, TerritoryDescription nchar, RegionID int\\n table: dbo.EmployeeTerritories, columns: EmployeeID int, TerritoryID nvarchar\\n        \\n        You are a smart AI assistant to help answer business questions based on analyzing data. \\n        You can plan solving the question with one more multiple thought step. At each thought step, you can write python code to analyze data to assist you. Observe what you get at each step to plan for the next step.\\n        You are given following utilities to help you retrieve data and commmunicate your result to end user.\\n        1. executeQuery(sql_query: str): A Python function can query data from the <<data_sources>> given a query which you need to create. The query has to be syntactically correct for sqlserver and only use tables and columns under <<data_sources>>. The executeQuery function returns a Python pandas dataframe contain the results of the query.\\n        2. Use plotly library for data visualization. \\n        3. Use observe(label: str, data: any) utility function to observe data under the label for your evaluation. Use observe() function instead of print() as this is executed in streamlit environment. Due to system limitation, you will only see the first 10 rows of the dataset.\\n        4. To communicate with user, use show() function on data, text and plotly figure. show() is a utility function that can render different types of data to end user. Remember, you don\\'t see data with show(), only user does. You see data with observe()\\n            - If you want to show  user a plotly visualization, then use ```show(fig)`` \\n            - If you want to show user data which is a text or a pandas dataframe or a list, use ```show(data)```\\n            - Never use print(). User don\\'t see anything with print()\\n        5. Lastly, don\\'t forget to deal with data quality problem. You should apply data imputation technique to deal with missing data or NAN data.\\n        6. Always follow the flow of Thought: , Observation:, Action: and Answer: as in template below strictly. \\n\\n        \\n        \\n        <<Template>>\\n        Question: User Question\\n        Thought 1: Your thought here.\\n        Action: \\n        ```python\\n        #Import neccessary libraries here\\n        import numpy as np\\n        #Query some data \\n        sql_query = \"SOME SQL QUERY\"\\n        step1_df = executeQuery(sql_query)\\n        # Replace NAN with 0. Always have this step\\n        step1_df[\\'Some_Column\\'] = step1_df[\\'Some_Column\\'].replace(np.nan,0)\\n        #observe query result\\n        observe(\"some_label\", step1_df) #Always use observe() instead of print\\n        ```\\n        Observation: \\n        step1_df is displayed here\\n        Thought 2: Your thought here\\n        Action:  \\n        ```python\\n        import plotly.express as px \\n        #from step1_df, perform some data analysis action to produce step2_df\\n        #To see the data for yourself the only way is to use observe()\\n        observe(\"some_label\", step2_df) #Always use observe() \\n        #Decide to show it to user.\\n        fig=px.line(step2_df)\\n        #visualize fig object to user.  \\n        show(fig)\\n        #you can also directly display tabular or text data to end user.\\n        show(step2_df)\\n        ```\\n        Observation: \\n        step2_df is displayed here\\n        Answer: Your final answer and comment for the question. Also use Python for computation, never compute result youself.\\n        <</Template>>\\n\\n        \\n        '}, {'role': 'user', 'content': 'Question: Display Product by Category'}]\n",
      "Answer:\n",
      "The table above displays the products by category. Each row represents a product and its corresponding category.\n",
      "Answer is given, finish\n",
      "Prompt & Chat History : \n",
      "[{'role': 'system', 'content': '\\n        <<data_sources>>\\n        table: dbo.sysdiagrams, columns: name nvarchar, principal_id int, diagram_id int, version int, definition varbinary\\n table: dbo.Employees, columns: EmployeeID int, LastName nvarchar, FirstName nvarchar, Title nvarchar, TitleOfCourtesy nvarchar, BirthDate datetime, HireDate datetime, Address nvarchar, City nvarchar, Region nvarchar, PostalCode nvarchar, Country nvarchar, HomePhone nvarchar, Extension nvarchar, Photo image, Notes ntext, ReportsTo int, PhotoPath nvarchar\\n table: dbo.Categories, columns: CategoryID int, CategoryName nvarchar, Description ntext, Picture image\\n table: dbo.Customers, columns: CustomerID nchar, CompanyName nvarchar, ContactName nvarchar, ContactTitle nvarchar, Address nvarchar, City nvarchar, Region nvarchar, PostalCode nvarchar, Country nvarchar, Phone nvarchar, Fax nvarchar\\n table: dbo.Shippers, columns: ShipperID int, CompanyName nvarchar, Phone nvarchar\\n table: dbo.Suppliers, columns: SupplierID int, CompanyName nvarchar, ContactName nvarchar, ContactTitle nvarchar, Address nvarchar, City nvarchar, Region nvarchar, PostalCode nvarchar, Country nvarchar, Phone nvarchar, Fax nvarchar, HomePage ntext\\n table: dbo.Orders, columns: OrderID int, CustomerID nchar, EmployeeID int, OrderDate datetime, RequiredDate datetime, ShippedDate datetime, ShipVia int, Freight money, ShipName nvarchar, ShipAddress nvarchar, ShipCity nvarchar, ShipRegion nvarchar, ShipPostalCode nvarchar, ShipCountry nvarchar\\n table: dbo.Products, columns: ProductID int, ProductName nvarchar, SupplierID int, CategoryID int, QuantityPerUnit nvarchar, UnitPrice money, UnitsInStock smallint, UnitsOnOrder smallint, ReorderLevel smallint, Discontinued bit\\n table: dbo.OrderDetails, columns: OrderID int, ProductID int, UnitPrice money, Quantity smallint, Discount real\\n table: dbo.CustomerCustomerDemo, columns: CustomerID nchar, CustomerTypeID nchar\\n table: dbo.CustomerDemographics, columns: CustomerTypeID nchar, CustomerDesc ntext\\n table: dbo.Region, columns: RegionID int, RegionDescription nchar\\n table: dbo.Territories, columns: TerritoryID nvarchar, TerritoryDescription nchar, RegionID int\\n table: dbo.EmployeeTerritories, columns: EmployeeID int, TerritoryID nvarchar\\n        \\n        You are a smart AI assistant to help answer business questions based on analyzing data. \\n        You can plan solving the question with one more multiple thought step. At each thought step, you can write python code to analyze data to assist you. Observe what you get at each step to plan for the next step.\\n        You are given following utilities to help you retrieve data and commmunicate your result to end user.\\n        1. executeQuery(sql_query: str): A Python function can query data from the <<data_sources>> given a query which you need to create. The query has to be syntactically correct for sqlserver and only use tables and columns under <<data_sources>>. The executeQuery function returns a Python pandas dataframe contain the results of the query.\\n        2. Use plotly library for data visualization. \\n        3. Use observe(label: str, data: any) utility function to observe data under the label for your evaluation. Use observe() function instead of print() as this is executed in streamlit environment. Due to system limitation, you will only see the first 10 rows of the dataset.\\n        4. To communicate with user, use show() function on data, text and plotly figure. show() is a utility function that can render different types of data to end user. Remember, you don\\'t see data with show(), only user does. You see data with observe()\\n            - If you want to show  user a plotly visualization, then use ```show(fig)`` \\n            - If you want to show user data which is a text or a pandas dataframe or a list, use ```show(data)```\\n            - Never use print(). User don\\'t see anything with print()\\n        5. Lastly, don\\'t forget to deal with data quality problem. You should apply data imputation technique to deal with missing data or NAN data.\\n        6. Always follow the flow of Thought: , Observation:, Action: and Answer: as in template below strictly. \\n\\n        \\n        \\n        <<Template>>\\n        Question: User Question\\n        Thought 1: Your thought here.\\n        Action: \\n        ```python\\n        #Import neccessary libraries here\\n        import numpy as np\\n        #Query some data \\n        sql_query = \"SOME SQL QUERY\"\\n        step1_df = executeQuery(sql_query)\\n        # Replace NAN with 0. Always have this step\\n        step1_df[\\'Some_Column\\'] = step1_df[\\'Some_Column\\'].replace(np.nan,0)\\n        #observe query result\\n        observe(\"some_label\", step1_df) #Always use observe() instead of print\\n        ```\\n        Observation: \\n        step1_df is displayed here\\n        Thought 2: Your thought here\\n        Action:  \\n        ```python\\n        import plotly.express as px \\n        #from step1_df, perform some data analysis action to produce step2_df\\n        #To see the data for yourself the only way is to use observe()\\n        observe(\"some_label\", step2_df) #Always use observe() \\n        #Decide to show it to user.\\n        fig=px.line(step2_df)\\n        #visualize fig object to user.  \\n        show(fig)\\n        #you can also directly display tabular or text data to end user.\\n        show(step2_df)\\n        ```\\n        Observation: \\n        step2_df is displayed here\\n        Answer: Your final answer and comment for the question. Also use Python for computation, never compute result youself.\\n        <</Template>>\\n\\n        \\n        '}, {'role': 'user', 'content': 'Question: Display Product by Category\\nQuestion: Display Product by Category\\nThought 1: To display products by category, I need to retrieve data from the \"Products\" and \"Categories\" tables. I can join these two tables on the \"CategoryID\" column to get the desired result.\\n\\nAction: \\n```python\\n# Query the data from the Products and Categories tables\\nsql_query = \"SELECT p.ProductName, c.CategoryName FROM dbo.Products p JOIN dbo.Categories c ON p.CategoryID = c.CategoryID\"\\nproduct_category_df = executeQuery(sql_query)\\n\\n# Replace NaN values with empty string\\nproduct_category_df = product_category_df.fillna(\\'\\')\\n\\n# Observe the query result\\nobserve(\"Product Category Data\", product_category_df)\\n```\\n\\n\\nTo display products by category, I need to retrieve data from the \"Products\" and \"Categories\" tables. I can join these two tables on the \"CategoryID\" column to get the desired result.\\n# Query the data from the Products and Categories tables\\nsql_query = \"SELECT p.ProductName, c.CategoryName FROM dbo.Products p JOIN dbo.Categories c ON p.CategoryID = c.CategoryID\"\\nproduct_category_df = executeQuery(sql_query)\\n\\n# Replace NaN values with empty string\\nproduct_category_df = product_category_df.fillna(\\'\\')\\n\\n# Observe the query result\\nobserve(\"Product Category Data\", product_category_df)\\n\\nObservation on the first 10 rows of data: []'}]\n"
     ]
    }
   ],
   "source": [
    "daChatHistory =  [{\"role\": \"system\", \"content\": daSysMessage}]\n",
    "#daQuestion = \"Number of units in stock by category and supplier continent\"\n",
    "daQuestion = \"Display Product by Category\"\n",
    "daNewInput= f\"Question: {daQuestion}\"\n",
    "getDaAnswer(daExtractPattern, daNewInput, daChatHistory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
