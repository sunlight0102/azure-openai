{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatbots with History\n",
    "ChatGPT took the world by storm by exposing a powerful language model with a new interface - chat. There are several components that go into building a chatbot.\n",
    "\n",
    "- The model - you can construct a chatbot from a normal language model or a Chat Model. The important thing to remember is that even if you are using a Chat Model, the API itself is stateless, meaning it won't remember previous interactions - you have to pass them in.\n",
    "- PromptTemplate - this will guide how your chatbot acts. Are they sassy? Helpful? These can be used to give your chatbot some character.\n",
    "- Memory - as mentioned above, the models themselves are stateless. Memory brings some concept of state to the table, allowing it remember previous interactions\n",
    "\n",
    "Chatbots are often very powerful and more differentiated when combined with other sources of data. The same techniques that underpin \"Question Answering Over Docs\" can also be used here to give your chatbot access to that data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "import json  \n",
    "import openai\n",
    "from Utilities.envVars import *\n",
    "\n",
    "# Set Search Service endpoint, index name, and API key from environment variables\n",
    "indexName = SearchIndex\n",
    "\n",
    "# Set OpenAI API key and endpoint\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = OpenAiVersion\n",
    "openai_api_key = OpenAiKey\n",
    "assert openai_api_key, \"ERROR: Azure OpenAI Key is missing\"\n",
    "openai.api_key = openai_api_key\n",
    "openAiEndPoint = f\"https://{OpenAiService}.openai.azure.com\"\n",
    "assert openAiEndPoint, \"ERROR: Azure OpenAI Endpoint is missing\"\n",
    "assert \"openai.azure.com\" in openAiEndPoint.lower(), \"ERROR: Azure OpenAI Endpoint should be in the form: \\n\\n\\t<your unique endpoint identifier>.openai.azure.com\"\n",
    "openai.api_base = openAiEndPoint\n",
    "davincimodel = OpenAiDavinci\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's chat on same index document we created in previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.chat_models import AzureChatOpenAI, ChatOpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from IPython.display import display, HTML\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from Utilities.cogSearchRetriever import CognitiveSearchRetriever\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "embeddingModelType = \"azureopenai\"\n",
    "temperature = 0.3\n",
    "tokenLength = 1000\n",
    "\n",
    "if (embeddingModelType == 'azureopenai'):\n",
    "        baseUrl = f\"https://{OpenAiService}.openai.azure.com\"\n",
    "        openai.api_type = \"azure\"\n",
    "        openai.api_key = OpenAiKey\n",
    "        openai.api_version = OpenAiVersion\n",
    "        openai.api_base = f\"https://{OpenAiService}.openai.azure.com\"\n",
    "\n",
    "        llm = AzureChatOpenAI(\n",
    "                    openai_api_base=baseUrl,\n",
    "                    openai_api_version=OpenAiVersion,\n",
    "                    deployment_name=OpenAiChat,\n",
    "                    temperature=temperature,\n",
    "                    openai_api_key=OpenAiKey,\n",
    "                    openai_api_type=\"azure\",\n",
    "                    max_tokens=tokenLength)\n",
    "        embeddings = OpenAIEmbeddings(model=OpenAiEmbedding, chunk_size=1, openai_api_key=OpenAiKey)\n",
    "        \n",
    "elif embeddingModelType == \"openai\":\n",
    "        openai.api_type = \"open_ai\"\n",
    "        openai.api_base = \"https://api.openai.com/v1\"\n",
    "        openai.api_version = '2020-11-07' \n",
    "        openai.api_key = OpenAiApiKey\n",
    "        llm = ChatOpenAI(temperature=temperature,\n",
    "                openai_api_key=OpenAiApiKey,\n",
    "                max_tokens=tokenLength)\n",
    "        embeddings = OpenAIEmbeddings(openai_api_key=OpenAiApiKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can now create a memory object, which is neccessary to track the inputs/outputs and hold a conversation.\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Fabric is a comprehensive set of analytics experiences provided by Microsoft. It is designed to work seamlessly together and offers a range of industry-leading experiences in categories such as Data Engineering, Data Factory, and more. Fabric allows users to perform large-scale data transformation, democratize data through a lakehouse, and connect to various data sources. It also provides a hierarchical organizational structure called OneLake, which simplifies data management and sharing. Additionally, Fabric includes a contextual Help pane to assist users in finding answers and learning about its features.\n"
     ]
    }
   ],
   "source": [
    "topK = 3\n",
    "\n",
    "# We can now create a retriever object, which is neccessary to retrieve documents from the index.\n",
    "retriever = CognitiveSearchRetriever(content_key=\"content\",\n",
    "                                                  service_name=SearchService,\n",
    "                                                  api_key=SearchKey,\n",
    "                                                  index_name=indexName,\n",
    "                                                  topK=topK)\n",
    "\n",
    "## Use the ConversationalRetrievalChain to combine the LLM, retriever, and memory into a single object.\n",
    "qa = ConversationalRetrievalChain.from_llm(llm, retriever, memory=memory)\n",
    "query = \"What is Microsoft Fabric\"\n",
    "answer = qa({\"question\": query})\n",
    "outputAnswer = answer['answer']\n",
    "print(outputAnswer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, Microsoft Fabric supports real-time analytics use-cases. It brings together components from Power BI, Azure Synapse, and Azure Data Explorer to provide real-time analytics capabilities. With Microsoft Fabric, you can perform real-time analytics on your data using the integrated experiences such as Data Engineering, Data Science, and Real-Time Analytics.\n"
     ]
    }
   ],
   "source": [
    "query = \"Does it support real-time analytics use-cases?\"\n",
    "answer = qa({\"question\": query})\n",
    "outputAnswer = answer['answer']\n",
    "print(outputAnswer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Fabric is a comprehensive set of analytics experiences provided by Microsoft. It is designed to work seamlessly together, offering a range of industry-leading experiences in data engineering, data factory, and more. Fabric allows users to focus on their tasks and personas without needing to understand or manage the underlying infrastructure. It provides a simplified and integrated platform for data transformation, analytics, and machine learning. Users can create workspaces, access data sources, perform large-scale data processing, and leverage various tools and features within the Fabric ecosystem.\n"
     ]
    }
   ],
   "source": [
    "# In the above example, we used a Memory object to track chat history. We can also just pass it in explicitly. \n",
    "# In order to do this, we need to initialize a chain without any memory object.\n",
    "chat_history = []\n",
    "\n",
    "qaNoMemory = ConversationalRetrievalChain.from_llm(llm, retriever)\n",
    "query = \"What is Microsoft Fabric\"\n",
    "answer = qaNoMemory({\"question\": query, \"chat_history\": chat_history})\n",
    "outputAnswer = answer['answer']\n",
    "print(outputAnswer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, Microsoft Fabric supports real-time analytics use-cases. It brings together components from Power BI, Azure Synapse, and Azure Data Explorer to provide a unified environment for real-time analytics. With Fabric, you can perform real-time analytics on your data and leverage features such as the KQL database and KQL Queryset for querying and manipulating data in real-time.\n"
     ]
    }
   ],
   "source": [
    "chat_history = [(query, answer[\"answer\"])]\n",
    "query = \"Does it support real-time analytics use-cases?\"\n",
    "answer = qaNoMemory({\"question\": query, \"chat_history\": chat_history})\n",
    "outputAnswer = answer['answer']\n",
    "print(outputAnswer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can also try using other Chaintype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chainType = \"map_reduce\"\n",
    "questionGenerator = LLMChain(llm=llm, prompt=CONDENSE_QUESTION_PROMPT)\n",
    "docChain = load_qa_chain(llm, chain_type=chainType)\n",
    "\n",
    "mapRChain = ConversationalRetrievalChain(\n",
    "    retriever=retriever,\n",
    "    question_generator=questionGenerator,\n",
    "    combine_docs_chain=docChain,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Fabric is a platform that offers a comprehensive set of analytics experiences designed to manage organizational structure and storage of data. It provides a range of features and functionalities, including data engineering, data integration, and machine learning capabilities. It allows users to perform tasks such as data transformation, sharing, and management, while also managing the underlying infrastructure that supports the analytics experience.\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "\n",
    "query = \"What is Microsoft Fabric\"\n",
    "answer = mapRChain({\"question\": query, \"chat_history\": chat_history})\n",
    "outputAnswer = answer['answer']\n",
    "print(outputAnswer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, Microsoft Fabric supports real-time analytics use-cases.\n"
     ]
    }
   ],
   "source": [
    "chat_history = [(query, answer[\"answer\"])]\n",
    "query = \"Does it support real-time analytics use-cases?\"\n",
    "answer = mapRChain({\"question\": query, \"chat_history\": chat_history})\n",
    "outputAnswer = answer['answer']\n",
    "print(outputAnswer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Does it support real-time analytics use-cases?', 'chat_history': [('What is Microsoft Fabric', 'Microsoft Fabric is a platform that offers a comprehensive set of analytics experiences designed to manage organizational structure and storage of data. It provides a range of features and functionalities, including data engineering, data integration, and machine learning capabilities. It allows users to perform tasks such as data transformation, sharing, and management, while also managing the underlying infrastructure that supports the analytics experience.')], 'answer': 'Yes, Microsoft Fabric supports real-time analytics use-cases.'}\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
