{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarization & Generating Sample QA\n",
    "A common use case is wanting to summarize long documents. This naturally runs into the context window limitations. Unlike in question-answering, you can't just do some semantic search hacks to only select the chunks of text most relevant to the question (because, in this case, there is no particular question - you want to summarize everything). So what do you do then?\n",
    "\n",
    "The most common way around this is to split the documents into chunks and then do summarization in a recursive manner. By this we mean you first summarize each chunk by itself, then you group the summaries into chunks and summarize each chunk of summaries, and continue doing that until only one is left."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "import json  \n",
    "import openai\n",
    "from Utilities.envVars import *\n",
    "\n",
    "# Set Search Service endpoint, index name, and API key from environment variables\n",
    "indexName = SearchIndex\n",
    "\n",
    "# Set OpenAI API key and endpoint\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = OpenAiVersion\n",
    "openai_api_key = OpenAiKey\n",
    "assert openai_api_key, \"ERROR: Azure OpenAI Key is missing\"\n",
    "openai.api_key = openai_api_key\n",
    "openAiEndPoint = f\"https://{OpenAiService}.openai.azure.com\"\n",
    "assert openAiEndPoint, \"ERROR: Azure OpenAI Endpoint is missing\"\n",
    "assert \"openai.azure.com\" in openAiEndPoint.lower(), \"ERROR: Azure OpenAI Endpoint should be in the form: \\n\\n\\t<your unique endpoint identifier>.openai.azure.com\"\n",
    "openai.api_base = openAiEndPoint\n",
    "davincimodel = OpenAiDavinci\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarize the document/PDF (instead of getting that data from Vector store or document reposit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "# Import required libraries\n",
    "from langchain.llms.openai import AzureOpenAI, OpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import (\n",
    "    PDFMinerLoader,\n",
    "    UnstructuredFileLoader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flexibility to change the call to OpenAI or Azure OpenAI\n",
    "embeddingModelType = \"openai\"\n",
    "\n",
    "# Set the file name and the namespace for the index\n",
    "fileName = \"Fabric Get Started.pdf\"\n",
    "fabricGetStartedPath = \"Data/PDF/\" + fileName\n",
    "# Load the PDF with Document Loader available from Langchain\n",
    "loader = PDFMinerLoader(fabricGetStartedPath)\n",
    "rawDocs = loader.load()\n",
    "# Set the source \n",
    "for doc in rawDocs:\n",
    "    doc.metadata['source'] = fabricGetStartedPath\n",
    "\n",
    "textSplitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=0)\n",
    "docs = textSplitter.split_documents(rawDocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents chunks generated from PDF :  58\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of documents chunks generated from PDF : \", len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.llms.openai import AzureOpenAI, OpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from Utilities.cogSearch import performCogSearch\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from IPython.display import display, HTML\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "embeddingModelType = \"azureopenai\"\n",
    "temperature = 0.3\n",
    "tokenLength = 1000\n",
    "\n",
    "if (embeddingModelType == 'azureopenai'):\n",
    "    openai.api_type = \"azure\"\n",
    "    openai.api_key = OpenAiKey\n",
    "    openai.api_version = OpenAiVersion\n",
    "    openai.api_base = f\"https://{OpenAiService}.openai.azure.com\"\n",
    "\n",
    "    llm = AzureOpenAI(deployment_name=OpenAiDavinci,\n",
    "            temperature=temperature,\n",
    "            openai_api_key=OpenAiKey,\n",
    "            max_tokens=tokenLength,\n",
    "            batch_size=10, \n",
    "            max_retries=12)\n",
    "\n",
    "    logging.info(\"LLM Setup done\")\n",
    "    embeddings = OpenAIEmbeddings(model=OpenAiEmbedding, chunk_size=1, openai_api_key=OpenAiKey)\n",
    "elif embeddingModelType == \"openai\":\n",
    "    openai.api_type = \"open_ai\"\n",
    "    openai.api_base = \"https://api.openai.com/v1\"\n",
    "    openai.api_version = '2020-11-07' \n",
    "    openai.api_key = OpenAiApiKey\n",
    "    llm = OpenAI(temperature=temperature,\n",
    "            openai_api_key=OpenAiApiKey,\n",
    "            max_tokens=tokenLength)\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=OpenAiApiKey)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Microsoft Fabric is an all-in-one analytics solution for enterprises that provides data lake, data engineering, data integration, data science, data warehousing, real-time analytics, and Power BI capabilities. It includes features such as Data Engineering, Data Factory, Data Science experiences, OneLake workspaces, shortcuts, end-to-end tutorials, Apache Spark, Dataflow Gen 2, Leo, Mary, Adam, Susan, Rob, and Ash examples, a feature-aware search engine, Help pane, Global Search feature, sorting and filtering features, workspace accounts, settings for personal use, resources and extensions, Azure Analysis Services, and sensitivity labels.\n"
     ]
    }
   ],
   "source": [
    "# Let's use the chaintype of mapreduce to summarize the document\n",
    "chainType = \"map_reduce\"\n",
    "summaryChain = load_summarize_chain(llm, chain_type=chainType, return_intermediate_steps=True)\n",
    "summary = summaryChain({\"input_documents\": docs}, return_only_outputs=True)\n",
    "outputAnswer = summary['output_text']\n",
    "print(outputAnswer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b> \n",
       "\n",
       "Microsoft Fabric is an all-in-one analytics solution for enterprises that covers everything from data movement to data science, Real-Time Analytics, and business intelligence. It offers a comprehensive suite of services, including data lake, data engineering, and data integration, all in one place. The platform is built on a foundation of Software as a Service (SaaS) to simplify analytics needs. The Microsoft Fabric get started documentation provides an overview of the platform, instructions on how to get started, and how-to guides."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  Microsoft Fabric is a prerelease product that brings together components from Power BI, Azure Synapse, and Azure Data Explorer into a single integrated environment. It provides an extensive range of deeply integrated analytics, shared experiences, and a unified data lake. It also allows for centralized administration and governance across all experiences. IT teams can centrally configure core enterprise capabilities and data sensitivity labels are inherited automatically."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  Microsoft Fabric is a comprehensive set of analytics experiences tailored to specific personas and tasks. It includes Data Engineering, Data Factory, and Data Science experiences that enable creators to concentrate on producing their best work without needing to manage or understand the underlying infrastructure. It integrates with Azure Machine Learning to provide experiment tracking."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  Microsoft Fabric provides industry leading data science, data warehousing, real-time analytics, and Power BI capabilities to help businesses access and analyze data quickly and accurately. Data scientists are empowered to enrich organizational data with predictions and allow business analysts to integrate those predictions into their BI reports. Power BI is the world's leading Business Intelligence platform."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  Microsoft Fabric is a comprehensive big data analytics platform that unifies OneLake and lakehouse architecture across enterprises. It is built on top of ADLS (Azure Data Lake Storage) Gen2 and provides a single SaaS experience and a tenant-wide store for data. It eliminates data silos and simplifies the experiences, eliminating the need for users to understand any infrastructure concepts."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  OneLake is a unified storage system for all developers that simplifies management, requires no up-front provisioning, and provides a single-pane-of-glass file-system namespace. It is hierarchical in nature, with tenants at the top level, workspaces as folders, and lakehouses as collections of files, folders, and tables. It allows developers and business units to instantly create their own storage accounts with policy and security settings enforced centrally and uniformly."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  Microsoft Fabric (Preview) trial provides access to the Fabric product experiences, including OneLake workspaces which allow users to ingest data, process, analyze and collaborate on the data. Shortcut feature allows users to access data stored in Azure Data Lake Storage and share data between users and applications. Additionally, the trial includes end-to-end tutorials in Microsoft Fabric."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  Microsoft Fabric is currently in preview and this document helps users understand and start a Fabric (Preview) trial. Existing Power BI users can skip to Start the Fabric (Preview) trial, while new users must first sign up for a Power BI free license. To start the trial, users must open the Fabric homepage and select the Account manager, agree to the terms, and select Start trial. Once the trial capacity is ready, users will receive a confirmation message and can begin working in Fabric."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  Microsoft Fabric (Preview) trial includes a Power BI individual trial and a Fabric (Preview) trial capacity. It provides full access to all of the Fabric experiences and features, as well as OneLake storage up to 1 TB. With a Fabric (Preview) trial, users can create workspaces (folders) for projects that support Fabric capabilities. The size of the capacity is determined by the SKU. An Account manager keeps track of the number of days remaining in the trial."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  Fabric (Preview) is a trial capacity that allows users to share and collaborate on items such as datasets, warehouses, and notebooks. To begin using the trial, users must add items to their workspace and assign it to their trial capacity. The trial capacity is 64 capacity units (CUs) that allow users to consume 64x60 CU seconds per minute. There is no limit on the number of workspaces or items that can be created, but the rate at which CUs are consumed must be taken into account."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  This article outlines the steps for administering a Fabric (Preview) trial, including cancelling the trial, disabling access for specific users, and understanding the impact of making changes to the tenant setting. Each trial user is the capacity admin for their trial capacity and Microsoft does not currently support multiple capacity administrators per trial capacity."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  Power BI administrators may have disabled access to the Fabric (Preview) trial, or the tenant may have exhausted its trial capacity limit. If the Start trial button is visible in the Account manager, the user may purchase a Fabric capacity from Azure, request another trial capacity user to share their trial capacity, or reach out to the Power BI administrator to create a CSS request to increase tenant trial capacity limits. Additionally, administrators cannot view metrics for individual capacities, but there are plans to support this capability in an upcoming admin monitoring feature."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  This known bug occurs when the Power BI administrator turns off trials after they have been started. To add the workspace to the trial capacity, open the Admin portal and select Trial > Capacity settings. The region for the Fabric (Preview) trial capacity is the home region for the tenant, and if it does not have Fabric enabled, then the trial cannot create any Fabric items. The Fabric (Preview) trial is different from an individual trial of Power BI paid in that it allows access to the Fabric landing page."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  The Fabric (Preview) trial is a free trial for users to access non-Power BI experiences and items. Private links and public access are disabled during the trial, and autoscale is not supported. Existing Synapse and Power BI users can sign up for the trial without an Azure subscription. If an Azure subscription is available, users can purchase a paid Fabric capacity."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  This article explains the terms used in Microsoft Fabric, a prerelease product. It explains how to migrate existing workspaces into a trial capacity, and provides definitions for terms such as capacity, experience, and item. It also provides information on the Fabric experiences, such as Synapse Data Warehouse, Synapse Data Engineering, Synapse Data Science, Synapse Real-Time Analytics, Data Factory, and Power BI."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  Synapse Data Engineering is a platform that provides capabilities such as lakehouses, notebooks, and Spark job definitions. A tenant is an instance of Fabric for an organization, and a workspace is a collection of items for collaboration. Lakehouses are collections of files, folders, and tables used for big data processing, and notebooks are interactive programming tools with rich functions."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  Apache Spark is a program used by data engineers and data scientists to explore and process data, build machine learning experiments, and collaborate with a team. It can be transformed into a pipeline activity for orchestration. It is divided into multiple Spark jobs that run in parallel, and is optimized with the v-order parquet file format. Data Factory offers a rich set of connectors to connect with the Spark application."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  Data Factory is a data pipeline used for orchestrating data movement and transformation. Dataflows provide a low-code interface for ingesting data from hundreds of data sources and transforming data. Data Wrangler is a notebook-based tool used for exploratory data analysis. Machine learning experiments are the primary unit of organization and control for all related machine learning runs."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  \n",
       "MLflow is a platform that allows users to track experiments and runs of machine learning models. Synapse Data Warehouse provides a traditional data warehouse with full transactional T-SQL capabilities. The KQL database is a representation of a database that can be queried using KQL queries, which can be saved and shared with others using the KQL Queryset."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  Microsoft Fabric is a platform that provides a centralized place to capture, transform, and route real-time events to destinations with a no-code experience. OneLake shortcuts are embedded references that point to other file store locations. End-to-end tutorials are available in Microsoft Fabric to help users develop a foundational understanding of the platform. Microsoft Fabric is currently in PREVIEW."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  This article provides tutorials for multiple Fabric experiences, including ingesting, transforming, and loading data into a lakehouse, exploring and cleaning a taxicab trip dataset, using streaming and query capabilities to analyze a New York Yellow Taxi trip dataset, building an end-to-end data warehouse, and creating a dataflow and pipeline to bring data into a lakehouse and generate a report."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  This article provides a reference guide and example scenarios to help decide whether to use a copy activity, dataflow, or Spark for workloads using Microsoft Fabric. It covers the properties of each, the use case, primary developer persona, and primary developer skill set. It also explains that no code or low code is required for the pipeline copy activity."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b> \n",
       "\n",
       "Dataflow Gen 2 is a low-code/no-code platform that provides data ingestion, transformation, wrangling, and profiling capabilities. It supports ETL, M, and SQL, and is powered by Spark. It has 30+ connectors for sources and 18+ connectors for destinations, and provides hundreds of Spark libraries. It also supports low to high complexity transformations, with 300+ transformations and support for native Spark and open-source libraries. It is suitable for data engineers, data scientists, and data developers."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  Leo, a data engineer with no experience in Spark, wants to consolidate data from various sources into a single lakehouse and process it on a schedule. Mary is tasked with cleaning the data, applying business logics, and loading it into multiple destinations. To achieve this, Leo uses the Copy Activity pattern to move petabytes of data to lakehouses and warehouses from varieties of sources, either ad-hoc or via a schedule. Mary will use her deep knowledge of the multiple LOB analytic reporting requirements to clean and load the data into multiple destinations."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  Mary is an experienced Power Query user and decides to use Dataflow Gen 2 as her preferred transformation option. Adam is a data engineer responsible for building and maintaining data pipelines for a large retail company. He decides to use Spark to build the extract and transformation logic and writes a Spark application using Python or Scala to read data from OneLake, cleanse, transform, and write to Delta tables in the lakehouse."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  This article provides a guide to help users choose between a data warehouse or a lakehouse for their workloads using Microsoft Fabric. It outlines the properties of each, including data volume, type of data, primary developer persona, primary developer skill set, citizen developer, read and write operations, multi-table transactions, primary development interface, and security. It is important to note that Microsoft Fabric is currently in PREVIEW."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  Susan, a professional developer, is new to Microsoft Fabric and needs to decide between building a data warehouse or a lakehouse. After reviewing the details, the primary decision points are the available skill set and the need for multi-table transactions. Susan has experience building data warehouses and the primary consumers of the data are also skilled with SQL and SQL analytical tools, so she decides to use a data warehouse. This allows the team to interact primarily with T-SQL while also allowing any Spark users in the organization to access the data."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  Rob, a data engineer, needs to store and model several terabytes of data in Fabric. He decides to use a lakehouse, which allows the team to use their diverse skills against the data. Ash, a citizen developer, is a Power BI developer and needs to build a data product for a business unit. They decide to use a Premium capacity subscription and realize the primary consumers of this data may be analysts, familiar with no-code."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  \n",
       "This article provides an overview of navigating to items and actions from Microsoft Fabric Home. It explains how each product experience has its own Home, and how items available on Home are different for each user. Ash decides to use a Power BI datamart to build the capability fast, using a no-code experience. Queries can be executed via Power BI and T-SQL, while also allowing any Spark users in the organization to access the data as well. The article also provides an introduction to data warehousing in Microsoft Fabric and how to create a warehouse and lakehouse in Microsoft Fabric."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  Microsoft Fabric is a platform where users can create and share items such as apps, lakehouses, warehouses, reports, and more. Home is the best place to start working in Microsoft Fabric, but users can also navigate directly to a workspace. Home is different for every user and product experience, but it includes a left navigation pane and a selector for switching product experiences. Power BI Home is different from other product experiences."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  Microsoft Fabric provides a top menu bar for orienting yourself, finding items, help, and sending feedback. The Account manager control is important for looking up account information and managing the trial. There are options for creating new items and links to recommended content to get started. Home organizes items by recent, favorites, and items shared with colleagues. Searching is the easiest and quickest way to find something, or use the nav pane to open a workspace or select a card on the Home canvas."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  The Data Factory Nav Pane includes Home, Browse, OneLake Data Hub, Create, and Workspaces. Workspaces are places to collaborate with colleagues and create collections of items. To find and open workspaces, you can search by name or owner, or select the Workspaces icon in the Nav Pane. When you open a workspace, its name replaces My Workspace in the Nav Pane."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  Microsoft Fabric provides a nav pane to view content such as notebooks, pipelines, reports, and lakehouses. The experience selector in the bottom left corner allows users to open other product experiences. Search, sort, and filter options are available to find content. The Help pane provides context sensitive help with articles, forum topics, and suggested topics to learn how to use Microsoft Fabric features and terminology."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  The Help pane is a great place to search for answers to questions. For more information, the user can scroll to the bottom of the Help pane for more resources, such as the Account manager and Support options. Additionally, the user can explore the Notifications center, Settings, and Feedback options in the upper right corner of Home. Finally, the canvas in the center of Home contains helpful content."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b> \n",
       "\n",
       "Power BI Home is a feature that allows users to create new items, view recommended items, recents, favorites, and content shared with them. When creating a new item, it is saved in the My workspace unless a workspace from Workspaces is selected. The Help pane is a feature-aware search engine that quickly finds answers to questions in the Fabric documentation and Fabric community forums. Microsoft Fabric is currently in PREVIEW."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  The Help pane is a search engine and feature-aware state that provides recommended topics, resources relevant to the current context and location in Fabric, and links to other resources. It is perfect for learning and getting started as it updates based on selections and locations in Fabric."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  The Help pane in Microsoft Fabric provides users with articles and documents to help them learn how to use the data hub. It also allows users to search the Microsoft documentation and community forums, as well as submit questions and ideas. Additionally, the Global Search feature allows users to search, filter, and sort through long lists of content."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  Microsoft Fabric provides a search box at the top of Home to quickly find items by title, name, or keyword. Search is available from Home and most other areas of Microsoft Fabric, and users can enter their colleague's name to search for content they have shared. Additionally, most experiences on the Microsoft Fabric canvas include a Filter by keyword field to narrow down the content on the canvas."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  Microsoft Fabric offers sorting and filtering features to help users quickly locate content. Sorting criteria can be set by selecting a column header, while filters can be displayed by selecting the Filter option in the upper right corner. However, not all columns can be sorted and the filters available depend on the location in Microsoft Fabric."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  This article explains how to open the Fabric settings pane and the different settings that can be accessed from there. These include preferences, such as setting the display language, managing notifications, and configuring settings for personal use. Additionally, the resources and extensions section provides links to pages where users can manage personal/group storage and Power BI settings."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b> \n",
       "\n",
       "Workspaces are places to collaborate with colleagues to create collections of Power BI items such as dashboards, datasets, workbooks, reports, datamarts, and dataflows. The manage page allows users to manage connections, on-premises data gateways, connections, embed codes, and virtual networks data gateways. The Azure Analysis Services page allows users to migrate their datasets to Power BI Premium. The governance and insights section provides links to help admins and users with their admin, governance, and compliance tasks. The Fabric admin portal allows admins to perform various management tasks and configure Fabric tenant settings. Microsoft Purview hub provides insights about an organization's sensitive data and links to Purview governance and compliance capabilities."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  This article provides tips on how to manage and navigate workspaces, including pinning workspaces to the top of the list, using granular workspace roles for flexible permissions, and managing workspace settings. Additionally, it explains how to select and open a workspace to make it the current workspace, and how to navigate to the current workspace from anywhere."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  The Workspace Contact List feature allows users to specify which users receive notifications about issues occurring in the workspace. The Workspace OneDrive feature allows users to configure a Microsoft 365 Group whose SharePoint document library is available to workspace users. It is important to note that creating Microsoft 365 Groups may be restricted in some environments, and permissions between users or groups with workspace access and users or groups with Microsoft 365 Group membership are not synchronized."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  You can configure OneDrive in workspace settings by typing in the name of the Microsoft 365 group that you created earlier. You can configure the license mode and Azure connections configuration in the workspace settings. Additionally, you can manage dataset storage in system storage."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  This article discusses the use of workspace accounts to store and publish reports and datasets. It explains how to free up storage space by deleting items, and how to remove a workspace as an admin. It also explains how to administer and audit workspaces in the Microsoft Fabric admin portal."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  This article explains how to create workspaces in Microsoft Fabric. It outlines the steps for creating a workspace, including giving it a unique name, providing a description, and assigning it to a domain. It also provides considerations and limitations to be aware of, such as a maximum of 1,000 datasets or reports per dataset, and special characters not being supported in workspace names. Finally, it provides next steps for creating workspaces and giving users access to them."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  This article explains the advanced settings for Power BI workspaces, including the contact list, license mode, and default storage format. It also notes that when downgrading from Premium capacity to Pro (Shared capacity), any non-Power BI Fabric items must first be removed."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  Power BI template apps are developed for sharing outside an organization and data used with Power BI is stored in internal storage provided by Power BI by default. Users can give access to a workspace and pin workspaces to the top of the workspace flyout list. Workspace roles allow users to manage who can do what in a Microsoft Fabric workspace."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  Microsoft Fabric workspaces are built on top of OneLake and divide the data lake into separate containers that can be secured independently. Workspace roles in Microsoft Fabric extend the Power BI workspace roles by associating new capabilities such as data integration and data exploration. Users are assigned roles such as Admin, Member, Contributor, or Viewer to grant access to the workspace. These roles have additional Microsoft Fabric capabilities in addition to the existing Power BI capabilities."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  This article provides an overview of the roles and permissions in workspaces in Power BI, and how to create workspaces and give users access to them. It also covers OneLake security, shortcuts, data warehouse security, data engineering security, and data science roles and permissions."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  Microsoft Fabric allows users to give others access to their workspace by assigning them roles such as Admin, Member, Contributor, or Viewer. To enforce row-level security, assign the Viewer Role. Permission changes only take effect the next time the user logs in. Access can be managed by selecting \"Manage Access\" on the workspace page, adding people or groups, and modifying access if needed."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  The OneLake data hub provides a filterable list of data items that users have access to, as well as a gallery of recommended data items, a way of finding data items by workspace, and an options menu of things that can be done with the data item. This article explains how to use the data hub, including how to filter the list of data items, and how to use the three tabs to narrow down the list of data items."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  This overview describes the columns of the data hub list, which includes the name, endorsement status, owner, workspace, refresh time, next refresh time, and sensitivity of the data item. It also explains how to find items by workspace and recommended items."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  This article explains how to use the data hub to view recommended data items, display data items belonging to a particular domain, and open an item's options menu. It also notes that the Explorer pane may list workspaces that the user does not have access to if the workspace contains items that the user does have access to."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  Fabric provides two ways to endorse items to increase their visibility: promotion and certification. Promotion is done by item owners or anyone with write permissions on the item, while certification is done by authorized reviewers. This article explains how to promote and certify items, as well as how to request certification if you're not an authorized reviewer."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  This article explains how to promote and certify items in Power BI. It outlines the steps to take to promote or certify an item, as well as how to request item certification if the user is not authorized to do so. It also explains how to make a dataset discoverable if the Make discoverable checkbox is available."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  This article provides instructions on how to apply sensitivity labels to Microsoft Fabric items. It explains how to open the settings of an item, expand the endorsement section, and select the link about how to get the item certified. It also explains that if the link redirects back to the note, it means the Power BI admin has not made any information available and the user should contact the Power BI admin directly. Finally, it provides prerequisites for applying sensitivity labels."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Chunk Summary:</b>  In order to apply sensitivity labels to Fabric items, you must have Power BI Pro or Premium Per User (PPU) license, as well as edit permissions on the item you wish to label. There are two ways to apply a sensitivity label to an item: from the flyout menu in the item header, and in the item settings. If you cannot apply a label, contact your organization's tech support."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For the chaintype of MapReduce and Refine, we can also get insight into intermediate steps of the pipeline.\n",
    "# This way you can inspect the results from map_reduce chain type, each top similar chunk summary\n",
    "intermediateSteps = summary['intermediate_steps']\n",
    "for step in intermediateSteps:\n",
    "        display(HTML(\"<b>Chunk Summary:</b> \" + step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: What are the advantages of Microsoft Fabric's SaaS foundation?\n",
      "\n",
      "Sample Questions:\n",
      "1. How does Microsoft Fabric's SaaS foundation improve scalability?\n",
      "2. What security features are included in Microsoft Fabric's SaaS foundation?\n",
      "3. How does Microsoft Fabric's SaaS foundation help reduce costs?\n",
      "4. What is the architecture of Microsoft Fabric's SaaS foundation?\n",
      "5. How does Microsoft Fabric's SaaS foundation enable faster deployment?\n"
     ]
    }
   ],
   "source": [
    "# Now that we have the summary, let's create the prompt to generates sample questions from the document\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "qaTemplate = \"\"\"Use the following portion of a long document.\n",
    "        {context}\n",
    "        \"\"\"\n",
    "\n",
    "qaPrompt = PromptTemplate(template=qaTemplate, input_variables=[\"context\"])\n",
    "\n",
    "combinePromptTemplate = \"\"\" \n",
    "        Given the following extracted parts of a long document and a question, recommend between 1-5 sample questions.\n",
    "        =========\n",
    "        {summaries}\n",
    "        =========\n",
    "        \"\"\"\n",
    "combinePrompt = PromptTemplate(\n",
    "    template=combinePromptTemplate, input_variables=[\"summaries\"]\n",
    ")\n",
    "qaChain = load_qa_with_sources_chain(llm,\n",
    "        chain_type=\"map_reduce\", question_prompt=qaPrompt, combine_prompt=combinePrompt)\n",
    "answer = qaChain({\"input_documents\": docs}, return_only_outputs=True)\n",
    "qa = answer['output_text']\n",
    "print(qa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
